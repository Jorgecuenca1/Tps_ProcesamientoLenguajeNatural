{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jorgecuenca1/Tps_ProcesamientoLenguajeNatural/blob/main/clase1_tp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AVncikBcTKxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9742d55-3cd5-4a83-f82c-1f6c4ec717c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['el', 'hoy', 'de', 'gracias', 'muchas', 'que', 'martes', 'dia', 'es']\n",
            "[[0 1 0 0 0 1 0 1 1]\n",
            " [1 1 1 0 0 0 1 1 1]\n",
            " [0 0 0 1 1 0 1 0 0]]\n",
            "[[0 1 0 0 0 1 0 1 1]\n",
            " [1 1 1 0 0 0 2 1 1]\n",
            " [0 0 0 1 1 0 1 0 0]]\n",
            "[[-0.         -0.51082562 -0.         -0.         -0.         -0.51082562\n",
            "  -0.         -0.51082562 -0.51082562]\n",
            " [-0.84729786 -0.84729786 -0.84729786 -0.         -0.         -0.\n",
            "  -1.69459572 -0.84729786 -0.84729786]\n",
            " [-0.         -0.         -0.         -0.28768207 -0.28768207 -0.\n",
            "  -0.28768207 -0.         -0.        ]]\n",
            "[0 1 2]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Obtener el vocabulario del corpus\n",
        "def get_vocab(corpus):\n",
        "    vocab = set()\n",
        "    for doc in corpus:\n",
        "        words = doc.split()\n",
        "        vocab.update(words)\n",
        "    return list(vocab)\n",
        "\n",
        "corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])\n",
        "vocab = get_vocab(corpus)\n",
        "print(vocab)\n",
        "# 2. One-hot encoding\n",
        "def one_hot_encode(corpus, vocab):\n",
        "    vectorized_docs = []\n",
        "    for doc in corpus:\n",
        "        words = doc.split()\n",
        "        vector = [1 if term in words else 0 for term in vocab]\n",
        "        vectorized_docs.append(vector)\n",
        "    return np.array(vectorized_docs)\n",
        "\n",
        "one_hot_encoded = one_hot_encode(corpus, vocab)\n",
        "print(one_hot_encoded)\n",
        "# 3. Vectores de frecuencia\n",
        "def term_frequency(corpus, vocab):\n",
        "    vectorized_docs = []\n",
        "    for doc in corpus:\n",
        "        words = doc.split()\n",
        "        vector = [words.count(term) for term in vocab]\n",
        "        vectorized_docs.append(vector)\n",
        "    return np.array(vectorized_docs)\n",
        "\n",
        "term_frequencies = term_frequency(corpus, vocab)\n",
        "print(term_frequencies)\n",
        "# 4. TF-IDF\n",
        "def tf_idf(corpus, vocab):\n",
        "    N = len(corpus)\n",
        "    term_frequencies = term_frequency(corpus, vocab)\n",
        "    vectorized_docs = []\n",
        "    for doc_tf in term_frequencies:\n",
        "        df = np.count_nonzero(doc_tf)\n",
        "        idf = np.log(N / (df + 1))\n",
        "        tf_idf_vector = np.multiply(doc_tf, idf)\n",
        "        vectorized_docs.append(tf_idf_vector)\n",
        "    return np.array(vectorized_docs)\n",
        "\n",
        "tf_idf_vectors = tf_idf(corpus, vocab)\n",
        "print(tf_idf_vectors)\n",
        "# 5. Comparaci√≥n de documentos\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))\n",
        "\n",
        "def compare_docs(corpus, index):\n",
        "    tf_idf_vectors = tf_idf(corpus, vocab)\n",
        "    similarities = [cosine_similarity(tf_idf_vectors[index], vec) for vec in tf_idf_vectors]\n",
        "    sorted_docs = np.argsort(similarities)[::-1]\n",
        "    return sorted_docs\n",
        "\n",
        "doc_similarities = compare_docs(corpus, 0)\n",
        "print(doc_similarities)\n"
      ]
    }
  ]
}