{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jorgecuenca1/Tps_ProcesamientoLenguajeNatural/blob/main/TP%20clase%202.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. RULE-BASED NOT CON TF IDF"
      ],
      "metadata": {
        "id": "nTbQDWtcBvPx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1nr_XPXAQvp",
        "outputId": "b8bd050c-4eca-45aa-9a66-5f147ab401fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usuario: como te llamas?\n",
            "Pregunta más cercana:  Lo siento, no puedo responder a esa pregunta.\n",
            "ChatBot:  \n",
            "Usuario: que eres\n",
            "Pregunta más cercana:  Lo siento, no puedo responder a esa pregunta.\n",
            "ChatBot:  \n",
            "Usuario: hola, como estas?\n",
            "Pregunta más cercana:  Lo siento, no puedo responder a esa pregunta.\n",
            "ChatBot:  \n",
            "Usuario: ¿Cuál es tu nombre?\n",
            "Pregunta más cercana:  ¿cuál es tu nombre?\n",
            "ChatBot:  Soy un bot\n",
            "Usuario: ¿Cómo estás?\n",
            "Pregunta más cercana:  ¿cómo estás?\n",
            "ChatBot:  Estoy bien, gracias\n",
            "Usuario: ¿Cuál es tu color favorito?\n",
            "Pregunta más cercana:  ¿cuál es tu color favorito?\n",
            "ChatBot:  Mi color favorito es azul\n",
            "Usuario: ¿Dónde vives?\n",
            "Pregunta más cercana:  ¿dónde vives?\n",
            "ChatBot:  Vivo en el ciberespacio\n"
          ]
        }
      ],
      "source": [
        "# importamos las librerias necesarias\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "\n",
        "# ignoramos los warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "nltk.download('punkt') # primero descargamos punkt\n",
        "nltk.download('stopwords') # luego descargamos las stopwords\n",
        "\n",
        "# esto es solo un ejemplo, deberías cambiar estas respuestas y preguntas por las tuyas\n",
        "data = {'preguntas': ['¿Cuál es tu nombre?', '¿Cómo estás?', '¿Cuál es tu color favorito?', '¿Dónde vives?'],\n",
        "        'respuestas': ['Soy un bot', 'Estoy bien, gracias', 'Mi color favorito es azul', 'Vivo en el ciberespacio']}\n",
        "\n",
        "# convertimos todas las preguntas a minúsculas\n",
        "data['preguntas'] = [pregunta.lower() for pregunta in data['preguntas']]\n",
        "\n",
        "# creamos nuestro vectorizador TF-IDF\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
        "\n",
        "# entrenamos el vectorizador con nuestras preguntas\n",
        "X = vectorizer.fit_transform(data['preguntas'])\n",
        "\n",
        "def chatbot(pregunta):\n",
        "    # convertimos la pregunta a minúsculas\n",
        "    pregunta = pregunta.lower()\n",
        "\n",
        "    # calculamos la matriz tf-idf de la pregunta\n",
        "    pregunta_tf_idf = vectorizer.transform([pregunta])\n",
        "\n",
        "    # calculamos la similitud del coseno entre la pregunta del usuario y todas las preguntas en nuestros datos\n",
        "    cosineValues = cosine_similarity(pregunta_tf_idf, X)\n",
        "\n",
        "    # obtenemos el índice de la pregunta más similar en nuestros datos\n",
        "    idx = np.argmax(cosineValues)\n",
        "\n",
        "    # si la similitud del coseno es 0 entonces la pregunta del usuario no es similar a ninguna de nuestras preguntas\n",
        "    if cosineValues[0][idx] == 0:\n",
        "        return \"Lo siento, no puedo responder a esa pregunta.\", \"\"\n",
        "    else:\n",
        "        return data['preguntas'][idx], data['respuestas'][idx]\n",
        "\n",
        "while True:\n",
        "    userInput = input(\"Usuario: \")\n",
        "    if userInput.lower() == 'salir':\n",
        "        break\n",
        "    pregunta, respuesta = chatbot(userInput)\n",
        "    print(\"Pregunta más cercana: \", pregunta)\n",
        "    print(\"ChatBot: \", respuesta)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "rule-based bot con DNN"
      ],
      "metadata": {
        "id": "jrqWSW1UCGb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "latent_dim = 256\n",
        "\n",
        "# Pares de preguntas y respuestas\n",
        "input_texts = ['Hola', '¿Cómo estás?', 'Adiós', '¿Cuál es tu nombre?', '¿Qué hora es?',\n",
        "               '¿Puedes ayudarme?', 'No entiendo', '¿Eres un robot?', '¿Dónde estamos?',\n",
        "               '¿Quién eres?', 'Me siento triste', 'Estoy feliz', 'Estoy aburrido',\n",
        "               '¿Puedes contarme un chiste?', '¿Cómo es el clima hoy?', '¿Cuál es tu comida favorita?',\n",
        "               'Estoy aprendiendo Python', 'Me gusta el fútbol', '¿Puedes recomendarme una película?',\n",
        "               '¿Qué edad tienes?']\n",
        "\n",
        "target_texts = ['Hola, ¿cómo puedo ayudarte hoy?', 'Soy un bot, no tengo emociones, pero gracias por preguntar. ¿Cómo puedo ayudarte hoy?',\n",
        "                'Adiós, ¡ten un buen día!', 'Soy Chatbot, un bot de IA.',\n",
        "                'Lo siento, como bot de chat, no tengo acceso a la hora actual.',\n",
        "                'Claro, estaré encantado de ayudarte. ¿Qué necesitas?',\n",
        "                'Lo siento si algo no fue claro. Intenta hacer tu pregunta de otra manera.',\n",
        "                'Sí, soy un bot de chat basado en inteligencia artificial.',\n",
        "                'Estamos en el ciberespacio.',\n",
        "                'Soy Chatbot, un bot de IA desarrollado para responder a tus preguntas.',\n",
        "                'Lo siento, debes sentirte así. Recuerda que hay personas que pueden ayudarte.',\n",
        "                '¡Me alegra saber que estás feliz!',\n",
        "                '¡Puedo ayudarte a aprender algo nuevo si quieres!',\n",
        "                '¿Por qué los pájaros no usan Facebook? Porque ya tienen Twitter.',\n",
        "                'Lo siento, como bot de chat, no tengo acceso a información en tiempo real como el clima.',\n",
        "                'Como bot de IA, no como comida.',\n",
        "                '¡Eso es genial! Python es un lenguaje de programación muy útil.',\n",
        "                'Eso es interesante. ¿Te gustaría saber más sobre fútbol?',\n",
        "                'Lo siento, como un bot de chat, no tengo la capacidad de recomendar películas.',\n",
        "                'Como un bot de IA, no tengo una edad.']\n",
        "\n",
        "# Código para preparar los datos de entrenamiento y prueba\n",
        "\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "for input_text, target_text in zip(input_texts, target_texts):\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "# Mapa de caracteres a índices/índices a caracteres\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "# Preparación de datos para la LSTM\n",
        "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
        "decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
        "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "\n",
        "# Creación del modelo\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "\n",
        "# Inferencia\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "# Creación de diccionarios inversos para la inferencia\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "        if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        if sampled_token_index in target_token_index.values():\n",
        "            target_seq[0, 0, sampled_token_index] = 1.\n",
        "        states_value = [h, c]\n",
        "    return decoded_sentence\n",
        "\n",
        "def get_user_input():\n",
        "    user_input = input(\"Por favor, escriba su pregunta: \")\n",
        "    input_seq = np.zeros((1, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
        "    for t, char in enumerate(user_input):\n",
        "        if char in input_token_index:\n",
        "            input_seq[0, t, input_token_index[char]] = 1.\n",
        "    return user_input, input_seq\n",
        "\n",
        "while True:\n",
        "    user_input, user_input_seq = get_user_input()\n",
        "    decoded_sentence = decode_sequence(user_input_seq)\n",
        "    print('Pregunta:', user_input)\n",
        "    print('Respuesta:', decoded_sentence)\n"
      ],
      "metadata": {
        "id": "EvtPhz_SqhgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un bot basado en reglas con TF-IDF, como el primer ejemplo, es relativamente más sencillo y rápido de implementar. Utiliza técnicas clásicas de Procesamiento del Lenguaje Natural (PLN) y Recuperación de Información para responder a las preguntas en función de su similitud con las preguntas predefinidas. Este enfoque tiene la ventaja de ser fácil de entender y de controlar, ya que las respuestas son predefinidas y las reglas están bien establecidas.\n",
        "\n",
        "En cambio, un bot basado en Redes Neuronales Profundas, como el segundo ejemplo, es más complejo y puede requerir un tiempo de entrenamiento significativo. Sin embargo, tiene la capacidad de aprender y generalizar a partir de los datos de entrenamiento, lo que significa que puede ser capaz de proporcionar respuestas sensatas a preguntas que no se encuentren exactamente en los datos de entrenamiento. Además, este enfoque puede mejorar con el tiempo y con más datos de entrenamiento(esta dificil a mi manera que buen ejemplo el que nos diste en tu clase yo intente algo y esta suepr dificil).\n",
        "\n",
        "En cuanto a cuál es más óptimo, depende en gran medida del contexto y de los requisitos específicos. Si tienes un conjunto limitado de preguntas y respuestas y prefieres tener un control total sobre las respuestas del bot, un bot basado en reglas con TF-IDF podría ser la opción más adecuada. Por otro lado, si tienes una gran cantidad de datos de entrenamiento y estás dispuesto a invertir tiempo y recursos en el entrenamiento y la afinación de un modelo de aprendizaje profundo, un bot basado en Redes Neuronales Profundas podría proporcionar un rendimiento superior."
      ],
      "metadata": {
        "id": "QNf-LlQtCdrh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r29G8bHhngr3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}