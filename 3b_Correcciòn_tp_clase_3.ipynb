{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jorgecuenca1/Tps_ProcesamientoLenguajeNatural/blob/main/3b_Correcci%C3%B2n_tp_clase_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZd5yLnnHOK0"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Custom embedddings con Gensim\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA7nqkumo9z9"
      },
      "source": [
        "### Objetivo\n",
        "El objetivo es utilizar documentos / corpus para crear embeddings de palabras basado en ese contexto. Se utilizará canciones de bandas para generar los embeddings, es decir, que los vectores tendrán la forma en función de como esa banda haya utilizado las palabras en sus canciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lFToQs5FK5uZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import multiprocessing\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g07zJxG7H9vG"
      },
      "source": [
        "### Datos\n",
        "Utilizaremos como dataset canciones de bandas de habla inglesa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l7z4CSBfpR3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13888065-44d6-4cec-994b-1bd18371b4c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-22 05:13:39--  http://songs_dataset.zip/\n",
            "Resolving songs_dataset.zip (songs_dataset.zip)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘songs_dataset.zip’\n",
            "--2023-06-22 05:13:39--  https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/datasets/songs_dataset.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/datasets/songs_dataset.zip [following]\n",
            "--2023-06-22 05:13:39--  https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/datasets/songs_dataset.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2075036 (2.0M) [application/zip]\n",
            "Saving to: ‘songs_dataset.zip’\n",
            "\n",
            "songs_dataset.zip   100%[===================>]   1.98M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-06-22 05:13:39 (152 MB/s) - ‘songs_dataset.zip’ saved [2075036/2075036]\n",
            "\n",
            "FINISHED --2023-06-22 05:13:39--\n",
            "Total wall clock time: 0.5s\n",
            "Downloaded: 1 files, 2.0M in 0.01s (152 MB/s)\n"
          ]
        }
      ],
      "source": [
        "# Descargar la carpeta de dataset\n",
        "import os\n",
        "import platform\n",
        "if os.access('./songs_dataset', os.F_OK) is False:\n",
        "    if os.access('songs_dataset.zip', os.F_OK) is False:\n",
        "        if platform.system() == 'Windows':\n",
        "            !curl https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/datasets/songs_dataset.zip -o songs_dataset.zip\n",
        "        else:\n",
        "            !wget songs_dataset.zip https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/datasets/songs_dataset.zip\n",
        "    !unzip -q songs_dataset.zip\n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mysGrIw9ljC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6aef7f8-a623-43e7-fc05-a4488693fffd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alicia-keys.txt',\n",
              " 'kanye-west.txt',\n",
              " 'adele.txt',\n",
              " 'drake.txt',\n",
              " 'bieber.txt',\n",
              " 'bruno-mars.txt',\n",
              " 'notorious-big.txt',\n",
              " 'paul-simon.txt',\n",
              " 'nursery_rhymes.txt',\n",
              " 'bob-marley.txt',\n",
              " 'joni-mitchell.txt',\n",
              " 'Kanye_West.txt',\n",
              " 'bjork.txt',\n",
              " 'beatles.txt',\n",
              " 'lil-wayne.txt',\n",
              " 'kanye.txt',\n",
              " 'disney.txt',\n",
              " 'dj-khaled.txt',\n",
              " 'prince.txt',\n",
              " 'nirvana.txt',\n",
              " 'patti-smith.txt',\n",
              " 'nicki-minaj.txt',\n",
              " 'al-green.txt',\n",
              " 'blink-182.txt',\n",
              " 'missy-elliott.txt',\n",
              " 'leonard-cohen.txt',\n",
              " 'bruce-springsteen.txt',\n",
              " 'lin-manuel-miranda.txt',\n",
              " 'jimi-hendrix.txt',\n",
              " 'bob-dylan.txt',\n",
              " 'johnny-cash.txt',\n",
              " 'michael-jackson.txt',\n",
              " 'nickelback.txt',\n",
              " 'ludacris.txt',\n",
              " 'radiohead.txt',\n",
              " 'eminem.txt',\n",
              " 'dickinson.txt',\n",
              " 'janisjoplin.txt',\n",
              " 'notorious_big.txt',\n",
              " 'amy-winehouse.txt',\n",
              " 'dr-seuss.txt',\n",
              " 'r-kelly.txt',\n",
              " 'Lil_Wayne.txt',\n",
              " 'lorde.txt',\n",
              " 'britney-spears.txt',\n",
              " 'rihanna.txt',\n",
              " 'lady-gaga.txt',\n",
              " 'dolly-parton.txt',\n",
              " 'cake.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Posibles bandas\n",
        "os.listdir(\"./songs_dataset/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ticoqYD1Z3I7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "69d7b33b-8b5a-4b12-d767-f05b4b50fa9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-89d9bc44a57b>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  df = pd.read_csv('songs_dataset/bob-marley.txt', sep='/n', header=None)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   0\n",
              "0                        \"Don't worry about a thing,\n",
              "1      'Cause every little thing gonna be all right.\n",
              "2               Singin': \"Don't worry about a thing,\n",
              "3  'Cause every little thing gonna be all right!\"...\n",
              "4                        Smiled with the risin' sun,"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16460045-4aea-4766-ae11-05cd10b6e68a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"Don't worry about a thing,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'Cause every little thing gonna be all right.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Singin': \"Don't worry about a thing,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'Cause every little thing gonna be all right!\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Smiled with the risin' sun,</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16460045-4aea-4766-ae11-05cd10b6e68a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16460045-4aea-4766-ae11-05cd10b6e68a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16460045-4aea-4766-ae11-05cd10b6e68a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Armar el dataset utilizando salto de línea para separar las oraciones/docs\n",
        "df = pd.read_csv('songs_dataset/bob-marley.txt', sep='/n', header=None)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LEpKubK9XzXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8552b168-6531-489f-d15d-a9e78781b055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de documentos: 2218\n"
          ]
        }
      ],
      "source": [
        "print(\"Cantidad de documentos:\", df.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab94qaFlrA1G"
      },
      "source": [
        "### 1 - Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rIsmMWmjrDHd"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "sentence_tokens = []\n",
        "# Recorrer todas las filas y transformar las oraciones\n",
        "# en una secuencia de palabras (esto podría realizarse con NLTK o spaCy también)\n",
        "for _, row in df[:None].iterrows():\n",
        "    sentence_tokens.append(text_to_word_sequence(row[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CHepi_DGrbhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72c713b5-9651-4865-d497-8525309470bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[\"don't\", 'worry', 'about', 'a', 'thing'],\n",
              " [\"'cause\", 'every', 'little', 'thing', 'gonna', 'be', 'all', 'right']]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Demos un vistazo\n",
        "sentence_tokens[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaXV6nlHr5Aa"
      },
      "source": [
        "### 2 - Crear los vectores (word2vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OSb0v7h8r7hK"
      },
      "outputs": [],
      "source": [
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "# Durante el entrenamiento gensim por defecto no informa el \"loss\" en cada época\n",
        "# Sobrecargamos el callback para poder tener esta información\n",
        "class callback(CallbackAny2Vec):\n",
        "    \"\"\"\n",
        "    Callback to print loss after each epoch\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        loss = model.get_latest_training_loss()\n",
        "        if self.epoch == 0:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
        "        else:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
        "        self.epoch += 1\n",
        "        self.loss_previous_step = loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "i0wnDdv9sJ47"
      },
      "outputs": [],
      "source": [
        "# Crearmos el modelo generador de vectores\n",
        "# En este caso utilizaremos la estructura modelo Skipgram\n",
        "w2v_model = Word2Vec(min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario\n",
        "                     window=2,       # cant de palabras antes y desp de la predicha\n",
        "                     vector_size=300,       # dimensionalidad de los vectores\n",
        "                     negative=20,    # cantidad de negative samples... 0 es no se usa\n",
        "                     workers=1,      # si tienen más cores pueden cambiar este valor\n",
        "                     sg=1)           # modelo 0:CBOW  1:skipgram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5lTt8wErsf17"
      },
      "outputs": [],
      "source": [
        "# Obtener el vocabulario con los tokens\n",
        "w2v_model.build_vocab(sentence_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TNc9qt4os5AT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6db4232c-191c-4ee2-8f2e-a29d5b08edac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de docs en el corpus: 2218\n"
          ]
        }
      ],
      "source": [
        "# Cantidad de filas/docs encontradas en el corpus\n",
        "print(\"Cantidad de docs en el corpus:\", w2v_model.corpus_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "idw9cHF3tSMl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3445e838-6a62-4d7c-95e2-9ff846232c52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de palabras distintas en el corpus: 532\n"
          ]
        }
      ],
      "source": [
        "# Cantidad de words encontradas en el corpus\n",
        "num_words = len(w2v_model.wv)\n",
        "print(\"Cantidad de palabras distintas en el corpus:\", num_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC9mZ8DPk-UC"
      },
      "source": [
        "### 3 - Entrenar el modelo generador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QSp-x0PAsq56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3640f9ac-3e00-4a52-ab72-a27fbac289e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after epoch 0: 150431.25\n",
            "Loss after epoch 1: 92639.9375\n",
            "Loss after epoch 2: 91598.375\n",
            "Loss after epoch 3: 91160.0\n",
            "Loss after epoch 4: 89182.40625\n",
            "Loss after epoch 5: 83465.03125\n",
            "Loss after epoch 6: 76280.3125\n",
            "Loss after epoch 7: 72554.0625\n",
            "Loss after epoch 8: 68532.1875\n",
            "Loss after epoch 9: 64487.9375\n",
            "Loss after epoch 10: 62416.8125\n",
            "Loss after epoch 11: 60083.625\n",
            "Loss after epoch 12: 57400.0625\n",
            "Loss after epoch 13: 52298.125\n",
            "Loss after epoch 14: 51624.875\n",
            "Loss after epoch 15: 51240.75\n",
            "Loss after epoch 16: 49625.25\n",
            "Loss after epoch 17: 49211.0\n",
            "Loss after epoch 18: 48584.5\n",
            "Loss after epoch 19: 47380.875\n",
            "Loss after epoch 20: 47196.75\n",
            "Loss after epoch 21: 46585.0\n",
            "Loss after epoch 22: 46403.0\n",
            "Loss after epoch 23: 46236.625\n",
            "Loss after epoch 24: 45696.25\n",
            "Loss after epoch 25: 45878.75\n",
            "Loss after epoch 26: 45894.375\n",
            "Loss after epoch 27: 44992.125\n",
            "Loss after epoch 28: 44379.25\n",
            "Loss after epoch 29: 44183.25\n",
            "Loss after epoch 30: 44150.125\n",
            "Loss after epoch 31: 44592.75\n",
            "Loss after epoch 32: 44433.875\n",
            "Loss after epoch 33: 44274.375\n",
            "Loss after epoch 34: 44331.125\n",
            "Loss after epoch 35: 43101.25\n",
            "Loss after epoch 36: 43005.75\n",
            "Loss after epoch 37: 41888.0\n",
            "Loss after epoch 38: 41964.5\n",
            "Loss after epoch 39: 41911.5\n",
            "Loss after epoch 40: 42477.25\n",
            "Loss after epoch 41: 42760.25\n",
            "Loss after epoch 42: 42645.25\n",
            "Loss after epoch 43: 42592.5\n",
            "Loss after epoch 44: 42039.0\n",
            "Loss after epoch 45: 41392.5\n",
            "Loss after epoch 46: 43139.25\n",
            "Loss after epoch 47: 42380.0\n",
            "Loss after epoch 48: 42025.25\n",
            "Loss after epoch 49: 42488.0\n",
            "Loss after epoch 50: 41328.0\n",
            "Loss after epoch 51: 42142.0\n",
            "Loss after epoch 52: 41919.0\n",
            "Loss after epoch 53: 42263.0\n",
            "Loss after epoch 54: 43174.75\n",
            "Loss after epoch 55: 42080.25\n",
            "Loss after epoch 56: 42948.25\n",
            "Loss after epoch 57: 41751.75\n",
            "Loss after epoch 58: 42455.0\n",
            "Loss after epoch 59: 41934.5\n",
            "Loss after epoch 60: 41891.75\n",
            "Loss after epoch 61: 42413.75\n",
            "Loss after epoch 62: 42511.75\n",
            "Loss after epoch 63: 42421.0\n",
            "Loss after epoch 64: 42037.25\n",
            "Loss after epoch 65: 41925.75\n",
            "Loss after epoch 66: 42010.75\n",
            "Loss after epoch 67: 43125.25\n",
            "Loss after epoch 68: 42793.5\n",
            "Loss after epoch 69: 42268.25\n",
            "Loss after epoch 70: 41586.75\n",
            "Loss after epoch 71: 41497.5\n",
            "Loss after epoch 72: 41890.75\n",
            "Loss after epoch 73: 41931.25\n",
            "Loss after epoch 74: 41652.5\n",
            "Loss after epoch 75: 42232.75\n",
            "Loss after epoch 76: 42401.75\n",
            "Loss after epoch 77: 42657.5\n",
            "Loss after epoch 78: 42246.25\n",
            "Loss after epoch 79: 41815.25\n",
            "Loss after epoch 80: 41113.25\n",
            "Loss after epoch 81: 42070.75\n",
            "Loss after epoch 82: 41059.75\n",
            "Loss after epoch 83: 41894.75\n",
            "Loss after epoch 84: 41631.0\n",
            "Loss after epoch 85: 39211.0\n",
            "Loss after epoch 86: 39292.0\n",
            "Loss after epoch 87: 40163.5\n",
            "Loss after epoch 88: 39349.0\n",
            "Loss after epoch 89: 39784.0\n",
            "Loss after epoch 90: 39760.0\n",
            "Loss after epoch 91: 39670.5\n",
            "Loss after epoch 92: 39720.5\n",
            "Loss after epoch 93: 39335.5\n",
            "Loss after epoch 94: 40175.5\n",
            "Loss after epoch 95: 40933.5\n",
            "Loss after epoch 96: 38733.0\n",
            "Loss after epoch 97: 39938.5\n",
            "Loss after epoch 98: 39863.0\n",
            "Loss after epoch 99: 39860.0\n",
            "Loss after epoch 100: 39326.5\n",
            "Loss after epoch 101: 39690.5\n",
            "Loss after epoch 102: 39907.0\n",
            "Loss after epoch 103: 40158.0\n",
            "Loss after epoch 104: 40149.5\n",
            "Loss after epoch 105: 39661.5\n",
            "Loss after epoch 106: 39970.0\n",
            "Loss after epoch 107: 38936.5\n",
            "Loss after epoch 108: 39488.0\n",
            "Loss after epoch 109: 39502.0\n",
            "Loss after epoch 110: 39939.5\n",
            "Loss after epoch 111: 39568.0\n",
            "Loss after epoch 112: 40018.0\n",
            "Loss after epoch 113: 39614.5\n",
            "Loss after epoch 114: 40098.5\n",
            "Loss after epoch 115: 40182.0\n",
            "Loss after epoch 116: 40278.0\n",
            "Loss after epoch 117: 39433.0\n",
            "Loss after epoch 118: 39603.5\n",
            "Loss after epoch 119: 39912.5\n",
            "Loss after epoch 120: 39864.5\n",
            "Loss after epoch 121: 39929.0\n",
            "Loss after epoch 122: 39474.5\n",
            "Loss after epoch 123: 39686.0\n",
            "Loss after epoch 124: 39997.5\n",
            "Loss after epoch 125: 39759.5\n",
            "Loss after epoch 126: 39634.0\n",
            "Loss after epoch 127: 40095.0\n",
            "Loss after epoch 128: 39611.5\n",
            "Loss after epoch 129: 39372.0\n",
            "Loss after epoch 130: 39378.0\n",
            "Loss after epoch 131: 39539.5\n",
            "Loss after epoch 132: 40000.5\n",
            "Loss after epoch 133: 39620.0\n",
            "Loss after epoch 134: 39092.0\n",
            "Loss after epoch 135: 39840.5\n",
            "Loss after epoch 136: 39815.5\n",
            "Loss after epoch 137: 40134.0\n",
            "Loss after epoch 138: 40054.0\n",
            "Loss after epoch 139: 39905.0\n",
            "Loss after epoch 140: 40075.0\n",
            "Loss after epoch 141: 40143.5\n",
            "Loss after epoch 142: 39941.0\n",
            "Loss after epoch 143: 40649.0\n",
            "Loss after epoch 144: 39981.5\n",
            "Loss after epoch 145: 39426.0\n",
            "Loss after epoch 146: 39485.0\n",
            "Loss after epoch 147: 39726.0\n",
            "Loss after epoch 148: 39614.0\n",
            "Loss after epoch 149: 40029.0\n",
            "Loss after epoch 150: 40132.5\n",
            "Loss after epoch 151: 40196.5\n",
            "Loss after epoch 152: 39985.0\n",
            "Loss after epoch 153: 40427.0\n",
            "Loss after epoch 154: 40035.5\n",
            "Loss after epoch 155: 39832.5\n",
            "Loss after epoch 156: 39587.0\n",
            "Loss after epoch 157: 39326.0\n",
            "Loss after epoch 158: 39530.0\n",
            "Loss after epoch 159: 39269.5\n",
            "Loss after epoch 160: 39487.0\n",
            "Loss after epoch 161: 40129.0\n",
            "Loss after epoch 162: 39914.0\n",
            "Loss after epoch 163: 39966.5\n",
            "Loss after epoch 164: 39833.5\n",
            "Loss after epoch 165: 39680.0\n",
            "Loss after epoch 166: 39912.0\n",
            "Loss after epoch 167: 38607.0\n",
            "Loss after epoch 168: 40059.5\n",
            "Loss after epoch 169: 39839.0\n",
            "Loss after epoch 170: 39924.5\n",
            "Loss after epoch 171: 39937.5\n",
            "Loss after epoch 172: 39456.5\n",
            "Loss after epoch 173: 39997.5\n",
            "Loss after epoch 174: 40202.0\n",
            "Loss after epoch 175: 39604.0\n",
            "Loss after epoch 176: 39068.5\n",
            "Loss after epoch 177: 39529.5\n",
            "Loss after epoch 178: 40332.0\n",
            "Loss after epoch 179: 40366.0\n",
            "Loss after epoch 180: 39431.0\n",
            "Loss after epoch 181: 39307.0\n",
            "Loss after epoch 182: 39726.0\n",
            "Loss after epoch 183: 40102.0\n",
            "Loss after epoch 184: 40104.5\n",
            "Loss after epoch 185: 40666.0\n",
            "Loss after epoch 186: 39795.0\n",
            "Loss after epoch 187: 40054.5\n",
            "Loss after epoch 188: 39715.0\n",
            "Loss after epoch 189: 39802.0\n",
            "Loss after epoch 190: 37565.5\n",
            "Loss after epoch 191: 36202.0\n",
            "Loss after epoch 192: 37590.0\n",
            "Loss after epoch 193: 36455.0\n",
            "Loss after epoch 194: 37038.0\n",
            "Loss after epoch 195: 36534.0\n",
            "Loss after epoch 196: 36784.0\n",
            "Loss after epoch 197: 35966.0\n",
            "Loss after epoch 198: 36715.0\n",
            "Loss after epoch 199: 36868.0\n",
            "Loss after epoch 200: 36524.0\n",
            "Loss after epoch 201: 36770.0\n",
            "Loss after epoch 202: 36924.0\n",
            "Loss after epoch 203: 36712.0\n",
            "Loss after epoch 204: 36681.0\n",
            "Loss after epoch 205: 36840.0\n",
            "Loss after epoch 206: 36929.0\n",
            "Loss after epoch 207: 36745.0\n",
            "Loss after epoch 208: 36494.0\n",
            "Loss after epoch 209: 36922.0\n",
            "Loss after epoch 210: 36785.0\n",
            "Loss after epoch 211: 37180.0\n",
            "Loss after epoch 212: 36521.0\n",
            "Loss after epoch 213: 36259.0\n",
            "Loss after epoch 214: 37404.0\n",
            "Loss after epoch 215: 36593.0\n",
            "Loss after epoch 216: 37211.0\n",
            "Loss after epoch 217: 36896.0\n",
            "Loss after epoch 218: 37123.0\n",
            "Loss after epoch 219: 37026.0\n",
            "Loss after epoch 220: 36749.0\n",
            "Loss after epoch 221: 36832.0\n",
            "Loss after epoch 222: 36995.0\n",
            "Loss after epoch 223: 37053.0\n",
            "Loss after epoch 224: 36702.0\n",
            "Loss after epoch 225: 37215.0\n",
            "Loss after epoch 226: 36529.0\n",
            "Loss after epoch 227: 36503.0\n",
            "Loss after epoch 228: 36634.0\n",
            "Loss after epoch 229: 36662.0\n",
            "Loss after epoch 230: 36402.0\n",
            "Loss after epoch 231: 37232.0\n",
            "Loss after epoch 232: 36562.0\n",
            "Loss after epoch 233: 36874.0\n",
            "Loss after epoch 234: 36305.0\n",
            "Loss after epoch 235: 35724.0\n",
            "Loss after epoch 236: 36545.0\n",
            "Loss after epoch 237: 36686.0\n",
            "Loss after epoch 238: 36891.0\n",
            "Loss after epoch 239: 37356.0\n",
            "Loss after epoch 240: 37217.0\n",
            "Loss after epoch 241: 37136.0\n",
            "Loss after epoch 242: 36414.0\n",
            "Loss after epoch 243: 36689.0\n",
            "Loss after epoch 244: 36142.0\n",
            "Loss after epoch 245: 37367.0\n",
            "Loss after epoch 246: 36965.0\n",
            "Loss after epoch 247: 36175.0\n",
            "Loss after epoch 248: 37055.0\n",
            "Loss after epoch 249: 36409.0\n",
            "Loss after epoch 250: 37442.0\n",
            "Loss after epoch 251: 35939.0\n",
            "Loss after epoch 252: 36628.0\n",
            "Loss after epoch 253: 36700.0\n",
            "Loss after epoch 254: 36690.0\n",
            "Loss after epoch 255: 37036.0\n",
            "Loss after epoch 256: 36351.0\n",
            "Loss after epoch 257: 36652.0\n",
            "Loss after epoch 258: 36345.0\n",
            "Loss after epoch 259: 37315.0\n",
            "Loss after epoch 260: 37081.0\n",
            "Loss after epoch 261: 36487.0\n",
            "Loss after epoch 262: 36463.0\n",
            "Loss after epoch 263: 36724.0\n",
            "Loss after epoch 264: 36877.0\n",
            "Loss after epoch 265: 36310.0\n",
            "Loss after epoch 266: 37182.0\n",
            "Loss after epoch 267: 36686.0\n",
            "Loss after epoch 268: 36505.0\n",
            "Loss after epoch 269: 37071.0\n",
            "Loss after epoch 270: 36756.0\n",
            "Loss after epoch 271: 37308.0\n",
            "Loss after epoch 272: 36735.0\n",
            "Loss after epoch 273: 36289.0\n",
            "Loss after epoch 274: 36486.0\n",
            "Loss after epoch 275: 36648.0\n",
            "Loss after epoch 276: 37253.0\n",
            "Loss after epoch 277: 37043.0\n",
            "Loss after epoch 278: 36603.0\n",
            "Loss after epoch 279: 36899.0\n",
            "Loss after epoch 280: 36266.0\n",
            "Loss after epoch 281: 36634.0\n",
            "Loss after epoch 282: 36958.0\n",
            "Loss after epoch 283: 37099.0\n",
            "Loss after epoch 284: 36399.0\n",
            "Loss after epoch 285: 36300.0\n",
            "Loss after epoch 286: 36239.0\n",
            "Loss after epoch 287: 36759.0\n",
            "Loss after epoch 288: 36553.0\n",
            "Loss after epoch 289: 36787.0\n",
            "Loss after epoch 290: 37061.0\n",
            "Loss after epoch 291: 36743.0\n",
            "Loss after epoch 292: 36921.0\n",
            "Loss after epoch 293: 37044.0\n",
            "Loss after epoch 294: 36760.0\n",
            "Loss after epoch 295: 36356.0\n",
            "Loss after epoch 296: 36830.0\n",
            "Loss after epoch 297: 36332.0\n",
            "Loss after epoch 298: 37028.0\n",
            "Loss after epoch 299: 36794.0\n",
            "Loss after epoch 300: 36618.0\n",
            "Loss after epoch 301: 36558.0\n",
            "Loss after epoch 302: 36489.0\n",
            "Loss after epoch 303: 36805.0\n",
            "Loss after epoch 304: 36786.0\n",
            "Loss after epoch 305: 37575.0\n",
            "Loss after epoch 306: 36912.0\n",
            "Loss after epoch 307: 36666.0\n",
            "Loss after epoch 308: 36280.0\n",
            "Loss after epoch 309: 36836.0\n",
            "Loss after epoch 310: 36416.0\n",
            "Loss after epoch 311: 36483.0\n",
            "Loss after epoch 312: 36748.0\n",
            "Loss after epoch 313: 36784.0\n",
            "Loss after epoch 314: 36443.0\n",
            "Loss after epoch 315: 37644.0\n",
            "Loss after epoch 316: 36849.0\n",
            "Loss after epoch 317: 36050.0\n",
            "Loss after epoch 318: 36585.0\n",
            "Loss after epoch 319: 36345.0\n",
            "Loss after epoch 320: 37192.0\n",
            "Loss after epoch 321: 36616.0\n",
            "Loss after epoch 322: 37021.0\n",
            "Loss after epoch 323: 36500.0\n",
            "Loss after epoch 324: 36616.0\n",
            "Loss after epoch 325: 36950.0\n",
            "Loss after epoch 326: 36185.0\n",
            "Loss after epoch 327: 36924.0\n",
            "Loss after epoch 328: 36842.0\n",
            "Loss after epoch 329: 36435.0\n",
            "Loss after epoch 330: 36689.0\n",
            "Loss after epoch 331: 37120.0\n",
            "Loss after epoch 332: 36712.0\n",
            "Loss after epoch 333: 36748.0\n",
            "Loss after epoch 334: 36521.0\n",
            "Loss after epoch 335: 37086.0\n",
            "Loss after epoch 336: 37187.0\n",
            "Loss after epoch 337: 37110.0\n",
            "Loss after epoch 338: 36439.0\n",
            "Loss after epoch 339: 37384.0\n",
            "Loss after epoch 340: 36364.0\n",
            "Loss after epoch 341: 36134.0\n",
            "Loss after epoch 342: 36645.0\n",
            "Loss after epoch 343: 36436.0\n",
            "Loss after epoch 344: 36943.0\n",
            "Loss after epoch 345: 37678.0\n",
            "Loss after epoch 346: 37668.0\n",
            "Loss after epoch 347: 36670.0\n",
            "Loss after epoch 348: 36905.0\n",
            "Loss after epoch 349: 37157.0\n",
            "Loss after epoch 350: 37013.0\n",
            "Loss after epoch 351: 37359.0\n",
            "Loss after epoch 352: 36358.0\n",
            "Loss after epoch 353: 36516.0\n",
            "Loss after epoch 354: 36612.0\n",
            "Loss after epoch 355: 36630.0\n",
            "Loss after epoch 356: 37439.0\n",
            "Loss after epoch 357: 37538.0\n",
            "Loss after epoch 358: 36971.0\n",
            "Loss after epoch 359: 36664.0\n",
            "Loss after epoch 360: 36663.0\n",
            "Loss after epoch 361: 37066.0\n",
            "Loss after epoch 362: 36811.0\n",
            "Loss after epoch 363: 36613.0\n",
            "Loss after epoch 364: 36870.0\n",
            "Loss after epoch 365: 36824.0\n",
            "Loss after epoch 366: 36805.0\n",
            "Loss after epoch 367: 36973.0\n",
            "Loss after epoch 368: 36852.0\n",
            "Loss after epoch 369: 36289.0\n",
            "Loss after epoch 370: 37799.0\n",
            "Loss after epoch 371: 36541.0\n",
            "Loss after epoch 372: 36884.0\n",
            "Loss after epoch 373: 36449.0\n",
            "Loss after epoch 374: 36892.0\n",
            "Loss after epoch 375: 37570.0\n",
            "Loss after epoch 376: 37214.0\n",
            "Loss after epoch 377: 36858.0\n",
            "Loss after epoch 378: 36208.0\n",
            "Loss after epoch 379: 37059.0\n",
            "Loss after epoch 380: 36715.0\n",
            "Loss after epoch 381: 37066.0\n",
            "Loss after epoch 382: 36994.0\n",
            "Loss after epoch 383: 36572.0\n",
            "Loss after epoch 384: 37083.0\n",
            "Loss after epoch 385: 37140.0\n",
            "Loss after epoch 386: 36587.0\n",
            "Loss after epoch 387: 37435.0\n",
            "Loss after epoch 388: 37141.0\n",
            "Loss after epoch 389: 37360.0\n",
            "Loss after epoch 390: 36376.0\n",
            "Loss after epoch 391: 36534.0\n",
            "Loss after epoch 392: 36408.0\n",
            "Loss after epoch 393: 36332.0\n",
            "Loss after epoch 394: 37146.0\n",
            "Loss after epoch 395: 36398.0\n",
            "Loss after epoch 396: 36841.0\n",
            "Loss after epoch 397: 37468.0\n",
            "Loss after epoch 398: 35862.0\n",
            "Loss after epoch 399: 37037.0\n",
            "Loss after epoch 400: 37370.0\n",
            "Loss after epoch 401: 36639.0\n",
            "Loss after epoch 402: 36898.0\n",
            "Loss after epoch 403: 37009.0\n",
            "Loss after epoch 404: 37272.0\n",
            "Loss after epoch 405: 36635.0\n",
            "Loss after epoch 406: 36472.0\n",
            "Loss after epoch 407: 36548.0\n",
            "Loss after epoch 408: 36253.0\n",
            "Loss after epoch 409: 36720.0\n",
            "Loss after epoch 410: 36642.0\n",
            "Loss after epoch 411: 36344.0\n",
            "Loss after epoch 412: 36672.0\n",
            "Loss after epoch 413: 36458.0\n",
            "Loss after epoch 414: 36742.0\n",
            "Loss after epoch 415: 36405.0\n",
            "Loss after epoch 416: 37832.0\n",
            "Loss after epoch 417: 36997.0\n",
            "Loss after epoch 418: 34513.0\n",
            "Loss after epoch 419: 32436.0\n",
            "Loss after epoch 420: 32280.0\n",
            "Loss after epoch 421: 32602.0\n",
            "Loss after epoch 422: 32256.0\n",
            "Loss after epoch 423: 32832.0\n",
            "Loss after epoch 424: 32226.0\n",
            "Loss after epoch 425: 32390.0\n",
            "Loss after epoch 426: 32236.0\n",
            "Loss after epoch 427: 32056.0\n",
            "Loss after epoch 428: 32648.0\n",
            "Loss after epoch 429: 32190.0\n",
            "Loss after epoch 430: 32508.0\n",
            "Loss after epoch 431: 32158.0\n",
            "Loss after epoch 432: 32390.0\n",
            "Loss after epoch 433: 32640.0\n",
            "Loss after epoch 434: 32332.0\n",
            "Loss after epoch 435: 32530.0\n",
            "Loss after epoch 436: 32582.0\n",
            "Loss after epoch 437: 31844.0\n",
            "Loss after epoch 438: 32292.0\n",
            "Loss after epoch 439: 32542.0\n",
            "Loss after epoch 440: 33174.0\n",
            "Loss after epoch 441: 31972.0\n",
            "Loss after epoch 442: 32596.0\n",
            "Loss after epoch 443: 32578.0\n",
            "Loss after epoch 444: 32822.0\n",
            "Loss after epoch 445: 32168.0\n",
            "Loss after epoch 446: 31432.0\n",
            "Loss after epoch 447: 32234.0\n",
            "Loss after epoch 448: 32152.0\n",
            "Loss after epoch 449: 32198.0\n",
            "Loss after epoch 450: 32526.0\n",
            "Loss after epoch 451: 32488.0\n",
            "Loss after epoch 452: 31724.0\n",
            "Loss after epoch 453: 32220.0\n",
            "Loss after epoch 454: 32070.0\n",
            "Loss after epoch 455: 32756.0\n",
            "Loss after epoch 456: 32454.0\n",
            "Loss after epoch 457: 32518.0\n",
            "Loss after epoch 458: 31948.0\n",
            "Loss after epoch 459: 32300.0\n",
            "Loss after epoch 460: 32704.0\n",
            "Loss after epoch 461: 33162.0\n",
            "Loss after epoch 462: 33080.0\n",
            "Loss after epoch 463: 32248.0\n",
            "Loss after epoch 464: 32110.0\n",
            "Loss after epoch 465: 32830.0\n",
            "Loss after epoch 466: 32366.0\n",
            "Loss after epoch 467: 32412.0\n",
            "Loss after epoch 468: 32102.0\n",
            "Loss after epoch 469: 32292.0\n",
            "Loss after epoch 470: 32834.0\n",
            "Loss after epoch 471: 32218.0\n",
            "Loss after epoch 472: 32978.0\n",
            "Loss after epoch 473: 31838.0\n",
            "Loss after epoch 474: 32082.0\n",
            "Loss after epoch 475: 32136.0\n",
            "Loss after epoch 476: 32976.0\n",
            "Loss after epoch 477: 32468.0\n",
            "Loss after epoch 478: 32870.0\n",
            "Loss after epoch 479: 32416.0\n",
            "Loss after epoch 480: 32242.0\n",
            "Loss after epoch 481: 32616.0\n",
            "Loss after epoch 482: 32694.0\n",
            "Loss after epoch 483: 32414.0\n",
            "Loss after epoch 484: 32116.0\n",
            "Loss after epoch 485: 32130.0\n",
            "Loss after epoch 486: 32566.0\n",
            "Loss after epoch 487: 32048.0\n",
            "Loss after epoch 488: 32396.0\n",
            "Loss after epoch 489: 32924.0\n",
            "Loss after epoch 490: 32486.0\n",
            "Loss after epoch 491: 32624.0\n",
            "Loss after epoch 492: 32232.0\n",
            "Loss after epoch 493: 32028.0\n",
            "Loss after epoch 494: 31484.0\n",
            "Loss after epoch 495: 32008.0\n",
            "Loss after epoch 496: 32210.0\n",
            "Loss after epoch 497: 32274.0\n",
            "Loss after epoch 498: 32342.0\n",
            "Loss after epoch 499: 32052.0\n",
            "Loss after epoch 500: 32390.0\n",
            "Loss after epoch 501: 32098.0\n",
            "Loss after epoch 502: 32468.0\n",
            "Loss after epoch 503: 32264.0\n",
            "Loss after epoch 504: 32032.0\n",
            "Loss after epoch 505: 31930.0\n",
            "Loss after epoch 506: 32062.0\n",
            "Loss after epoch 507: 32324.0\n",
            "Loss after epoch 508: 32594.0\n",
            "Loss after epoch 509: 31536.0\n",
            "Loss after epoch 510: 32240.0\n",
            "Loss after epoch 511: 31806.0\n",
            "Loss after epoch 512: 32386.0\n",
            "Loss after epoch 513: 32370.0\n",
            "Loss after epoch 514: 32816.0\n",
            "Loss after epoch 515: 32178.0\n",
            "Loss after epoch 516: 33172.0\n",
            "Loss after epoch 517: 32868.0\n",
            "Loss after epoch 518: 32022.0\n",
            "Loss after epoch 519: 32056.0\n",
            "Loss after epoch 520: 32388.0\n",
            "Loss after epoch 521: 31936.0\n",
            "Loss after epoch 522: 31966.0\n",
            "Loss after epoch 523: 31924.0\n",
            "Loss after epoch 524: 32578.0\n",
            "Loss after epoch 525: 32140.0\n",
            "Loss after epoch 526: 32790.0\n",
            "Loss after epoch 527: 32502.0\n",
            "Loss after epoch 528: 32314.0\n",
            "Loss after epoch 529: 32290.0\n",
            "Loss after epoch 530: 32744.0\n",
            "Loss after epoch 531: 32248.0\n",
            "Loss after epoch 532: 32560.0\n",
            "Loss after epoch 533: 31880.0\n",
            "Loss after epoch 534: 32098.0\n",
            "Loss after epoch 535: 32870.0\n",
            "Loss after epoch 536: 32276.0\n",
            "Loss after epoch 537: 32016.0\n",
            "Loss after epoch 538: 31238.0\n",
            "Loss after epoch 539: 32758.0\n",
            "Loss after epoch 540: 32500.0\n",
            "Loss after epoch 541: 32504.0\n",
            "Loss after epoch 542: 32466.0\n",
            "Loss after epoch 543: 32608.0\n",
            "Loss after epoch 544: 32160.0\n",
            "Loss after epoch 545: 33128.0\n",
            "Loss after epoch 546: 32670.0\n",
            "Loss after epoch 547: 32810.0\n",
            "Loss after epoch 548: 32174.0\n",
            "Loss after epoch 549: 32338.0\n",
            "Loss after epoch 550: 32832.0\n",
            "Loss after epoch 551: 32454.0\n",
            "Loss after epoch 552: 32082.0\n",
            "Loss after epoch 553: 32140.0\n",
            "Loss after epoch 554: 32626.0\n",
            "Loss after epoch 555: 32482.0\n",
            "Loss after epoch 556: 31824.0\n",
            "Loss after epoch 557: 32806.0\n",
            "Loss after epoch 558: 32604.0\n",
            "Loss after epoch 559: 32214.0\n",
            "Loss after epoch 560: 32428.0\n",
            "Loss after epoch 561: 32308.0\n",
            "Loss after epoch 562: 31966.0\n",
            "Loss after epoch 563: 32866.0\n",
            "Loss after epoch 564: 32062.0\n",
            "Loss after epoch 565: 32482.0\n",
            "Loss after epoch 566: 32092.0\n",
            "Loss after epoch 567: 31768.0\n",
            "Loss after epoch 568: 32462.0\n",
            "Loss after epoch 569: 32590.0\n",
            "Loss after epoch 570: 32146.0\n",
            "Loss after epoch 571: 31904.0\n",
            "Loss after epoch 572: 32028.0\n",
            "Loss after epoch 573: 32308.0\n",
            "Loss after epoch 574: 31982.0\n",
            "Loss after epoch 575: 31702.0\n",
            "Loss after epoch 576: 32278.0\n",
            "Loss after epoch 577: 32128.0\n",
            "Loss after epoch 578: 32872.0\n",
            "Loss after epoch 579: 31946.0\n",
            "Loss after epoch 580: 32636.0\n",
            "Loss after epoch 581: 32250.0\n",
            "Loss after epoch 582: 32326.0\n",
            "Loss after epoch 583: 33012.0\n",
            "Loss after epoch 584: 32236.0\n",
            "Loss after epoch 585: 32352.0\n",
            "Loss after epoch 586: 32442.0\n",
            "Loss after epoch 587: 32382.0\n",
            "Loss after epoch 588: 31822.0\n",
            "Loss after epoch 589: 31640.0\n",
            "Loss after epoch 590: 32658.0\n",
            "Loss after epoch 591: 32390.0\n",
            "Loss after epoch 592: 32196.0\n",
            "Loss after epoch 593: 32186.0\n",
            "Loss after epoch 594: 32084.0\n",
            "Loss after epoch 595: 31910.0\n",
            "Loss after epoch 596: 32672.0\n",
            "Loss after epoch 597: 33022.0\n",
            "Loss after epoch 598: 32162.0\n",
            "Loss after epoch 599: 32614.0\n",
            "Loss after epoch 600: 31812.0\n",
            "Loss after epoch 601: 32044.0\n",
            "Loss after epoch 602: 32546.0\n",
            "Loss after epoch 603: 32510.0\n",
            "Loss after epoch 604: 32132.0\n",
            "Loss after epoch 605: 32042.0\n",
            "Loss after epoch 606: 31888.0\n",
            "Loss after epoch 607: 32204.0\n",
            "Loss after epoch 608: 32308.0\n",
            "Loss after epoch 609: 31840.0\n",
            "Loss after epoch 610: 32246.0\n",
            "Loss after epoch 611: 32454.0\n",
            "Loss after epoch 612: 32560.0\n",
            "Loss after epoch 613: 32804.0\n",
            "Loss after epoch 614: 32256.0\n",
            "Loss after epoch 615: 31776.0\n",
            "Loss after epoch 616: 31770.0\n",
            "Loss after epoch 617: 32384.0\n",
            "Loss after epoch 618: 32970.0\n",
            "Loss after epoch 619: 32750.0\n",
            "Loss after epoch 620: 32748.0\n",
            "Loss after epoch 621: 32180.0\n",
            "Loss after epoch 622: 32574.0\n",
            "Loss after epoch 623: 32722.0\n",
            "Loss after epoch 624: 31754.0\n",
            "Loss after epoch 625: 32444.0\n",
            "Loss after epoch 626: 31890.0\n",
            "Loss after epoch 627: 31972.0\n",
            "Loss after epoch 628: 32474.0\n",
            "Loss after epoch 629: 32002.0\n",
            "Loss after epoch 630: 32250.0\n",
            "Loss after epoch 631: 32462.0\n",
            "Loss after epoch 632: 32052.0\n",
            "Loss after epoch 633: 32076.0\n",
            "Loss after epoch 634: 31504.0\n",
            "Loss after epoch 635: 31514.0\n",
            "Loss after epoch 636: 32066.0\n",
            "Loss after epoch 637: 32162.0\n",
            "Loss after epoch 638: 32090.0\n",
            "Loss after epoch 639: 32304.0\n",
            "Loss after epoch 640: 32044.0\n",
            "Loss after epoch 641: 32290.0\n",
            "Loss after epoch 642: 31536.0\n",
            "Loss after epoch 643: 31602.0\n",
            "Loss after epoch 644: 32316.0\n",
            "Loss after epoch 645: 32214.0\n",
            "Loss after epoch 646: 32102.0\n",
            "Loss after epoch 647: 31666.0\n",
            "Loss after epoch 648: 32336.0\n",
            "Loss after epoch 649: 32610.0\n",
            "Loss after epoch 650: 32572.0\n",
            "Loss after epoch 651: 32248.0\n",
            "Loss after epoch 652: 31896.0\n",
            "Loss after epoch 653: 32350.0\n",
            "Loss after epoch 654: 32620.0\n",
            "Loss after epoch 655: 31972.0\n",
            "Loss after epoch 656: 32692.0\n",
            "Loss after epoch 657: 32846.0\n",
            "Loss after epoch 658: 32480.0\n",
            "Loss after epoch 659: 31622.0\n",
            "Loss after epoch 660: 32296.0\n",
            "Loss after epoch 661: 31944.0\n",
            "Loss after epoch 662: 32274.0\n",
            "Loss after epoch 663: 32398.0\n",
            "Loss after epoch 664: 31408.0\n",
            "Loss after epoch 665: 32242.0\n",
            "Loss after epoch 666: 32342.0\n",
            "Loss after epoch 667: 32204.0\n",
            "Loss after epoch 668: 32302.0\n",
            "Loss after epoch 669: 31642.0\n",
            "Loss after epoch 670: 32436.0\n",
            "Loss after epoch 671: 32730.0\n",
            "Loss after epoch 672: 31974.0\n",
            "Loss after epoch 673: 32030.0\n",
            "Loss after epoch 674: 32242.0\n",
            "Loss after epoch 675: 32412.0\n",
            "Loss after epoch 676: 32756.0\n",
            "Loss after epoch 677: 32322.0\n",
            "Loss after epoch 678: 31884.0\n",
            "Loss after epoch 679: 32212.0\n",
            "Loss after epoch 680: 31792.0\n",
            "Loss after epoch 681: 32196.0\n",
            "Loss after epoch 682: 31996.0\n",
            "Loss after epoch 683: 32256.0\n",
            "Loss after epoch 684: 31816.0\n",
            "Loss after epoch 685: 31924.0\n",
            "Loss after epoch 686: 32316.0\n",
            "Loss after epoch 687: 31690.0\n",
            "Loss after epoch 688: 32786.0\n",
            "Loss after epoch 689: 32554.0\n",
            "Loss after epoch 690: 31866.0\n",
            "Loss after epoch 691: 32718.0\n",
            "Loss after epoch 692: 32454.0\n",
            "Loss after epoch 693: 31416.0\n",
            "Loss after epoch 694: 32014.0\n",
            "Loss after epoch 695: 32196.0\n",
            "Loss after epoch 696: 32196.0\n",
            "Loss after epoch 697: 32422.0\n",
            "Loss after epoch 698: 32282.0\n",
            "Loss after epoch 699: 31832.0\n",
            "Loss after epoch 700: 32326.0\n",
            "Loss after epoch 701: 31832.0\n",
            "Loss after epoch 702: 32024.0\n",
            "Loss after epoch 703: 32046.0\n",
            "Loss after epoch 704: 31996.0\n",
            "Loss after epoch 705: 32164.0\n",
            "Loss after epoch 706: 32562.0\n",
            "Loss after epoch 707: 32568.0\n",
            "Loss after epoch 708: 32224.0\n",
            "Loss after epoch 709: 32002.0\n",
            "Loss after epoch 710: 32034.0\n",
            "Loss after epoch 711: 32446.0\n",
            "Loss after epoch 712: 32186.0\n",
            "Loss after epoch 713: 32048.0\n",
            "Loss after epoch 714: 32814.0\n",
            "Loss after epoch 715: 32248.0\n",
            "Loss after epoch 716: 31882.0\n",
            "Loss after epoch 717: 31556.0\n",
            "Loss after epoch 718: 32286.0\n",
            "Loss after epoch 719: 32460.0\n",
            "Loss after epoch 720: 31990.0\n",
            "Loss after epoch 721: 31888.0\n",
            "Loss after epoch 722: 31606.0\n",
            "Loss after epoch 723: 32106.0\n",
            "Loss after epoch 724: 32628.0\n",
            "Loss after epoch 725: 32188.0\n",
            "Loss after epoch 726: 31722.0\n",
            "Loss after epoch 727: 32136.0\n",
            "Loss after epoch 728: 32006.0\n",
            "Loss after epoch 729: 32216.0\n",
            "Loss after epoch 730: 32012.0\n",
            "Loss after epoch 731: 32244.0\n",
            "Loss after epoch 732: 32716.0\n",
            "Loss after epoch 733: 32372.0\n",
            "Loss after epoch 734: 32158.0\n",
            "Loss after epoch 735: 32396.0\n",
            "Loss after epoch 736: 32296.0\n",
            "Loss after epoch 737: 32356.0\n",
            "Loss after epoch 738: 32052.0\n",
            "Loss after epoch 739: 32222.0\n",
            "Loss after epoch 740: 32264.0\n",
            "Loss after epoch 741: 31880.0\n",
            "Loss after epoch 742: 31886.0\n",
            "Loss after epoch 743: 32462.0\n",
            "Loss after epoch 744: 32470.0\n",
            "Loss after epoch 745: 32332.0\n",
            "Loss after epoch 746: 31770.0\n",
            "Loss after epoch 747: 31630.0\n",
            "Loss after epoch 748: 32438.0\n",
            "Loss after epoch 749: 31998.0\n",
            "Loss after epoch 750: 32586.0\n",
            "Loss after epoch 751: 31694.0\n",
            "Loss after epoch 752: 32014.0\n",
            "Loss after epoch 753: 31732.0\n",
            "Loss after epoch 754: 32540.0\n",
            "Loss after epoch 755: 31956.0\n",
            "Loss after epoch 756: 32092.0\n",
            "Loss after epoch 757: 32952.0\n",
            "Loss after epoch 758: 32014.0\n",
            "Loss after epoch 759: 32106.0\n",
            "Loss after epoch 760: 31494.0\n",
            "Loss after epoch 761: 31608.0\n",
            "Loss after epoch 762: 32616.0\n",
            "Loss after epoch 763: 32536.0\n",
            "Loss after epoch 764: 32132.0\n",
            "Loss after epoch 765: 32100.0\n",
            "Loss after epoch 766: 32030.0\n",
            "Loss after epoch 767: 31790.0\n",
            "Loss after epoch 768: 32026.0\n",
            "Loss after epoch 769: 31974.0\n",
            "Loss after epoch 770: 32428.0\n",
            "Loss after epoch 771: 32416.0\n",
            "Loss after epoch 772: 32372.0\n",
            "Loss after epoch 773: 32448.0\n",
            "Loss after epoch 774: 32434.0\n",
            "Loss after epoch 775: 32464.0\n",
            "Loss after epoch 776: 31704.0\n",
            "Loss after epoch 777: 32624.0\n",
            "Loss after epoch 778: 31360.0\n",
            "Loss after epoch 779: 32474.0\n",
            "Loss after epoch 780: 31964.0\n",
            "Loss after epoch 781: 32038.0\n",
            "Loss after epoch 782: 31910.0\n",
            "Loss after epoch 783: 31508.0\n",
            "Loss after epoch 784: 31862.0\n",
            "Loss after epoch 785: 32306.0\n",
            "Loss after epoch 786: 32232.0\n",
            "Loss after epoch 787: 32366.0\n",
            "Loss after epoch 788: 31850.0\n",
            "Loss after epoch 789: 32288.0\n",
            "Loss after epoch 790: 32330.0\n",
            "Loss after epoch 791: 31558.0\n",
            "Loss after epoch 792: 32022.0\n",
            "Loss after epoch 793: 32580.0\n",
            "Loss after epoch 794: 31870.0\n",
            "Loss after epoch 795: 31898.0\n",
            "Loss after epoch 796: 32330.0\n",
            "Loss after epoch 797: 32330.0\n",
            "Loss after epoch 798: 32014.0\n",
            "Loss after epoch 799: 31888.0\n",
            "Loss after epoch 800: 32854.0\n",
            "Loss after epoch 801: 32046.0\n",
            "Loss after epoch 802: 32004.0\n",
            "Loss after epoch 803: 32260.0\n",
            "Loss after epoch 804: 32022.0\n",
            "Loss after epoch 805: 31902.0\n",
            "Loss after epoch 806: 32638.0\n",
            "Loss after epoch 807: 31806.0\n",
            "Loss after epoch 808: 32126.0\n",
            "Loss after epoch 809: 32572.0\n",
            "Loss after epoch 810: 31944.0\n",
            "Loss after epoch 811: 32080.0\n",
            "Loss after epoch 812: 31944.0\n",
            "Loss after epoch 813: 32250.0\n",
            "Loss after epoch 814: 32528.0\n",
            "Loss after epoch 815: 32238.0\n",
            "Loss after epoch 816: 32278.0\n",
            "Loss after epoch 817: 31480.0\n",
            "Loss after epoch 818: 31834.0\n",
            "Loss after epoch 819: 32266.0\n",
            "Loss after epoch 820: 32158.0\n",
            "Loss after epoch 821: 31826.0\n",
            "Loss after epoch 822: 32348.0\n",
            "Loss after epoch 823: 32596.0\n",
            "Loss after epoch 824: 31738.0\n",
            "Loss after epoch 825: 32696.0\n",
            "Loss after epoch 826: 31654.0\n",
            "Loss after epoch 827: 31638.0\n",
            "Loss after epoch 828: 31860.0\n",
            "Loss after epoch 829: 32530.0\n",
            "Loss after epoch 830: 31854.0\n",
            "Loss after epoch 831: 32082.0\n",
            "Loss after epoch 832: 32136.0\n",
            "Loss after epoch 833: 32838.0\n",
            "Loss after epoch 834: 31598.0\n",
            "Loss after epoch 835: 32128.0\n",
            "Loss after epoch 836: 32182.0\n",
            "Loss after epoch 837: 32620.0\n",
            "Loss after epoch 838: 31940.0\n",
            "Loss after epoch 839: 32076.0\n",
            "Loss after epoch 840: 32044.0\n",
            "Loss after epoch 841: 32340.0\n",
            "Loss after epoch 842: 31930.0\n",
            "Loss after epoch 843: 31974.0\n",
            "Loss after epoch 844: 32230.0\n",
            "Loss after epoch 845: 31478.0\n",
            "Loss after epoch 846: 32102.0\n",
            "Loss after epoch 847: 32874.0\n",
            "Loss after epoch 848: 32086.0\n",
            "Loss after epoch 849: 32622.0\n",
            "Loss after epoch 850: 32496.0\n",
            "Loss after epoch 851: 31718.0\n",
            "Loss after epoch 852: 32438.0\n",
            "Loss after epoch 853: 32290.0\n",
            "Loss after epoch 854: 32252.0\n",
            "Loss after epoch 855: 31878.0\n",
            "Loss after epoch 856: 31582.0\n",
            "Loss after epoch 857: 32028.0\n",
            "Loss after epoch 858: 32626.0\n",
            "Loss after epoch 859: 31718.0\n",
            "Loss after epoch 860: 31820.0\n",
            "Loss after epoch 861: 32326.0\n",
            "Loss after epoch 862: 32476.0\n",
            "Loss after epoch 863: 31450.0\n",
            "Loss after epoch 864: 32328.0\n",
            "Loss after epoch 865: 32800.0\n",
            "Loss after epoch 866: 33046.0\n",
            "Loss after epoch 867: 31524.0\n",
            "Loss after epoch 868: 32290.0\n",
            "Loss after epoch 869: 31712.0\n",
            "Loss after epoch 870: 31306.0\n",
            "Loss after epoch 871: 32140.0\n",
            "Loss after epoch 872: 31382.0\n",
            "Loss after epoch 873: 32062.0\n",
            "Loss after epoch 874: 31586.0\n",
            "Loss after epoch 875: 32256.0\n",
            "Loss after epoch 876: 31724.0\n",
            "Loss after epoch 877: 31676.0\n",
            "Loss after epoch 878: 32540.0\n",
            "Loss after epoch 879: 32682.0\n",
            "Loss after epoch 880: 31154.0\n",
            "Loss after epoch 881: 31932.0\n",
            "Loss after epoch 882: 31958.0\n",
            "Loss after epoch 883: 31906.0\n",
            "Loss after epoch 884: 31820.0\n",
            "Loss after epoch 885: 31758.0\n",
            "Loss after epoch 886: 31998.0\n",
            "Loss after epoch 887: 31992.0\n",
            "Loss after epoch 888: 32286.0\n",
            "Loss after epoch 889: 32596.0\n",
            "Loss after epoch 890: 32428.0\n",
            "Loss after epoch 891: 31520.0\n",
            "Loss after epoch 892: 31440.0\n",
            "Loss after epoch 893: 32028.0\n",
            "Loss after epoch 894: 31734.0\n",
            "Loss after epoch 895: 31522.0\n",
            "Loss after epoch 896: 32360.0\n",
            "Loss after epoch 897: 31782.0\n",
            "Loss after epoch 898: 32122.0\n",
            "Loss after epoch 899: 31962.0\n",
            "Loss after epoch 900: 32118.0\n",
            "Loss after epoch 901: 32104.0\n",
            "Loss after epoch 902: 33414.0\n",
            "Loss after epoch 903: 31676.0\n",
            "Loss after epoch 904: 31724.0\n",
            "Loss after epoch 905: 32962.0\n",
            "Loss after epoch 906: 31264.0\n",
            "Loss after epoch 907: 31548.0\n",
            "Loss after epoch 908: 32594.0\n",
            "Loss after epoch 909: 31208.0\n",
            "Loss after epoch 910: 32222.0\n",
            "Loss after epoch 911: 32406.0\n",
            "Loss after epoch 912: 31756.0\n",
            "Loss after epoch 913: 31696.0\n",
            "Loss after epoch 914: 32140.0\n",
            "Loss after epoch 915: 31726.0\n",
            "Loss after epoch 916: 31682.0\n",
            "Loss after epoch 917: 31850.0\n",
            "Loss after epoch 918: 31888.0\n",
            "Loss after epoch 919: 31862.0\n",
            "Loss after epoch 920: 32140.0\n",
            "Loss after epoch 921: 31636.0\n",
            "Loss after epoch 922: 32542.0\n",
            "Loss after epoch 923: 32406.0\n",
            "Loss after epoch 924: 31616.0\n",
            "Loss after epoch 925: 32122.0\n",
            "Loss after epoch 926: 31860.0\n",
            "Loss after epoch 927: 32544.0\n",
            "Loss after epoch 928: 31880.0\n",
            "Loss after epoch 929: 32088.0\n",
            "Loss after epoch 930: 31494.0\n",
            "Loss after epoch 931: 31950.0\n",
            "Loss after epoch 932: 31964.0\n",
            "Loss after epoch 933: 32636.0\n",
            "Loss after epoch 934: 31878.0\n",
            "Loss after epoch 935: 31914.0\n",
            "Loss after epoch 936: 31736.0\n",
            "Loss after epoch 937: 31706.0\n",
            "Loss after epoch 938: 31950.0\n",
            "Loss after epoch 939: 28254.0\n",
            "Loss after epoch 940: 25352.0\n",
            "Loss after epoch 941: 24952.0\n",
            "Loss after epoch 942: 24900.0\n",
            "Loss after epoch 943: 24764.0\n",
            "Loss after epoch 944: 24908.0\n",
            "Loss after epoch 945: 24656.0\n",
            "Loss after epoch 946: 25084.0\n",
            "Loss after epoch 947: 25516.0\n",
            "Loss after epoch 948: 24912.0\n",
            "Loss after epoch 949: 25480.0\n",
            "Loss after epoch 950: 25556.0\n",
            "Loss after epoch 951: 25344.0\n",
            "Loss after epoch 952: 26088.0\n",
            "Loss after epoch 953: 24616.0\n",
            "Loss after epoch 954: 24944.0\n",
            "Loss after epoch 955: 25148.0\n",
            "Loss after epoch 956: 25612.0\n",
            "Loss after epoch 957: 25768.0\n",
            "Loss after epoch 958: 25088.0\n",
            "Loss after epoch 959: 24984.0\n",
            "Loss after epoch 960: 25764.0\n",
            "Loss after epoch 961: 25148.0\n",
            "Loss after epoch 962: 25020.0\n",
            "Loss after epoch 963: 25040.0\n",
            "Loss after epoch 964: 24832.0\n",
            "Loss after epoch 965: 25324.0\n",
            "Loss after epoch 966: 25016.0\n",
            "Loss after epoch 967: 25272.0\n",
            "Loss after epoch 968: 24788.0\n",
            "Loss after epoch 969: 24964.0\n",
            "Loss after epoch 970: 25144.0\n",
            "Loss after epoch 971: 25632.0\n",
            "Loss after epoch 972: 24552.0\n",
            "Loss after epoch 973: 25568.0\n",
            "Loss after epoch 974: 25848.0\n",
            "Loss after epoch 975: 25036.0\n",
            "Loss after epoch 976: 25104.0\n",
            "Loss after epoch 977: 24940.0\n",
            "Loss after epoch 978: 24988.0\n",
            "Loss after epoch 979: 25608.0\n",
            "Loss after epoch 980: 24852.0\n",
            "Loss after epoch 981: 25296.0\n",
            "Loss after epoch 982: 25104.0\n",
            "Loss after epoch 983: 25824.0\n",
            "Loss after epoch 984: 24944.0\n",
            "Loss after epoch 985: 25380.0\n",
            "Loss after epoch 986: 25384.0\n",
            "Loss after epoch 987: 25832.0\n",
            "Loss after epoch 988: 25580.0\n",
            "Loss after epoch 989: 25680.0\n",
            "Loss after epoch 990: 25724.0\n",
            "Loss after epoch 991: 25108.0\n",
            "Loss after epoch 992: 25116.0\n",
            "Loss after epoch 993: 24716.0\n",
            "Loss after epoch 994: 25080.0\n",
            "Loss after epoch 995: 24996.0\n",
            "Loss after epoch 996: 25704.0\n",
            "Loss after epoch 997: 25464.0\n",
            "Loss after epoch 998: 25532.0\n",
            "Loss after epoch 999: 24796.0\n",
            "Loss after epoch 1000: 25072.0\n",
            "Loss after epoch 1001: 24960.0\n",
            "Loss after epoch 1002: 25380.0\n",
            "Loss after epoch 1003: 25368.0\n",
            "Loss after epoch 1004: 25080.0\n",
            "Loss after epoch 1005: 25088.0\n",
            "Loss after epoch 1006: 24352.0\n",
            "Loss after epoch 1007: 25092.0\n",
            "Loss after epoch 1008: 24680.0\n",
            "Loss after epoch 1009: 25072.0\n",
            "Loss after epoch 1010: 25624.0\n",
            "Loss after epoch 1011: 25316.0\n",
            "Loss after epoch 1012: 24796.0\n",
            "Loss after epoch 1013: 25124.0\n",
            "Loss after epoch 1014: 25204.0\n",
            "Loss after epoch 1015: 25588.0\n",
            "Loss after epoch 1016: 25668.0\n",
            "Loss after epoch 1017: 25356.0\n",
            "Loss after epoch 1018: 25296.0\n",
            "Loss after epoch 1019: 24852.0\n",
            "Loss after epoch 1020: 25640.0\n",
            "Loss after epoch 1021: 24980.0\n",
            "Loss after epoch 1022: 25196.0\n",
            "Loss after epoch 1023: 25176.0\n",
            "Loss after epoch 1024: 25392.0\n",
            "Loss after epoch 1025: 24660.0\n",
            "Loss after epoch 1026: 25524.0\n",
            "Loss after epoch 1027: 24892.0\n",
            "Loss after epoch 1028: 25724.0\n",
            "Loss after epoch 1029: 25408.0\n",
            "Loss after epoch 1030: 24836.0\n",
            "Loss after epoch 1031: 24896.0\n",
            "Loss after epoch 1032: 25236.0\n",
            "Loss after epoch 1033: 25480.0\n",
            "Loss after epoch 1034: 25560.0\n",
            "Loss after epoch 1035: 25080.0\n",
            "Loss after epoch 1036: 25212.0\n",
            "Loss after epoch 1037: 25056.0\n",
            "Loss after epoch 1038: 25152.0\n",
            "Loss after epoch 1039: 25200.0\n",
            "Loss after epoch 1040: 25492.0\n",
            "Loss after epoch 1041: 25796.0\n",
            "Loss after epoch 1042: 25320.0\n",
            "Loss after epoch 1043: 25264.0\n",
            "Loss after epoch 1044: 25416.0\n",
            "Loss after epoch 1045: 25768.0\n",
            "Loss after epoch 1046: 24704.0\n",
            "Loss after epoch 1047: 25312.0\n",
            "Loss after epoch 1048: 24780.0\n",
            "Loss after epoch 1049: 25588.0\n",
            "Loss after epoch 1050: 24776.0\n",
            "Loss after epoch 1051: 25496.0\n",
            "Loss after epoch 1052: 24928.0\n",
            "Loss after epoch 1053: 24600.0\n",
            "Loss after epoch 1054: 26000.0\n",
            "Loss after epoch 1055: 25768.0\n",
            "Loss after epoch 1056: 25288.0\n",
            "Loss after epoch 1057: 24892.0\n",
            "Loss after epoch 1058: 25052.0\n",
            "Loss after epoch 1059: 25536.0\n",
            "Loss after epoch 1060: 25048.0\n",
            "Loss after epoch 1061: 24668.0\n",
            "Loss after epoch 1062: 24792.0\n",
            "Loss after epoch 1063: 24840.0\n",
            "Loss after epoch 1064: 24820.0\n",
            "Loss after epoch 1065: 25980.0\n",
            "Loss after epoch 1066: 25156.0\n",
            "Loss after epoch 1067: 25236.0\n",
            "Loss after epoch 1068: 25548.0\n",
            "Loss after epoch 1069: 25672.0\n",
            "Loss after epoch 1070: 25008.0\n",
            "Loss after epoch 1071: 25208.0\n",
            "Loss after epoch 1072: 24236.0\n",
            "Loss after epoch 1073: 25260.0\n",
            "Loss after epoch 1074: 25140.0\n",
            "Loss after epoch 1075: 24556.0\n",
            "Loss after epoch 1076: 25176.0\n",
            "Loss after epoch 1077: 24508.0\n",
            "Loss after epoch 1078: 25544.0\n",
            "Loss after epoch 1079: 25888.0\n",
            "Loss after epoch 1080: 24812.0\n",
            "Loss after epoch 1081: 25436.0\n",
            "Loss after epoch 1082: 25220.0\n",
            "Loss after epoch 1083: 25428.0\n",
            "Loss after epoch 1084: 25356.0\n",
            "Loss after epoch 1085: 25100.0\n",
            "Loss after epoch 1086: 25248.0\n",
            "Loss after epoch 1087: 24488.0\n",
            "Loss after epoch 1088: 24864.0\n",
            "Loss after epoch 1089: 25152.0\n",
            "Loss after epoch 1090: 25252.0\n",
            "Loss after epoch 1091: 24948.0\n",
            "Loss after epoch 1092: 24384.0\n",
            "Loss after epoch 1093: 24780.0\n",
            "Loss after epoch 1094: 25036.0\n",
            "Loss after epoch 1095: 24608.0\n",
            "Loss after epoch 1096: 24640.0\n",
            "Loss after epoch 1097: 25196.0\n",
            "Loss after epoch 1098: 25240.0\n",
            "Loss after epoch 1099: 25336.0\n",
            "Loss after epoch 1100: 25280.0\n",
            "Loss after epoch 1101: 25912.0\n",
            "Loss after epoch 1102: 25400.0\n",
            "Loss after epoch 1103: 24296.0\n",
            "Loss after epoch 1104: 25000.0\n",
            "Loss after epoch 1105: 25280.0\n",
            "Loss after epoch 1106: 25020.0\n",
            "Loss after epoch 1107: 25064.0\n",
            "Loss after epoch 1108: 24748.0\n",
            "Loss after epoch 1109: 24848.0\n",
            "Loss after epoch 1110: 24992.0\n",
            "Loss after epoch 1111: 24992.0\n",
            "Loss after epoch 1112: 24912.0\n",
            "Loss after epoch 1113: 24736.0\n",
            "Loss after epoch 1114: 24900.0\n",
            "Loss after epoch 1115: 25220.0\n",
            "Loss after epoch 1116: 24764.0\n",
            "Loss after epoch 1117: 25468.0\n",
            "Loss after epoch 1118: 24520.0\n",
            "Loss after epoch 1119: 24916.0\n",
            "Loss after epoch 1120: 25064.0\n",
            "Loss after epoch 1121: 24684.0\n",
            "Loss after epoch 1122: 24812.0\n",
            "Loss after epoch 1123: 24340.0\n",
            "Loss after epoch 1124: 25324.0\n",
            "Loss after epoch 1125: 24388.0\n",
            "Loss after epoch 1126: 24812.0\n",
            "Loss after epoch 1127: 24436.0\n",
            "Loss after epoch 1128: 25148.0\n",
            "Loss after epoch 1129: 25140.0\n",
            "Loss after epoch 1130: 25304.0\n",
            "Loss after epoch 1131: 24968.0\n",
            "Loss after epoch 1132: 25304.0\n",
            "Loss after epoch 1133: 25044.0\n",
            "Loss after epoch 1134: 24516.0\n",
            "Loss after epoch 1135: 24788.0\n",
            "Loss after epoch 1136: 25256.0\n",
            "Loss after epoch 1137: 24996.0\n",
            "Loss after epoch 1138: 25216.0\n",
            "Loss after epoch 1139: 25104.0\n",
            "Loss after epoch 1140: 25576.0\n",
            "Loss after epoch 1141: 25028.0\n",
            "Loss after epoch 1142: 25576.0\n",
            "Loss after epoch 1143: 25144.0\n",
            "Loss after epoch 1144: 25456.0\n",
            "Loss after epoch 1145: 24892.0\n",
            "Loss after epoch 1146: 24408.0\n",
            "Loss after epoch 1147: 25184.0\n",
            "Loss after epoch 1148: 25200.0\n",
            "Loss after epoch 1149: 25248.0\n",
            "Loss after epoch 1150: 24636.0\n",
            "Loss after epoch 1151: 24976.0\n",
            "Loss after epoch 1152: 25260.0\n",
            "Loss after epoch 1153: 24980.0\n",
            "Loss after epoch 1154: 25092.0\n",
            "Loss after epoch 1155: 25236.0\n",
            "Loss after epoch 1156: 25072.0\n",
            "Loss after epoch 1157: 24296.0\n",
            "Loss after epoch 1158: 25072.0\n",
            "Loss after epoch 1159: 25836.0\n",
            "Loss after epoch 1160: 24496.0\n",
            "Loss after epoch 1161: 25352.0\n",
            "Loss after epoch 1162: 24912.0\n",
            "Loss after epoch 1163: 25672.0\n",
            "Loss after epoch 1164: 24712.0\n",
            "Loss after epoch 1165: 24928.0\n",
            "Loss after epoch 1166: 25772.0\n",
            "Loss after epoch 1167: 24900.0\n",
            "Loss after epoch 1168: 25072.0\n",
            "Loss after epoch 1169: 25028.0\n",
            "Loss after epoch 1170: 25352.0\n",
            "Loss after epoch 1171: 25640.0\n",
            "Loss after epoch 1172: 24688.0\n",
            "Loss after epoch 1173: 25284.0\n",
            "Loss after epoch 1174: 24800.0\n",
            "Loss after epoch 1175: 25192.0\n",
            "Loss after epoch 1176: 25620.0\n",
            "Loss after epoch 1177: 25232.0\n",
            "Loss after epoch 1178: 25216.0\n",
            "Loss after epoch 1179: 24740.0\n",
            "Loss after epoch 1180: 25028.0\n",
            "Loss after epoch 1181: 25148.0\n",
            "Loss after epoch 1182: 24208.0\n",
            "Loss after epoch 1183: 24700.0\n",
            "Loss after epoch 1184: 24712.0\n",
            "Loss after epoch 1185: 24764.0\n",
            "Loss after epoch 1186: 24744.0\n",
            "Loss after epoch 1187: 25036.0\n",
            "Loss after epoch 1188: 25100.0\n",
            "Loss after epoch 1189: 25056.0\n",
            "Loss after epoch 1190: 25496.0\n",
            "Loss after epoch 1191: 25436.0\n",
            "Loss after epoch 1192: 24380.0\n",
            "Loss after epoch 1193: 25216.0\n",
            "Loss after epoch 1194: 25184.0\n",
            "Loss after epoch 1195: 24256.0\n",
            "Loss after epoch 1196: 24904.0\n",
            "Loss after epoch 1197: 25116.0\n",
            "Loss after epoch 1198: 25360.0\n",
            "Loss after epoch 1199: 25336.0\n",
            "Loss after epoch 1200: 24816.0\n",
            "Loss after epoch 1201: 25040.0\n",
            "Loss after epoch 1202: 24904.0\n",
            "Loss after epoch 1203: 25348.0\n",
            "Loss after epoch 1204: 24808.0\n",
            "Loss after epoch 1205: 24628.0\n",
            "Loss after epoch 1206: 24060.0\n",
            "Loss after epoch 1207: 24212.0\n",
            "Loss after epoch 1208: 24704.0\n",
            "Loss after epoch 1209: 25376.0\n",
            "Loss after epoch 1210: 24340.0\n",
            "Loss after epoch 1211: 25120.0\n",
            "Loss after epoch 1212: 25344.0\n",
            "Loss after epoch 1213: 24268.0\n",
            "Loss after epoch 1214: 24820.0\n",
            "Loss after epoch 1215: 25348.0\n",
            "Loss after epoch 1216: 25136.0\n",
            "Loss after epoch 1217: 25392.0\n",
            "Loss after epoch 1218: 24840.0\n",
            "Loss after epoch 1219: 24856.0\n",
            "Loss after epoch 1220: 25456.0\n",
            "Loss after epoch 1221: 25032.0\n",
            "Loss after epoch 1222: 25308.0\n",
            "Loss after epoch 1223: 24832.0\n",
            "Loss after epoch 1224: 24688.0\n",
            "Loss after epoch 1225: 24812.0\n",
            "Loss after epoch 1226: 24812.0\n",
            "Loss after epoch 1227: 25052.0\n",
            "Loss after epoch 1228: 24744.0\n",
            "Loss after epoch 1229: 24344.0\n",
            "Loss after epoch 1230: 24724.0\n",
            "Loss after epoch 1231: 25000.0\n",
            "Loss after epoch 1232: 24348.0\n",
            "Loss after epoch 1233: 24836.0\n",
            "Loss after epoch 1234: 24804.0\n",
            "Loss after epoch 1235: 25112.0\n",
            "Loss after epoch 1236: 25088.0\n",
            "Loss after epoch 1237: 24936.0\n",
            "Loss after epoch 1238: 24392.0\n",
            "Loss after epoch 1239: 24744.0\n",
            "Loss after epoch 1240: 24784.0\n",
            "Loss after epoch 1241: 23828.0\n",
            "Loss after epoch 1242: 24748.0\n",
            "Loss after epoch 1243: 24616.0\n",
            "Loss after epoch 1244: 24776.0\n",
            "Loss after epoch 1245: 24836.0\n",
            "Loss after epoch 1246: 24864.0\n",
            "Loss after epoch 1247: 24860.0\n",
            "Loss after epoch 1248: 24656.0\n",
            "Loss after epoch 1249: 24740.0\n",
            "Loss after epoch 1250: 25152.0\n",
            "Loss after epoch 1251: 24692.0\n",
            "Loss after epoch 1252: 24808.0\n",
            "Loss after epoch 1253: 25220.0\n",
            "Loss after epoch 1254: 25668.0\n",
            "Loss after epoch 1255: 24968.0\n",
            "Loss after epoch 1256: 24908.0\n",
            "Loss after epoch 1257: 24176.0\n",
            "Loss after epoch 1258: 24568.0\n",
            "Loss after epoch 1259: 24908.0\n",
            "Loss after epoch 1260: 24720.0\n",
            "Loss after epoch 1261: 25580.0\n",
            "Loss after epoch 1262: 23804.0\n",
            "Loss after epoch 1263: 25412.0\n",
            "Loss after epoch 1264: 24840.0\n",
            "Loss after epoch 1265: 24808.0\n",
            "Loss after epoch 1266: 24768.0\n",
            "Loss after epoch 1267: 25052.0\n",
            "Loss after epoch 1268: 24816.0\n",
            "Loss after epoch 1269: 24984.0\n",
            "Loss after epoch 1270: 24000.0\n",
            "Loss after epoch 1271: 24380.0\n",
            "Loss after epoch 1272: 24956.0\n",
            "Loss after epoch 1273: 24504.0\n",
            "Loss after epoch 1274: 24544.0\n",
            "Loss after epoch 1275: 25380.0\n",
            "Loss after epoch 1276: 25040.0\n",
            "Loss after epoch 1277: 24712.0\n",
            "Loss after epoch 1278: 24264.0\n",
            "Loss after epoch 1279: 25032.0\n",
            "Loss after epoch 1280: 25356.0\n",
            "Loss after epoch 1281: 25216.0\n",
            "Loss after epoch 1282: 25212.0\n",
            "Loss after epoch 1283: 24944.0\n",
            "Loss after epoch 1284: 25464.0\n",
            "Loss after epoch 1285: 25304.0\n",
            "Loss after epoch 1286: 24548.0\n",
            "Loss after epoch 1287: 24792.0\n",
            "Loss after epoch 1288: 25596.0\n",
            "Loss after epoch 1289: 24472.0\n",
            "Loss after epoch 1290: 25232.0\n",
            "Loss after epoch 1291: 24660.0\n",
            "Loss after epoch 1292: 24848.0\n",
            "Loss after epoch 1293: 25372.0\n",
            "Loss after epoch 1294: 24900.0\n",
            "Loss after epoch 1295: 25396.0\n",
            "Loss after epoch 1296: 24704.0\n",
            "Loss after epoch 1297: 24796.0\n",
            "Loss after epoch 1298: 24660.0\n",
            "Loss after epoch 1299: 24588.0\n",
            "Loss after epoch 1300: 24804.0\n",
            "Loss after epoch 1301: 25140.0\n",
            "Loss after epoch 1302: 25208.0\n",
            "Loss after epoch 1303: 24700.0\n",
            "Loss after epoch 1304: 25640.0\n",
            "Loss after epoch 1305: 25016.0\n",
            "Loss after epoch 1306: 24968.0\n",
            "Loss after epoch 1307: 25424.0\n",
            "Loss after epoch 1308: 25284.0\n",
            "Loss after epoch 1309: 25004.0\n",
            "Loss after epoch 1310: 24776.0\n",
            "Loss after epoch 1311: 24224.0\n",
            "Loss after epoch 1312: 24644.0\n",
            "Loss after epoch 1313: 25312.0\n",
            "Loss after epoch 1314: 25040.0\n",
            "Loss after epoch 1315: 24756.0\n",
            "Loss after epoch 1316: 24972.0\n",
            "Loss after epoch 1317: 25556.0\n",
            "Loss after epoch 1318: 24892.0\n",
            "Loss after epoch 1319: 25168.0\n",
            "Loss after epoch 1320: 25040.0\n",
            "Loss after epoch 1321: 25508.0\n",
            "Loss after epoch 1322: 24504.0\n",
            "Loss after epoch 1323: 24368.0\n",
            "Loss after epoch 1324: 24660.0\n",
            "Loss after epoch 1325: 25276.0\n",
            "Loss after epoch 1326: 25460.0\n",
            "Loss after epoch 1327: 24492.0\n",
            "Loss after epoch 1328: 25276.0\n",
            "Loss after epoch 1329: 24980.0\n",
            "Loss after epoch 1330: 24980.0\n",
            "Loss after epoch 1331: 25672.0\n",
            "Loss after epoch 1332: 25156.0\n",
            "Loss after epoch 1333: 24672.0\n",
            "Loss after epoch 1334: 24600.0\n",
            "Loss after epoch 1335: 25164.0\n",
            "Loss after epoch 1336: 25024.0\n",
            "Loss after epoch 1337: 24996.0\n",
            "Loss after epoch 1338: 24556.0\n",
            "Loss after epoch 1339: 25748.0\n",
            "Loss after epoch 1340: 25124.0\n",
            "Loss after epoch 1341: 25276.0\n",
            "Loss after epoch 1342: 24848.0\n",
            "Loss after epoch 1343: 23856.0\n",
            "Loss after epoch 1344: 23920.0\n",
            "Loss after epoch 1345: 25016.0\n",
            "Loss after epoch 1346: 25076.0\n",
            "Loss after epoch 1347: 24692.0\n",
            "Loss after epoch 1348: 24680.0\n",
            "Loss after epoch 1349: 25532.0\n",
            "Loss after epoch 1350: 23996.0\n",
            "Loss after epoch 1351: 24424.0\n",
            "Loss after epoch 1352: 24916.0\n",
            "Loss after epoch 1353: 25004.0\n",
            "Loss after epoch 1354: 24748.0\n",
            "Loss after epoch 1355: 24744.0\n",
            "Loss after epoch 1356: 24364.0\n",
            "Loss after epoch 1357: 24924.0\n",
            "Loss after epoch 1358: 24964.0\n",
            "Loss after epoch 1359: 24908.0\n",
            "Loss after epoch 1360: 24852.0\n",
            "Loss after epoch 1361: 24972.0\n",
            "Loss after epoch 1362: 24288.0\n",
            "Loss after epoch 1363: 24264.0\n",
            "Loss after epoch 1364: 24872.0\n",
            "Loss after epoch 1365: 25656.0\n",
            "Loss after epoch 1366: 24144.0\n",
            "Loss after epoch 1367: 24596.0\n",
            "Loss after epoch 1368: 24236.0\n",
            "Loss after epoch 1369: 24856.0\n",
            "Loss after epoch 1370: 24884.0\n",
            "Loss after epoch 1371: 25016.0\n",
            "Loss after epoch 1372: 25000.0\n",
            "Loss after epoch 1373: 23988.0\n",
            "Loss after epoch 1374: 25252.0\n",
            "Loss after epoch 1375: 24824.0\n",
            "Loss after epoch 1376: 24496.0\n",
            "Loss after epoch 1377: 24196.0\n",
            "Loss after epoch 1378: 25512.0\n",
            "Loss after epoch 1379: 25308.0\n",
            "Loss after epoch 1380: 24504.0\n",
            "Loss after epoch 1381: 24908.0\n",
            "Loss after epoch 1382: 24124.0\n",
            "Loss after epoch 1383: 25376.0\n",
            "Loss after epoch 1384: 24876.0\n",
            "Loss after epoch 1385: 24172.0\n",
            "Loss after epoch 1386: 25112.0\n",
            "Loss after epoch 1387: 24684.0\n",
            "Loss after epoch 1388: 24280.0\n",
            "Loss after epoch 1389: 25016.0\n",
            "Loss after epoch 1390: 23820.0\n",
            "Loss after epoch 1391: 24748.0\n",
            "Loss after epoch 1392: 24656.0\n",
            "Loss after epoch 1393: 25016.0\n",
            "Loss after epoch 1394: 24508.0\n",
            "Loss after epoch 1395: 24256.0\n",
            "Loss after epoch 1396: 24664.0\n",
            "Loss after epoch 1397: 24832.0\n",
            "Loss after epoch 1398: 24692.0\n",
            "Loss after epoch 1399: 25060.0\n",
            "Loss after epoch 1400: 25328.0\n",
            "Loss after epoch 1401: 24692.0\n",
            "Loss after epoch 1402: 24124.0\n",
            "Loss after epoch 1403: 23920.0\n",
            "Loss after epoch 1404: 25380.0\n",
            "Loss after epoch 1405: 23940.0\n",
            "Loss after epoch 1406: 24772.0\n",
            "Loss after epoch 1407: 25176.0\n",
            "Loss after epoch 1408: 24912.0\n",
            "Loss after epoch 1409: 24508.0\n",
            "Loss after epoch 1410: 24368.0\n",
            "Loss after epoch 1411: 24316.0\n",
            "Loss after epoch 1412: 24124.0\n",
            "Loss after epoch 1413: 24956.0\n",
            "Loss after epoch 1414: 25460.0\n",
            "Loss after epoch 1415: 24692.0\n",
            "Loss after epoch 1416: 24180.0\n",
            "Loss after epoch 1417: 24200.0\n",
            "Loss after epoch 1418: 24564.0\n",
            "Loss after epoch 1419: 23812.0\n",
            "Loss after epoch 1420: 24344.0\n",
            "Loss after epoch 1421: 24448.0\n",
            "Loss after epoch 1422: 24428.0\n",
            "Loss after epoch 1423: 25164.0\n",
            "Loss after epoch 1424: 24824.0\n",
            "Loss after epoch 1425: 24648.0\n",
            "Loss after epoch 1426: 24364.0\n",
            "Loss after epoch 1427: 24992.0\n",
            "Loss after epoch 1428: 25080.0\n",
            "Loss after epoch 1429: 24812.0\n",
            "Loss after epoch 1430: 24984.0\n",
            "Loss after epoch 1431: 24400.0\n",
            "Loss after epoch 1432: 24520.0\n",
            "Loss after epoch 1433: 24604.0\n",
            "Loss after epoch 1434: 23792.0\n",
            "Loss after epoch 1435: 24544.0\n",
            "Loss after epoch 1436: 24140.0\n",
            "Loss after epoch 1437: 23900.0\n",
            "Loss after epoch 1438: 24716.0\n",
            "Loss after epoch 1439: 24824.0\n",
            "Loss after epoch 1440: 24444.0\n",
            "Loss after epoch 1441: 24032.0\n",
            "Loss after epoch 1442: 24356.0\n",
            "Loss after epoch 1443: 24868.0\n",
            "Loss after epoch 1444: 24268.0\n",
            "Loss after epoch 1445: 24396.0\n",
            "Loss after epoch 1446: 24680.0\n",
            "Loss after epoch 1447: 24852.0\n",
            "Loss after epoch 1448: 25200.0\n",
            "Loss after epoch 1449: 24544.0\n",
            "Loss after epoch 1450: 24344.0\n",
            "Loss after epoch 1451: 24856.0\n",
            "Loss after epoch 1452: 24360.0\n",
            "Loss after epoch 1453: 24508.0\n",
            "Loss after epoch 1454: 23988.0\n",
            "Loss after epoch 1455: 24616.0\n",
            "Loss after epoch 1456: 23968.0\n",
            "Loss after epoch 1457: 24588.0\n",
            "Loss after epoch 1458: 24572.0\n",
            "Loss after epoch 1459: 24620.0\n",
            "Loss after epoch 1460: 24000.0\n",
            "Loss after epoch 1461: 25268.0\n",
            "Loss after epoch 1462: 24676.0\n",
            "Loss after epoch 1463: 25316.0\n",
            "Loss after epoch 1464: 24416.0\n",
            "Loss after epoch 1465: 24848.0\n",
            "Loss after epoch 1466: 24960.0\n",
            "Loss after epoch 1467: 24464.0\n",
            "Loss after epoch 1468: 23868.0\n",
            "Loss after epoch 1469: 24864.0\n",
            "Loss after epoch 1470: 24932.0\n",
            "Loss after epoch 1471: 24996.0\n",
            "Loss after epoch 1472: 24640.0\n",
            "Loss after epoch 1473: 24736.0\n",
            "Loss after epoch 1474: 24308.0\n",
            "Loss after epoch 1475: 24528.0\n",
            "Loss after epoch 1476: 24252.0\n",
            "Loss after epoch 1477: 24804.0\n",
            "Loss after epoch 1478: 24688.0\n",
            "Loss after epoch 1479: 24740.0\n",
            "Loss after epoch 1480: 24148.0\n",
            "Loss after epoch 1481: 24684.0\n",
            "Loss after epoch 1482: 24896.0\n",
            "Loss after epoch 1483: 23956.0\n",
            "Loss after epoch 1484: 24476.0\n",
            "Loss after epoch 1485: 24304.0\n",
            "Loss after epoch 1486: 24232.0\n",
            "Loss after epoch 1487: 24592.0\n",
            "Loss after epoch 1488: 24732.0\n",
            "Loss after epoch 1489: 25044.0\n",
            "Loss after epoch 1490: 24744.0\n",
            "Loss after epoch 1491: 25356.0\n",
            "Loss after epoch 1492: 24832.0\n",
            "Loss after epoch 1493: 24032.0\n",
            "Loss after epoch 1494: 24952.0\n",
            "Loss after epoch 1495: 23760.0\n",
            "Loss after epoch 1496: 24760.0\n",
            "Loss after epoch 1497: 24136.0\n",
            "Loss after epoch 1498: 23860.0\n",
            "Loss after epoch 1499: 24392.0\n",
            "Loss after epoch 1500: 24704.0\n",
            "Loss after epoch 1501: 24624.0\n",
            "Loss after epoch 1502: 24552.0\n",
            "Loss after epoch 1503: 24404.0\n",
            "Loss after epoch 1504: 24232.0\n",
            "Loss after epoch 1505: 24372.0\n",
            "Loss after epoch 1506: 24176.0\n",
            "Loss after epoch 1507: 24636.0\n",
            "Loss after epoch 1508: 24320.0\n",
            "Loss after epoch 1509: 24120.0\n",
            "Loss after epoch 1510: 24620.0\n",
            "Loss after epoch 1511: 24276.0\n",
            "Loss after epoch 1512: 24368.0\n",
            "Loss after epoch 1513: 24884.0\n",
            "Loss after epoch 1514: 25180.0\n",
            "Loss after epoch 1515: 24292.0\n",
            "Loss after epoch 1516: 23380.0\n",
            "Loss after epoch 1517: 24208.0\n",
            "Loss after epoch 1518: 25060.0\n",
            "Loss after epoch 1519: 24464.0\n",
            "Loss after epoch 1520: 24140.0\n",
            "Loss after epoch 1521: 24776.0\n",
            "Loss after epoch 1522: 23852.0\n",
            "Loss after epoch 1523: 24380.0\n",
            "Loss after epoch 1524: 24080.0\n",
            "Loss after epoch 1525: 24516.0\n",
            "Loss after epoch 1526: 24320.0\n",
            "Loss after epoch 1527: 25356.0\n",
            "Loss after epoch 1528: 24428.0\n",
            "Loss after epoch 1529: 24452.0\n",
            "Loss after epoch 1530: 24380.0\n",
            "Loss after epoch 1531: 23968.0\n",
            "Loss after epoch 1532: 24248.0\n",
            "Loss after epoch 1533: 24172.0\n",
            "Loss after epoch 1534: 24100.0\n",
            "Loss after epoch 1535: 24108.0\n",
            "Loss after epoch 1536: 24924.0\n",
            "Loss after epoch 1537: 23768.0\n",
            "Loss after epoch 1538: 24540.0\n",
            "Loss after epoch 1539: 25052.0\n",
            "Loss after epoch 1540: 24496.0\n",
            "Loss after epoch 1541: 24692.0\n",
            "Loss after epoch 1542: 24048.0\n",
            "Loss after epoch 1543: 24508.0\n",
            "Loss after epoch 1544: 24108.0\n",
            "Loss after epoch 1545: 24664.0\n",
            "Loss after epoch 1546: 23584.0\n",
            "Loss after epoch 1547: 24640.0\n",
            "Loss after epoch 1548: 24368.0\n",
            "Loss after epoch 1549: 24864.0\n",
            "Loss after epoch 1550: 24456.0\n",
            "Loss after epoch 1551: 25132.0\n",
            "Loss after epoch 1552: 24292.0\n",
            "Loss after epoch 1553: 24360.0\n",
            "Loss after epoch 1554: 24488.0\n",
            "Loss after epoch 1555: 23956.0\n",
            "Loss after epoch 1556: 24592.0\n",
            "Loss after epoch 1557: 24140.0\n",
            "Loss after epoch 1558: 24248.0\n",
            "Loss after epoch 1559: 24768.0\n",
            "Loss after epoch 1560: 23604.0\n",
            "Loss after epoch 1561: 24716.0\n",
            "Loss after epoch 1562: 24784.0\n",
            "Loss after epoch 1563: 24192.0\n",
            "Loss after epoch 1564: 24860.0\n",
            "Loss after epoch 1565: 24780.0\n",
            "Loss after epoch 1566: 23576.0\n",
            "Loss after epoch 1567: 25292.0\n",
            "Loss after epoch 1568: 24360.0\n",
            "Loss after epoch 1569: 24556.0\n",
            "Loss after epoch 1570: 24332.0\n",
            "Loss after epoch 1571: 24368.0\n",
            "Loss after epoch 1572: 24284.0\n",
            "Loss after epoch 1573: 24568.0\n",
            "Loss after epoch 1574: 24664.0\n",
            "Loss after epoch 1575: 24136.0\n",
            "Loss after epoch 1576: 24336.0\n",
            "Loss after epoch 1577: 24464.0\n",
            "Loss after epoch 1578: 23820.0\n",
            "Loss after epoch 1579: 23860.0\n",
            "Loss after epoch 1580: 24628.0\n",
            "Loss after epoch 1581: 23964.0\n",
            "Loss after epoch 1582: 25288.0\n",
            "Loss after epoch 1583: 24160.0\n",
            "Loss after epoch 1584: 24016.0\n",
            "Loss after epoch 1585: 24832.0\n",
            "Loss after epoch 1586: 24416.0\n",
            "Loss after epoch 1587: 24200.0\n",
            "Loss after epoch 1588: 24252.0\n",
            "Loss after epoch 1589: 24200.0\n",
            "Loss after epoch 1590: 24752.0\n",
            "Loss after epoch 1591: 24412.0\n",
            "Loss after epoch 1592: 24872.0\n",
            "Loss after epoch 1593: 24800.0\n",
            "Loss after epoch 1594: 24388.0\n",
            "Loss after epoch 1595: 23576.0\n",
            "Loss after epoch 1596: 24172.0\n",
            "Loss after epoch 1597: 24888.0\n",
            "Loss after epoch 1598: 24596.0\n",
            "Loss after epoch 1599: 24020.0\n",
            "Loss after epoch 1600: 24644.0\n",
            "Loss after epoch 1601: 25244.0\n",
            "Loss after epoch 1602: 23664.0\n",
            "Loss after epoch 1603: 24512.0\n",
            "Loss after epoch 1604: 24292.0\n",
            "Loss after epoch 1605: 24076.0\n",
            "Loss after epoch 1606: 24568.0\n",
            "Loss after epoch 1607: 24700.0\n",
            "Loss after epoch 1608: 24440.0\n",
            "Loss after epoch 1609: 24176.0\n",
            "Loss after epoch 1610: 24272.0\n",
            "Loss after epoch 1611: 24012.0\n",
            "Loss after epoch 1612: 24052.0\n",
            "Loss after epoch 1613: 24184.0\n",
            "Loss after epoch 1614: 24300.0\n",
            "Loss after epoch 1615: 24540.0\n",
            "Loss after epoch 1616: 24540.0\n",
            "Loss after epoch 1617: 25064.0\n",
            "Loss after epoch 1618: 24756.0\n",
            "Loss after epoch 1619: 24540.0\n",
            "Loss after epoch 1620: 24484.0\n",
            "Loss after epoch 1621: 24924.0\n",
            "Loss after epoch 1622: 25024.0\n",
            "Loss after epoch 1623: 23956.0\n",
            "Loss after epoch 1624: 24724.0\n",
            "Loss after epoch 1625: 23788.0\n",
            "Loss after epoch 1626: 24192.0\n",
            "Loss after epoch 1627: 24540.0\n",
            "Loss after epoch 1628: 24184.0\n",
            "Loss after epoch 1629: 24644.0\n",
            "Loss after epoch 1630: 24108.0\n",
            "Loss after epoch 1631: 24360.0\n",
            "Loss after epoch 1632: 24276.0\n",
            "Loss after epoch 1633: 24340.0\n",
            "Loss after epoch 1634: 24184.0\n",
            "Loss after epoch 1635: 24816.0\n",
            "Loss after epoch 1636: 24008.0\n",
            "Loss after epoch 1637: 24852.0\n",
            "Loss after epoch 1638: 24264.0\n",
            "Loss after epoch 1639: 25088.0\n",
            "Loss after epoch 1640: 24188.0\n",
            "Loss after epoch 1641: 24012.0\n",
            "Loss after epoch 1642: 24228.0\n",
            "Loss after epoch 1643: 24684.0\n",
            "Loss after epoch 1644: 24144.0\n",
            "Loss after epoch 1645: 24412.0\n",
            "Loss after epoch 1646: 24524.0\n",
            "Loss after epoch 1647: 23852.0\n",
            "Loss after epoch 1648: 23576.0\n",
            "Loss after epoch 1649: 24904.0\n",
            "Loss after epoch 1650: 23812.0\n",
            "Loss after epoch 1651: 23784.0\n",
            "Loss after epoch 1652: 24416.0\n",
            "Loss after epoch 1653: 24716.0\n",
            "Loss after epoch 1654: 24308.0\n",
            "Loss after epoch 1655: 23872.0\n",
            "Loss after epoch 1656: 24332.0\n",
            "Loss after epoch 1657: 24188.0\n",
            "Loss after epoch 1658: 23620.0\n",
            "Loss after epoch 1659: 25332.0\n",
            "Loss after epoch 1660: 24020.0\n",
            "Loss after epoch 1661: 24344.0\n",
            "Loss after epoch 1662: 24664.0\n",
            "Loss after epoch 1663: 24632.0\n",
            "Loss after epoch 1664: 23932.0\n",
            "Loss after epoch 1665: 24564.0\n",
            "Loss after epoch 1666: 24744.0\n",
            "Loss after epoch 1667: 23624.0\n",
            "Loss after epoch 1668: 23880.0\n",
            "Loss after epoch 1669: 23880.0\n",
            "Loss after epoch 1670: 23672.0\n",
            "Loss after epoch 1671: 24228.0\n",
            "Loss after epoch 1672: 24028.0\n",
            "Loss after epoch 1673: 24292.0\n",
            "Loss after epoch 1674: 24312.0\n",
            "Loss after epoch 1675: 24224.0\n",
            "Loss after epoch 1676: 23852.0\n",
            "Loss after epoch 1677: 24044.0\n",
            "Loss after epoch 1678: 24320.0\n",
            "Loss after epoch 1679: 24120.0\n",
            "Loss after epoch 1680: 24028.0\n",
            "Loss after epoch 1681: 23728.0\n",
            "Loss after epoch 1682: 24132.0\n",
            "Loss after epoch 1683: 24556.0\n",
            "Loss after epoch 1684: 24316.0\n",
            "Loss after epoch 1685: 23676.0\n",
            "Loss after epoch 1686: 23900.0\n",
            "Loss after epoch 1687: 24008.0\n",
            "Loss after epoch 1688: 23788.0\n",
            "Loss after epoch 1689: 24732.0\n",
            "Loss after epoch 1690: 24040.0\n",
            "Loss after epoch 1691: 24904.0\n",
            "Loss after epoch 1692: 23972.0\n",
            "Loss after epoch 1693: 24208.0\n",
            "Loss after epoch 1694: 24264.0\n",
            "Loss after epoch 1695: 24860.0\n",
            "Loss after epoch 1696: 24188.0\n",
            "Loss after epoch 1697: 23948.0\n",
            "Loss after epoch 1698: 24992.0\n",
            "Loss after epoch 1699: 24580.0\n",
            "Loss after epoch 1700: 23880.0\n",
            "Loss after epoch 1701: 24004.0\n",
            "Loss after epoch 1702: 24224.0\n",
            "Loss after epoch 1703: 24556.0\n",
            "Loss after epoch 1704: 24576.0\n",
            "Loss after epoch 1705: 23528.0\n",
            "Loss after epoch 1706: 24012.0\n",
            "Loss after epoch 1707: 23888.0\n",
            "Loss after epoch 1708: 24144.0\n",
            "Loss after epoch 1709: 24948.0\n",
            "Loss after epoch 1710: 24576.0\n",
            "Loss after epoch 1711: 24032.0\n",
            "Loss after epoch 1712: 23748.0\n",
            "Loss after epoch 1713: 24568.0\n",
            "Loss after epoch 1714: 23352.0\n",
            "Loss after epoch 1715: 23708.0\n",
            "Loss after epoch 1716: 24216.0\n",
            "Loss after epoch 1717: 23888.0\n",
            "Loss after epoch 1718: 24016.0\n",
            "Loss after epoch 1719: 24148.0\n",
            "Loss after epoch 1720: 24508.0\n",
            "Loss after epoch 1721: 24144.0\n",
            "Loss after epoch 1722: 24056.0\n",
            "Loss after epoch 1723: 23972.0\n",
            "Loss after epoch 1724: 24648.0\n",
            "Loss after epoch 1725: 24064.0\n",
            "Loss after epoch 1726: 24508.0\n",
            "Loss after epoch 1727: 24336.0\n",
            "Loss after epoch 1728: 24368.0\n",
            "Loss after epoch 1729: 23716.0\n",
            "Loss after epoch 1730: 24036.0\n",
            "Loss after epoch 1731: 24208.0\n",
            "Loss after epoch 1732: 24532.0\n",
            "Loss after epoch 1733: 24200.0\n",
            "Loss after epoch 1734: 23648.0\n",
            "Loss after epoch 1735: 23800.0\n",
            "Loss after epoch 1736: 24728.0\n",
            "Loss after epoch 1737: 24212.0\n",
            "Loss after epoch 1738: 24132.0\n",
            "Loss after epoch 1739: 24208.0\n",
            "Loss after epoch 1740: 24484.0\n",
            "Loss after epoch 1741: 23556.0\n",
            "Loss after epoch 1742: 23516.0\n",
            "Loss after epoch 1743: 23988.0\n",
            "Loss after epoch 1744: 23692.0\n",
            "Loss after epoch 1745: 24132.0\n",
            "Loss after epoch 1746: 24364.0\n",
            "Loss after epoch 1747: 23092.0\n",
            "Loss after epoch 1748: 24540.0\n",
            "Loss after epoch 1749: 24188.0\n",
            "Loss after epoch 1750: 23844.0\n",
            "Loss after epoch 1751: 24816.0\n",
            "Loss after epoch 1752: 24376.0\n",
            "Loss after epoch 1753: 24340.0\n",
            "Loss after epoch 1754: 24416.0\n",
            "Loss after epoch 1755: 24544.0\n",
            "Loss after epoch 1756: 24292.0\n",
            "Loss after epoch 1757: 23860.0\n",
            "Loss after epoch 1758: 24008.0\n",
            "Loss after epoch 1759: 23968.0\n",
            "Loss after epoch 1760: 23936.0\n",
            "Loss after epoch 1761: 24308.0\n",
            "Loss after epoch 1762: 24560.0\n",
            "Loss after epoch 1763: 24012.0\n",
            "Loss after epoch 1764: 24412.0\n",
            "Loss after epoch 1765: 23932.0\n",
            "Loss after epoch 1766: 24788.0\n",
            "Loss after epoch 1767: 24604.0\n",
            "Loss after epoch 1768: 23684.0\n",
            "Loss after epoch 1769: 24316.0\n",
            "Loss after epoch 1770: 23696.0\n",
            "Loss after epoch 1771: 24000.0\n",
            "Loss after epoch 1772: 24064.0\n",
            "Loss after epoch 1773: 24004.0\n",
            "Loss after epoch 1774: 24780.0\n",
            "Loss after epoch 1775: 24088.0\n",
            "Loss after epoch 1776: 24020.0\n",
            "Loss after epoch 1777: 24724.0\n",
            "Loss after epoch 1778: 24144.0\n",
            "Loss after epoch 1779: 23652.0\n",
            "Loss after epoch 1780: 23696.0\n",
            "Loss after epoch 1781: 23916.0\n",
            "Loss after epoch 1782: 24424.0\n",
            "Loss after epoch 1783: 24620.0\n",
            "Loss after epoch 1784: 23868.0\n",
            "Loss after epoch 1785: 23944.0\n",
            "Loss after epoch 1786: 23620.0\n",
            "Loss after epoch 1787: 24404.0\n",
            "Loss after epoch 1788: 24076.0\n",
            "Loss after epoch 1789: 23552.0\n",
            "Loss after epoch 1790: 24232.0\n",
            "Loss after epoch 1791: 24072.0\n",
            "Loss after epoch 1792: 23684.0\n",
            "Loss after epoch 1793: 24200.0\n",
            "Loss after epoch 1794: 24388.0\n",
            "Loss after epoch 1795: 24276.0\n",
            "Loss after epoch 1796: 24204.0\n",
            "Loss after epoch 1797: 23780.0\n",
            "Loss after epoch 1798: 23944.0\n",
            "Loss after epoch 1799: 23832.0\n",
            "Loss after epoch 1800: 23552.0\n",
            "Loss after epoch 1801: 23676.0\n",
            "Loss after epoch 1802: 23916.0\n",
            "Loss after epoch 1803: 24112.0\n",
            "Loss after epoch 1804: 23924.0\n",
            "Loss after epoch 1805: 24376.0\n",
            "Loss after epoch 1806: 23784.0\n",
            "Loss after epoch 1807: 24232.0\n",
            "Loss after epoch 1808: 23576.0\n",
            "Loss after epoch 1809: 23408.0\n",
            "Loss after epoch 1810: 23792.0\n",
            "Loss after epoch 1811: 24656.0\n",
            "Loss after epoch 1812: 24664.0\n",
            "Loss after epoch 1813: 23772.0\n",
            "Loss after epoch 1814: 23864.0\n",
            "Loss after epoch 1815: 23888.0\n",
            "Loss after epoch 1816: 24192.0\n",
            "Loss after epoch 1817: 24072.0\n",
            "Loss after epoch 1818: 23820.0\n",
            "Loss after epoch 1819: 24292.0\n",
            "Loss after epoch 1820: 23092.0\n",
            "Loss after epoch 1821: 23692.0\n",
            "Loss after epoch 1822: 23808.0\n",
            "Loss after epoch 1823: 23840.0\n",
            "Loss after epoch 1824: 24352.0\n",
            "Loss after epoch 1825: 23648.0\n",
            "Loss after epoch 1826: 23720.0\n",
            "Loss after epoch 1827: 24428.0\n",
            "Loss after epoch 1828: 24144.0\n",
            "Loss after epoch 1829: 24492.0\n",
            "Loss after epoch 1830: 24108.0\n",
            "Loss after epoch 1831: 23400.0\n",
            "Loss after epoch 1832: 23792.0\n",
            "Loss after epoch 1833: 23944.0\n",
            "Loss after epoch 1834: 24092.0\n",
            "Loss after epoch 1835: 24384.0\n",
            "Loss after epoch 1836: 24792.0\n",
            "Loss after epoch 1837: 23804.0\n",
            "Loss after epoch 1838: 24096.0\n",
            "Loss after epoch 1839: 24568.0\n",
            "Loss after epoch 1840: 24248.0\n",
            "Loss after epoch 1841: 24084.0\n",
            "Loss after epoch 1842: 23360.0\n",
            "Loss after epoch 1843: 24380.0\n",
            "Loss after epoch 1844: 23852.0\n",
            "Loss after epoch 1845: 23868.0\n",
            "Loss after epoch 1846: 23860.0\n",
            "Loss after epoch 1847: 23576.0\n",
            "Loss after epoch 1848: 24452.0\n",
            "Loss after epoch 1849: 24004.0\n",
            "Loss after epoch 1850: 24412.0\n",
            "Loss after epoch 1851: 23304.0\n",
            "Loss after epoch 1852: 24780.0\n",
            "Loss after epoch 1853: 24032.0\n",
            "Loss after epoch 1854: 23748.0\n",
            "Loss after epoch 1855: 24540.0\n",
            "Loss after epoch 1856: 22920.0\n",
            "Loss after epoch 1857: 24108.0\n",
            "Loss after epoch 1858: 23864.0\n",
            "Loss after epoch 1859: 24044.0\n",
            "Loss after epoch 1860: 24268.0\n",
            "Loss after epoch 1861: 24184.0\n",
            "Loss after epoch 1862: 24340.0\n",
            "Loss after epoch 1863: 23840.0\n",
            "Loss after epoch 1864: 23972.0\n",
            "Loss after epoch 1865: 24276.0\n",
            "Loss after epoch 1866: 23824.0\n",
            "Loss after epoch 1867: 23232.0\n",
            "Loss after epoch 1868: 23736.0\n",
            "Loss after epoch 1869: 23928.0\n",
            "Loss after epoch 1870: 23776.0\n",
            "Loss after epoch 1871: 23648.0\n",
            "Loss after epoch 1872: 24164.0\n",
            "Loss after epoch 1873: 23364.0\n",
            "Loss after epoch 1874: 24316.0\n",
            "Loss after epoch 1875: 24216.0\n",
            "Loss after epoch 1876: 23912.0\n",
            "Loss after epoch 1877: 23724.0\n",
            "Loss after epoch 1878: 24528.0\n",
            "Loss after epoch 1879: 24284.0\n",
            "Loss after epoch 1880: 24244.0\n",
            "Loss after epoch 1881: 24608.0\n",
            "Loss after epoch 1882: 23780.0\n",
            "Loss after epoch 1883: 24244.0\n",
            "Loss after epoch 1884: 23704.0\n",
            "Loss after epoch 1885: 24328.0\n",
            "Loss after epoch 1886: 24088.0\n",
            "Loss after epoch 1887: 23968.0\n",
            "Loss after epoch 1888: 24760.0\n",
            "Loss after epoch 1889: 23884.0\n",
            "Loss after epoch 1890: 23844.0\n",
            "Loss after epoch 1891: 24456.0\n",
            "Loss after epoch 1892: 23504.0\n",
            "Loss after epoch 1893: 24044.0\n",
            "Loss after epoch 1894: 23940.0\n",
            "Loss after epoch 1895: 23540.0\n",
            "Loss after epoch 1896: 23624.0\n",
            "Loss after epoch 1897: 23936.0\n",
            "Loss after epoch 1898: 23808.0\n",
            "Loss after epoch 1899: 23976.0\n",
            "Loss after epoch 1900: 23572.0\n",
            "Loss after epoch 1901: 24212.0\n",
            "Loss after epoch 1902: 23720.0\n",
            "Loss after epoch 1903: 23828.0\n",
            "Loss after epoch 1904: 24428.0\n",
            "Loss after epoch 1905: 24224.0\n",
            "Loss after epoch 1906: 24232.0\n",
            "Loss after epoch 1907: 24460.0\n",
            "Loss after epoch 1908: 23632.0\n",
            "Loss after epoch 1909: 23892.0\n",
            "Loss after epoch 1910: 23640.0\n",
            "Loss after epoch 1911: 23628.0\n",
            "Loss after epoch 1912: 24072.0\n",
            "Loss after epoch 1913: 24168.0\n",
            "Loss after epoch 1914: 23700.0\n",
            "Loss after epoch 1915: 24024.0\n",
            "Loss after epoch 1916: 24240.0\n",
            "Loss after epoch 1917: 23840.0\n",
            "Loss after epoch 1918: 24252.0\n",
            "Loss after epoch 1919: 23816.0\n",
            "Loss after epoch 1920: 23808.0\n",
            "Loss after epoch 1921: 23896.0\n",
            "Loss after epoch 1922: 24176.0\n",
            "Loss after epoch 1923: 24552.0\n",
            "Loss after epoch 1924: 23504.0\n",
            "Loss after epoch 1925: 23328.0\n",
            "Loss after epoch 1926: 24412.0\n",
            "Loss after epoch 1927: 23932.0\n",
            "Loss after epoch 1928: 24240.0\n",
            "Loss after epoch 1929: 23656.0\n",
            "Loss after epoch 1930: 23520.0\n",
            "Loss after epoch 1931: 23888.0\n",
            "Loss after epoch 1932: 23852.0\n",
            "Loss after epoch 1933: 24024.0\n",
            "Loss after epoch 1934: 24348.0\n",
            "Loss after epoch 1935: 23764.0\n",
            "Loss after epoch 1936: 23952.0\n",
            "Loss after epoch 1937: 23544.0\n",
            "Loss after epoch 1938: 23372.0\n",
            "Loss after epoch 1939: 23476.0\n",
            "Loss after epoch 1940: 23524.0\n",
            "Loss after epoch 1941: 23672.0\n",
            "Loss after epoch 1942: 24528.0\n",
            "Loss after epoch 1943: 24320.0\n",
            "Loss after epoch 1944: 24076.0\n",
            "Loss after epoch 1945: 22720.0\n",
            "Loss after epoch 1946: 24144.0\n",
            "Loss after epoch 1947: 23584.0\n",
            "Loss after epoch 1948: 23812.0\n",
            "Loss after epoch 1949: 24092.0\n",
            "Loss after epoch 1950: 24908.0\n",
            "Loss after epoch 1951: 23808.0\n",
            "Loss after epoch 1952: 23648.0\n",
            "Loss after epoch 1953: 23824.0\n",
            "Loss after epoch 1954: 23564.0\n",
            "Loss after epoch 1955: 24112.0\n",
            "Loss after epoch 1956: 23652.0\n",
            "Loss after epoch 1957: 22952.0\n",
            "Loss after epoch 1958: 23980.0\n",
            "Loss after epoch 1959: 23388.0\n",
            "Loss after epoch 1960: 24128.0\n",
            "Loss after epoch 1961: 23640.0\n",
            "Loss after epoch 1962: 24116.0\n",
            "Loss after epoch 1963: 23452.0\n",
            "Loss after epoch 1964: 23316.0\n",
            "Loss after epoch 1965: 23588.0\n",
            "Loss after epoch 1966: 24212.0\n",
            "Loss after epoch 1967: 23664.0\n",
            "Loss after epoch 1968: 23984.0\n",
            "Loss after epoch 1969: 23936.0\n",
            "Loss after epoch 1970: 24176.0\n",
            "Loss after epoch 1971: 23928.0\n",
            "Loss after epoch 1972: 23704.0\n",
            "Loss after epoch 1973: 22848.0\n",
            "Loss after epoch 1974: 23492.0\n",
            "Loss after epoch 1975: 23620.0\n",
            "Loss after epoch 1976: 23112.0\n",
            "Loss after epoch 1977: 24260.0\n",
            "Loss after epoch 1978: 23928.0\n",
            "Loss after epoch 1979: 23712.0\n",
            "Loss after epoch 1980: 23840.0\n",
            "Loss after epoch 1981: 23304.0\n",
            "Loss after epoch 1982: 23652.0\n",
            "Loss after epoch 1983: 23864.0\n",
            "Loss after epoch 1984: 23560.0\n",
            "Loss after epoch 1985: 22680.0\n",
            "Loss after epoch 1986: 23808.0\n",
            "Loss after epoch 1987: 23524.0\n",
            "Loss after epoch 1988: 23804.0\n",
            "Loss after epoch 1989: 23692.0\n",
            "Loss after epoch 1990: 23860.0\n",
            "Loss after epoch 1991: 24192.0\n",
            "Loss after epoch 1992: 23680.0\n",
            "Loss after epoch 1993: 24452.0\n",
            "Loss after epoch 1994: 23516.0\n",
            "Loss after epoch 1995: 23536.0\n",
            "Loss after epoch 1996: 23464.0\n",
            "Loss after epoch 1997: 23724.0\n",
            "Loss after epoch 1998: 24008.0\n",
            "Loss after epoch 1999: 24164.0\n",
            "Loss after epoch 2000: 23592.0\n",
            "Loss after epoch 2001: 23392.0\n",
            "Loss after epoch 2002: 24176.0\n",
            "Loss after epoch 2003: 24248.0\n",
            "Loss after epoch 2004: 23460.0\n",
            "Loss after epoch 2005: 24284.0\n",
            "Loss after epoch 2006: 23544.0\n",
            "Loss after epoch 2007: 23720.0\n",
            "Loss after epoch 2008: 23780.0\n",
            "Loss after epoch 2009: 24356.0\n",
            "Loss after epoch 2010: 23644.0\n",
            "Loss after epoch 2011: 23428.0\n",
            "Loss after epoch 2012: 23716.0\n",
            "Loss after epoch 2013: 23516.0\n",
            "Loss after epoch 2014: 23932.0\n",
            "Loss after epoch 2015: 24408.0\n",
            "Loss after epoch 2016: 24060.0\n",
            "Loss after epoch 2017: 24252.0\n",
            "Loss after epoch 2018: 23240.0\n",
            "Loss after epoch 2019: 24052.0\n",
            "Loss after epoch 2020: 23740.0\n",
            "Loss after epoch 2021: 23924.0\n",
            "Loss after epoch 2022: 23760.0\n",
            "Loss after epoch 2023: 23116.0\n",
            "Loss after epoch 2024: 23684.0\n",
            "Loss after epoch 2025: 23360.0\n",
            "Loss after epoch 2026: 24012.0\n",
            "Loss after epoch 2027: 23560.0\n",
            "Loss after epoch 2028: 23384.0\n",
            "Loss after epoch 2029: 23568.0\n",
            "Loss after epoch 2030: 23888.0\n",
            "Loss after epoch 2031: 22948.0\n",
            "Loss after epoch 2032: 23512.0\n",
            "Loss after epoch 2033: 23460.0\n",
            "Loss after epoch 2034: 23752.0\n",
            "Loss after epoch 2035: 23824.0\n",
            "Loss after epoch 2036: 23744.0\n",
            "Loss after epoch 2037: 24308.0\n",
            "Loss after epoch 2038: 23900.0\n",
            "Loss after epoch 2039: 23716.0\n",
            "Loss after epoch 2040: 24316.0\n",
            "Loss after epoch 2041: 23508.0\n",
            "Loss after epoch 2042: 23104.0\n",
            "Loss after epoch 2043: 23700.0\n",
            "Loss after epoch 2044: 24268.0\n",
            "Loss after epoch 2045: 23540.0\n",
            "Loss after epoch 2046: 24108.0\n",
            "Loss after epoch 2047: 23640.0\n",
            "Loss after epoch 2048: 23824.0\n",
            "Loss after epoch 2049: 23608.0\n",
            "Loss after epoch 2050: 23224.0\n",
            "Loss after epoch 2051: 22692.0\n",
            "Loss after epoch 2052: 23152.0\n",
            "Loss after epoch 2053: 23748.0\n",
            "Loss after epoch 2054: 23392.0\n",
            "Loss after epoch 2055: 23616.0\n",
            "Loss after epoch 2056: 23864.0\n",
            "Loss after epoch 2057: 23220.0\n",
            "Loss after epoch 2058: 23588.0\n",
            "Loss after epoch 2059: 24136.0\n",
            "Loss after epoch 2060: 23748.0\n",
            "Loss after epoch 2061: 23812.0\n",
            "Loss after epoch 2062: 24140.0\n",
            "Loss after epoch 2063: 23612.0\n",
            "Loss after epoch 2064: 24292.0\n",
            "Loss after epoch 2065: 23076.0\n",
            "Loss after epoch 2066: 23284.0\n",
            "Loss after epoch 2067: 23268.0\n",
            "Loss after epoch 2068: 23760.0\n",
            "Loss after epoch 2069: 23512.0\n",
            "Loss after epoch 2070: 23696.0\n",
            "Loss after epoch 2071: 23816.0\n",
            "Loss after epoch 2072: 23572.0\n",
            "Loss after epoch 2073: 23352.0\n",
            "Loss after epoch 2074: 23588.0\n",
            "Loss after epoch 2075: 23284.0\n",
            "Loss after epoch 2076: 23072.0\n",
            "Loss after epoch 2077: 22856.0\n",
            "Loss after epoch 2078: 23504.0\n",
            "Loss after epoch 2079: 23380.0\n",
            "Loss after epoch 2080: 23404.0\n",
            "Loss after epoch 2081: 24100.0\n",
            "Loss after epoch 2082: 24212.0\n",
            "Loss after epoch 2083: 24064.0\n",
            "Loss after epoch 2084: 23884.0\n",
            "Loss after epoch 2085: 23904.0\n",
            "Loss after epoch 2086: 24048.0\n",
            "Loss after epoch 2087: 23456.0\n",
            "Loss after epoch 2088: 23796.0\n",
            "Loss after epoch 2089: 23916.0\n",
            "Loss after epoch 2090: 23336.0\n",
            "Loss after epoch 2091: 23904.0\n",
            "Loss after epoch 2092: 24312.0\n",
            "Loss after epoch 2093: 23572.0\n",
            "Loss after epoch 2094: 24488.0\n",
            "Loss after epoch 2095: 23516.0\n",
            "Loss after epoch 2096: 23244.0\n",
            "Loss after epoch 2097: 23296.0\n",
            "Loss after epoch 2098: 23512.0\n",
            "Loss after epoch 2099: 22832.0\n",
            "Loss after epoch 2100: 23184.0\n",
            "Loss after epoch 2101: 23776.0\n",
            "Loss after epoch 2102: 24452.0\n",
            "Loss after epoch 2103: 24832.0\n",
            "Loss after epoch 2104: 24420.0\n",
            "Loss after epoch 2105: 23848.0\n",
            "Loss after epoch 2106: 23544.0\n",
            "Loss after epoch 2107: 23840.0\n",
            "Loss after epoch 2108: 23380.0\n",
            "Loss after epoch 2109: 23388.0\n",
            "Loss after epoch 2110: 23136.0\n",
            "Loss after epoch 2111: 23384.0\n",
            "Loss after epoch 2112: 23964.0\n",
            "Loss after epoch 2113: 23184.0\n",
            "Loss after epoch 2114: 24036.0\n",
            "Loss after epoch 2115: 23284.0\n",
            "Loss after epoch 2116: 23504.0\n",
            "Loss after epoch 2117: 23676.0\n",
            "Loss after epoch 2118: 23424.0\n",
            "Loss after epoch 2119: 23684.0\n",
            "Loss after epoch 2120: 23620.0\n",
            "Loss after epoch 2121: 23544.0\n",
            "Loss after epoch 2122: 23532.0\n",
            "Loss after epoch 2123: 23336.0\n",
            "Loss after epoch 2124: 23448.0\n",
            "Loss after epoch 2125: 23668.0\n",
            "Loss after epoch 2126: 23388.0\n",
            "Loss after epoch 2127: 23164.0\n",
            "Loss after epoch 2128: 23432.0\n",
            "Loss after epoch 2129: 22820.0\n",
            "Loss after epoch 2130: 23160.0\n",
            "Loss after epoch 2131: 23224.0\n",
            "Loss after epoch 2132: 23212.0\n",
            "Loss after epoch 2133: 23660.0\n",
            "Loss after epoch 2134: 23412.0\n",
            "Loss after epoch 2135: 23596.0\n",
            "Loss after epoch 2136: 23360.0\n",
            "Loss after epoch 2137: 23048.0\n",
            "Loss after epoch 2138: 23044.0\n",
            "Loss after epoch 2139: 24072.0\n",
            "Loss after epoch 2140: 23516.0\n",
            "Loss after epoch 2141: 23124.0\n",
            "Loss after epoch 2142: 23924.0\n",
            "Loss after epoch 2143: 23232.0\n",
            "Loss after epoch 2144: 23392.0\n",
            "Loss after epoch 2145: 23572.0\n",
            "Loss after epoch 2146: 23172.0\n",
            "Loss after epoch 2147: 23516.0\n",
            "Loss after epoch 2148: 23928.0\n",
            "Loss after epoch 2149: 23720.0\n",
            "Loss after epoch 2150: 23900.0\n",
            "Loss after epoch 2151: 23440.0\n",
            "Loss after epoch 2152: 23588.0\n",
            "Loss after epoch 2153: 23664.0\n",
            "Loss after epoch 2154: 23432.0\n",
            "Loss after epoch 2155: 23168.0\n",
            "Loss after epoch 2156: 24140.0\n",
            "Loss after epoch 2157: 23964.0\n",
            "Loss after epoch 2158: 23620.0\n",
            "Loss after epoch 2159: 23532.0\n",
            "Loss after epoch 2160: 23852.0\n",
            "Loss after epoch 2161: 24024.0\n",
            "Loss after epoch 2162: 23296.0\n",
            "Loss after epoch 2163: 22648.0\n",
            "Loss after epoch 2164: 23864.0\n",
            "Loss after epoch 2165: 24400.0\n",
            "Loss after epoch 2166: 23140.0\n",
            "Loss after epoch 2167: 23576.0\n",
            "Loss after epoch 2168: 23356.0\n",
            "Loss after epoch 2169: 23392.0\n",
            "Loss after epoch 2170: 23536.0\n",
            "Loss after epoch 2171: 23248.0\n",
            "Loss after epoch 2172: 22720.0\n",
            "Loss after epoch 2173: 23980.0\n",
            "Loss after epoch 2174: 23780.0\n",
            "Loss after epoch 2175: 23172.0\n",
            "Loss after epoch 2176: 23756.0\n",
            "Loss after epoch 2177: 23656.0\n",
            "Loss after epoch 2178: 22996.0\n",
            "Loss after epoch 2179: 23812.0\n",
            "Loss after epoch 2180: 23268.0\n",
            "Loss after epoch 2181: 23444.0\n",
            "Loss after epoch 2182: 23656.0\n",
            "Loss after epoch 2183: 24172.0\n",
            "Loss after epoch 2184: 24192.0\n",
            "Loss after epoch 2185: 24056.0\n",
            "Loss after epoch 2186: 23900.0\n",
            "Loss after epoch 2187: 24136.0\n",
            "Loss after epoch 2188: 23396.0\n",
            "Loss after epoch 2189: 23360.0\n",
            "Loss after epoch 2190: 23440.0\n",
            "Loss after epoch 2191: 23568.0\n",
            "Loss after epoch 2192: 23296.0\n",
            "Loss after epoch 2193: 23828.0\n",
            "Loss after epoch 2194: 23328.0\n",
            "Loss after epoch 2195: 23200.0\n",
            "Loss after epoch 2196: 23220.0\n",
            "Loss after epoch 2197: 23740.0\n",
            "Loss after epoch 2198: 23836.0\n",
            "Loss after epoch 2199: 23812.0\n",
            "Loss after epoch 2200: 23984.0\n",
            "Loss after epoch 2201: 23516.0\n",
            "Loss after epoch 2202: 22776.0\n",
            "Loss after epoch 2203: 23140.0\n",
            "Loss after epoch 2204: 23332.0\n",
            "Loss after epoch 2205: 23268.0\n",
            "Loss after epoch 2206: 22840.0\n",
            "Loss after epoch 2207: 23184.0\n",
            "Loss after epoch 2208: 23564.0\n",
            "Loss after epoch 2209: 23720.0\n",
            "Loss after epoch 2210: 23104.0\n",
            "Loss after epoch 2211: 24316.0\n",
            "Loss after epoch 2212: 23140.0\n",
            "Loss after epoch 2213: 23808.0\n",
            "Loss after epoch 2214: 23248.0\n",
            "Loss after epoch 2215: 23304.0\n",
            "Loss after epoch 2216: 23084.0\n",
            "Loss after epoch 2217: 22948.0\n",
            "Loss after epoch 2218: 23100.0\n",
            "Loss after epoch 2219: 23272.0\n",
            "Loss after epoch 2220: 23068.0\n",
            "Loss after epoch 2221: 23876.0\n",
            "Loss after epoch 2222: 23248.0\n",
            "Loss after epoch 2223: 23088.0\n",
            "Loss after epoch 2224: 22660.0\n",
            "Loss after epoch 2225: 23908.0\n",
            "Loss after epoch 2226: 22760.0\n",
            "Loss after epoch 2227: 23928.0\n",
            "Loss after epoch 2228: 23740.0\n",
            "Loss after epoch 2229: 23752.0\n",
            "Loss after epoch 2230: 23424.0\n",
            "Loss after epoch 2231: 23628.0\n",
            "Loss after epoch 2232: 23456.0\n",
            "Loss after epoch 2233: 23068.0\n",
            "Loss after epoch 2234: 23128.0\n",
            "Loss after epoch 2235: 23428.0\n",
            "Loss after epoch 2236: 23496.0\n",
            "Loss after epoch 2237: 22944.0\n",
            "Loss after epoch 2238: 22644.0\n",
            "Loss after epoch 2239: 23444.0\n",
            "Loss after epoch 2240: 23760.0\n",
            "Loss after epoch 2241: 23480.0\n",
            "Loss after epoch 2242: 23272.0\n",
            "Loss after epoch 2243: 23312.0\n",
            "Loss after epoch 2244: 23796.0\n",
            "Loss after epoch 2245: 23204.0\n",
            "Loss after epoch 2246: 23552.0\n",
            "Loss after epoch 2247: 23932.0\n",
            "Loss after epoch 2248: 22844.0\n",
            "Loss after epoch 2249: 23268.0\n",
            "Loss after epoch 2250: 23420.0\n",
            "Loss after epoch 2251: 22680.0\n",
            "Loss after epoch 2252: 23292.0\n",
            "Loss after epoch 2253: 22860.0\n",
            "Loss after epoch 2254: 23604.0\n",
            "Loss after epoch 2255: 22760.0\n",
            "Loss after epoch 2256: 23372.0\n",
            "Loss after epoch 2257: 23316.0\n",
            "Loss after epoch 2258: 23176.0\n",
            "Loss after epoch 2259: 23052.0\n",
            "Loss after epoch 2260: 23024.0\n",
            "Loss after epoch 2261: 23992.0\n",
            "Loss after epoch 2262: 23020.0\n",
            "Loss after epoch 2263: 23640.0\n",
            "Loss after epoch 2264: 23592.0\n",
            "Loss after epoch 2265: 23104.0\n",
            "Loss after epoch 2266: 22676.0\n",
            "Loss after epoch 2267: 22664.0\n",
            "Loss after epoch 2268: 23896.0\n",
            "Loss after epoch 2269: 23612.0\n",
            "Loss after epoch 2270: 22844.0\n",
            "Loss after epoch 2271: 23932.0\n",
            "Loss after epoch 2272: 23164.0\n",
            "Loss after epoch 2273: 23236.0\n",
            "Loss after epoch 2274: 23020.0\n",
            "Loss after epoch 2275: 23180.0\n",
            "Loss after epoch 2276: 23272.0\n",
            "Loss after epoch 2277: 23220.0\n",
            "Loss after epoch 2278: 22928.0\n",
            "Loss after epoch 2279: 23184.0\n",
            "Loss after epoch 2280: 23192.0\n",
            "Loss after epoch 2281: 23564.0\n",
            "Loss after epoch 2282: 24032.0\n",
            "Loss after epoch 2283: 23004.0\n",
            "Loss after epoch 2284: 23520.0\n",
            "Loss after epoch 2285: 23708.0\n",
            "Loss after epoch 2286: 23232.0\n",
            "Loss after epoch 2287: 22908.0\n",
            "Loss after epoch 2288: 23568.0\n",
            "Loss after epoch 2289: 23484.0\n",
            "Loss after epoch 2290: 23464.0\n",
            "Loss after epoch 2291: 23804.0\n",
            "Loss after epoch 2292: 23404.0\n",
            "Loss after epoch 2293: 23512.0\n",
            "Loss after epoch 2294: 23592.0\n",
            "Loss after epoch 2295: 23376.0\n",
            "Loss after epoch 2296: 22960.0\n",
            "Loss after epoch 2297: 23372.0\n",
            "Loss after epoch 2298: 22880.0\n",
            "Loss after epoch 2299: 23640.0\n",
            "Loss after epoch 2300: 23172.0\n",
            "Loss after epoch 2301: 23212.0\n",
            "Loss after epoch 2302: 22744.0\n",
            "Loss after epoch 2303: 23152.0\n",
            "Loss after epoch 2304: 23752.0\n",
            "Loss after epoch 2305: 23268.0\n",
            "Loss after epoch 2306: 23072.0\n",
            "Loss after epoch 2307: 23312.0\n",
            "Loss after epoch 2308: 23296.0\n",
            "Loss after epoch 2309: 23244.0\n",
            "Loss after epoch 2310: 23144.0\n",
            "Loss after epoch 2311: 23096.0\n",
            "Loss after epoch 2312: 23124.0\n",
            "Loss after epoch 2313: 23248.0\n",
            "Loss after epoch 2314: 22864.0\n",
            "Loss after epoch 2315: 23668.0\n",
            "Loss after epoch 2316: 23040.0\n",
            "Loss after epoch 2317: 23508.0\n",
            "Loss after epoch 2318: 22860.0\n",
            "Loss after epoch 2319: 20456.0\n",
            "Loss after epoch 2320: 4328.0\n",
            "Loss after epoch 2321: 4784.0\n",
            "Loss after epoch 2322: 4752.0\n",
            "Loss after epoch 2323: 4544.0\n",
            "Loss after epoch 2324: 4624.0\n",
            "Loss after epoch 2325: 4440.0\n",
            "Loss after epoch 2326: 4144.0\n",
            "Loss after epoch 2327: 4408.0\n",
            "Loss after epoch 2328: 4232.0\n",
            "Loss after epoch 2329: 4680.0\n",
            "Loss after epoch 2330: 4328.0\n",
            "Loss after epoch 2331: 4776.0\n",
            "Loss after epoch 2332: 4520.0\n",
            "Loss after epoch 2333: 4672.0\n",
            "Loss after epoch 2334: 4440.0\n",
            "Loss after epoch 2335: 4400.0\n",
            "Loss after epoch 2336: 4664.0\n",
            "Loss after epoch 2337: 4648.0\n",
            "Loss after epoch 2338: 4544.0\n",
            "Loss after epoch 2339: 4456.0\n",
            "Loss after epoch 2340: 4600.0\n",
            "Loss after epoch 2341: 4624.0\n",
            "Loss after epoch 2342: 4680.0\n",
            "Loss after epoch 2343: 4768.0\n",
            "Loss after epoch 2344: 4760.0\n",
            "Loss after epoch 2345: 4552.0\n",
            "Loss after epoch 2346: 4560.0\n",
            "Loss after epoch 2347: 4792.0\n",
            "Loss after epoch 2348: 4440.0\n",
            "Loss after epoch 2349: 4384.0\n",
            "Loss after epoch 2350: 4568.0\n",
            "Loss after epoch 2351: 4600.0\n",
            "Loss after epoch 2352: 4712.0\n",
            "Loss after epoch 2353: 4408.0\n",
            "Loss after epoch 2354: 4992.0\n",
            "Loss after epoch 2355: 4136.0\n",
            "Loss after epoch 2356: 4528.0\n",
            "Loss after epoch 2357: 4304.0\n",
            "Loss after epoch 2358: 4920.0\n",
            "Loss after epoch 2359: 4528.0\n",
            "Loss after epoch 2360: 4904.0\n",
            "Loss after epoch 2361: 4592.0\n",
            "Loss after epoch 2362: 4624.0\n",
            "Loss after epoch 2363: 4480.0\n",
            "Loss after epoch 2364: 4424.0\n",
            "Loss after epoch 2365: 4816.0\n",
            "Loss after epoch 2366: 4600.0\n",
            "Loss after epoch 2367: 4392.0\n",
            "Loss after epoch 2368: 4464.0\n",
            "Loss after epoch 2369: 4568.0\n",
            "Loss after epoch 2370: 4096.0\n",
            "Loss after epoch 2371: 4752.0\n",
            "Loss after epoch 2372: 4176.0\n",
            "Loss after epoch 2373: 4544.0\n",
            "Loss after epoch 2374: 4720.0\n",
            "Loss after epoch 2375: 4544.0\n",
            "Loss after epoch 2376: 4680.0\n",
            "Loss after epoch 2377: 4704.0\n",
            "Loss after epoch 2378: 4680.0\n",
            "Loss after epoch 2379: 4544.0\n",
            "Loss after epoch 2380: 4648.0\n",
            "Loss after epoch 2381: 4528.0\n",
            "Loss after epoch 2382: 4328.0\n",
            "Loss after epoch 2383: 4472.0\n",
            "Loss after epoch 2384: 4856.0\n",
            "Loss after epoch 2385: 4640.0\n",
            "Loss after epoch 2386: 3936.0\n",
            "Loss after epoch 2387: 4568.0\n",
            "Loss after epoch 2388: 4480.0\n",
            "Loss after epoch 2389: 4848.0\n",
            "Loss after epoch 2390: 4440.0\n",
            "Loss after epoch 2391: 4336.0\n",
            "Loss after epoch 2392: 4400.0\n",
            "Loss after epoch 2393: 4688.0\n",
            "Loss after epoch 2394: 4400.0\n",
            "Loss after epoch 2395: 4592.0\n",
            "Loss after epoch 2396: 4304.0\n",
            "Loss after epoch 2397: 4424.0\n",
            "Loss after epoch 2398: 4304.0\n",
            "Loss after epoch 2399: 4640.0\n",
            "Loss after epoch 2400: 4520.0\n",
            "Loss after epoch 2401: 4240.0\n",
            "Loss after epoch 2402: 4720.0\n",
            "Loss after epoch 2403: 4456.0\n",
            "Loss after epoch 2404: 4464.0\n",
            "Loss after epoch 2405: 4520.0\n",
            "Loss after epoch 2406: 4416.0\n",
            "Loss after epoch 2407: 4528.0\n",
            "Loss after epoch 2408: 4552.0\n",
            "Loss after epoch 2409: 4608.0\n",
            "Loss after epoch 2410: 4768.0\n",
            "Loss after epoch 2411: 4384.0\n",
            "Loss after epoch 2412: 4736.0\n",
            "Loss after epoch 2413: 4280.0\n",
            "Loss after epoch 2414: 4296.0\n",
            "Loss after epoch 2415: 4312.0\n",
            "Loss after epoch 2416: 4128.0\n",
            "Loss after epoch 2417: 4480.0\n",
            "Loss after epoch 2418: 4408.0\n",
            "Loss after epoch 2419: 4408.0\n",
            "Loss after epoch 2420: 4232.0\n",
            "Loss after epoch 2421: 4272.0\n",
            "Loss after epoch 2422: 4416.0\n",
            "Loss after epoch 2423: 4504.0\n",
            "Loss after epoch 2424: 4640.0\n",
            "Loss after epoch 2425: 4568.0\n",
            "Loss after epoch 2426: 4488.0\n",
            "Loss after epoch 2427: 4552.0\n",
            "Loss after epoch 2428: 4392.0\n",
            "Loss after epoch 2429: 4536.0\n",
            "Loss after epoch 2430: 4576.0\n",
            "Loss after epoch 2431: 4360.0\n",
            "Loss after epoch 2432: 4872.0\n",
            "Loss after epoch 2433: 4168.0\n",
            "Loss after epoch 2434: 4344.0\n",
            "Loss after epoch 2435: 4440.0\n",
            "Loss after epoch 2436: 4872.0\n",
            "Loss after epoch 2437: 4280.0\n",
            "Loss after epoch 2438: 4416.0\n",
            "Loss after epoch 2439: 4416.0\n",
            "Loss after epoch 2440: 4824.0\n",
            "Loss after epoch 2441: 4272.0\n",
            "Loss after epoch 2442: 4264.0\n",
            "Loss after epoch 2443: 4456.0\n",
            "Loss after epoch 2444: 4760.0\n",
            "Loss after epoch 2445: 4528.0\n",
            "Loss after epoch 2446: 4392.0\n",
            "Loss after epoch 2447: 4336.0\n",
            "Loss after epoch 2448: 4728.0\n",
            "Loss after epoch 2449: 4464.0\n",
            "Loss after epoch 2450: 4320.0\n",
            "Loss after epoch 2451: 4528.0\n",
            "Loss after epoch 2452: 4680.0\n",
            "Loss after epoch 2453: 4304.0\n",
            "Loss after epoch 2454: 4320.0\n",
            "Loss after epoch 2455: 4792.0\n",
            "Loss after epoch 2456: 3984.0\n",
            "Loss after epoch 2457: 4312.0\n",
            "Loss after epoch 2458: 4384.0\n",
            "Loss after epoch 2459: 4768.0\n",
            "Loss after epoch 2460: 4184.0\n",
            "Loss after epoch 2461: 4352.0\n",
            "Loss after epoch 2462: 4640.0\n",
            "Loss after epoch 2463: 4784.0\n",
            "Loss after epoch 2464: 4368.0\n",
            "Loss after epoch 2465: 4304.0\n",
            "Loss after epoch 2466: 4504.0\n",
            "Loss after epoch 2467: 4488.0\n",
            "Loss after epoch 2468: 4704.0\n",
            "Loss after epoch 2469: 4168.0\n",
            "Loss after epoch 2470: 4504.0\n",
            "Loss after epoch 2471: 4328.0\n",
            "Loss after epoch 2472: 4632.0\n",
            "Loss after epoch 2473: 4512.0\n",
            "Loss after epoch 2474: 4392.0\n",
            "Loss after epoch 2475: 4256.0\n",
            "Loss after epoch 2476: 4392.0\n",
            "Loss after epoch 2477: 4424.0\n",
            "Loss after epoch 2478: 4232.0\n",
            "Loss after epoch 2479: 4168.0\n",
            "Loss after epoch 2480: 4856.0\n",
            "Loss after epoch 2481: 4360.0\n",
            "Loss after epoch 2482: 4640.0\n",
            "Loss after epoch 2483: 4456.0\n",
            "Loss after epoch 2484: 4472.0\n",
            "Loss after epoch 2485: 4512.0\n",
            "Loss after epoch 2486: 4416.0\n",
            "Loss after epoch 2487: 4448.0\n",
            "Loss after epoch 2488: 4424.0\n",
            "Loss after epoch 2489: 4576.0\n",
            "Loss after epoch 2490: 4384.0\n",
            "Loss after epoch 2491: 4720.0\n",
            "Loss after epoch 2492: 4584.0\n",
            "Loss after epoch 2493: 4464.0\n",
            "Loss after epoch 2494: 4136.0\n",
            "Loss after epoch 2495: 4592.0\n",
            "Loss after epoch 2496: 4624.0\n",
            "Loss after epoch 2497: 4144.0\n",
            "Loss after epoch 2498: 4320.0\n",
            "Loss after epoch 2499: 4608.0\n",
            "Loss after epoch 2500: 4808.0\n",
            "Loss after epoch 2501: 4248.0\n",
            "Loss after epoch 2502: 4712.0\n",
            "Loss after epoch 2503: 4504.0\n",
            "Loss after epoch 2504: 4472.0\n",
            "Loss after epoch 2505: 4280.0\n",
            "Loss after epoch 2506: 4456.0\n",
            "Loss after epoch 2507: 4296.0\n",
            "Loss after epoch 2508: 4088.0\n",
            "Loss after epoch 2509: 4232.0\n",
            "Loss after epoch 2510: 4936.0\n",
            "Loss after epoch 2511: 4376.0\n",
            "Loss after epoch 2512: 4392.0\n",
            "Loss after epoch 2513: 4560.0\n",
            "Loss after epoch 2514: 4352.0\n",
            "Loss after epoch 2515: 4488.0\n",
            "Loss after epoch 2516: 4536.0\n",
            "Loss after epoch 2517: 4216.0\n",
            "Loss after epoch 2518: 4104.0\n",
            "Loss after epoch 2519: 4936.0\n",
            "Loss after epoch 2520: 4200.0\n",
            "Loss after epoch 2521: 4536.0\n",
            "Loss after epoch 2522: 4000.0\n",
            "Loss after epoch 2523: 4216.0\n",
            "Loss after epoch 2524: 4048.0\n",
            "Loss after epoch 2525: 4616.0\n",
            "Loss after epoch 2526: 4424.0\n",
            "Loss after epoch 2527: 4792.0\n",
            "Loss after epoch 2528: 4232.0\n",
            "Loss after epoch 2529: 4120.0\n",
            "Loss after epoch 2530: 4360.0\n",
            "Loss after epoch 2531: 4040.0\n",
            "Loss after epoch 2532: 4608.0\n",
            "Loss after epoch 2533: 4184.0\n",
            "Loss after epoch 2534: 4856.0\n",
            "Loss after epoch 2535: 4376.0\n",
            "Loss after epoch 2536: 4192.0\n",
            "Loss after epoch 2537: 4112.0\n",
            "Loss after epoch 2538: 4656.0\n",
            "Loss after epoch 2539: 4440.0\n",
            "Loss after epoch 2540: 4712.0\n",
            "Loss after epoch 2541: 4072.0\n",
            "Loss after epoch 2542: 4424.0\n",
            "Loss after epoch 2543: 4472.0\n",
            "Loss after epoch 2544: 4088.0\n",
            "Loss after epoch 2545: 4632.0\n",
            "Loss after epoch 2546: 4624.0\n",
            "Loss after epoch 2547: 4408.0\n",
            "Loss after epoch 2548: 4536.0\n",
            "Loss after epoch 2549: 4464.0\n",
            "Loss after epoch 2550: 4488.0\n",
            "Loss after epoch 2551: 4584.0\n",
            "Loss after epoch 2552: 4328.0\n",
            "Loss after epoch 2553: 4008.0\n",
            "Loss after epoch 2554: 4600.0\n",
            "Loss after epoch 2555: 4232.0\n",
            "Loss after epoch 2556: 4536.0\n",
            "Loss after epoch 2557: 4160.0\n",
            "Loss after epoch 2558: 4496.0\n",
            "Loss after epoch 2559: 4408.0\n",
            "Loss after epoch 2560: 3760.0\n",
            "Loss after epoch 2561: 4272.0\n",
            "Loss after epoch 2562: 4024.0\n",
            "Loss after epoch 2563: 4432.0\n",
            "Loss after epoch 2564: 4552.0\n",
            "Loss after epoch 2565: 4016.0\n",
            "Loss after epoch 2566: 4472.0\n",
            "Loss after epoch 2567: 4240.0\n",
            "Loss after epoch 2568: 4152.0\n",
            "Loss after epoch 2569: 4200.0\n",
            "Loss after epoch 2570: 4608.0\n",
            "Loss after epoch 2571: 4208.0\n",
            "Loss after epoch 2572: 4120.0\n",
            "Loss after epoch 2573: 4368.0\n",
            "Loss after epoch 2574: 4304.0\n",
            "Loss after epoch 2575: 4008.0\n",
            "Loss after epoch 2576: 4520.0\n",
            "Loss after epoch 2577: 4528.0\n",
            "Loss after epoch 2578: 4312.0\n",
            "Loss after epoch 2579: 4248.0\n",
            "Loss after epoch 2580: 4584.0\n",
            "Loss after epoch 2581: 4592.0\n",
            "Loss after epoch 2582: 4096.0\n",
            "Loss after epoch 2583: 4168.0\n",
            "Loss after epoch 2584: 4048.0\n",
            "Loss after epoch 2585: 4368.0\n",
            "Loss after epoch 2586: 4264.0\n",
            "Loss after epoch 2587: 4504.0\n",
            "Loss after epoch 2588: 4544.0\n",
            "Loss after epoch 2589: 4320.0\n",
            "Loss after epoch 2590: 4432.0\n",
            "Loss after epoch 2591: 4504.0\n",
            "Loss after epoch 2592: 4440.0\n",
            "Loss after epoch 2593: 4288.0\n",
            "Loss after epoch 2594: 4752.0\n",
            "Loss after epoch 2595: 4496.0\n",
            "Loss after epoch 2596: 4136.0\n",
            "Loss after epoch 2597: 4192.0\n",
            "Loss after epoch 2598: 3984.0\n",
            "Loss after epoch 2599: 4592.0\n",
            "Loss after epoch 2600: 4016.0\n",
            "Loss after epoch 2601: 4512.0\n",
            "Loss after epoch 2602: 4384.0\n",
            "Loss after epoch 2603: 4208.0\n",
            "Loss after epoch 2604: 4304.0\n",
            "Loss after epoch 2605: 4480.0\n",
            "Loss after epoch 2606: 4240.0\n",
            "Loss after epoch 2607: 3944.0\n",
            "Loss after epoch 2608: 4432.0\n",
            "Loss after epoch 2609: 4224.0\n",
            "Loss after epoch 2610: 4520.0\n",
            "Loss after epoch 2611: 4104.0\n",
            "Loss after epoch 2612: 4248.0\n",
            "Loss after epoch 2613: 4296.0\n",
            "Loss after epoch 2614: 4296.0\n",
            "Loss after epoch 2615: 4728.0\n",
            "Loss after epoch 2616: 4000.0\n",
            "Loss after epoch 2617: 3944.0\n",
            "Loss after epoch 2618: 4632.0\n",
            "Loss after epoch 2619: 4504.0\n",
            "Loss after epoch 2620: 4384.0\n",
            "Loss after epoch 2621: 4208.0\n",
            "Loss after epoch 2622: 4056.0\n",
            "Loss after epoch 2623: 4240.0\n",
            "Loss after epoch 2624: 4504.0\n",
            "Loss after epoch 2625: 4320.0\n",
            "Loss after epoch 2626: 4256.0\n",
            "Loss after epoch 2627: 4368.0\n",
            "Loss after epoch 2628: 4264.0\n",
            "Loss after epoch 2629: 4200.0\n",
            "Loss after epoch 2630: 4272.0\n",
            "Loss after epoch 2631: 4456.0\n",
            "Loss after epoch 2632: 4184.0\n",
            "Loss after epoch 2633: 4048.0\n",
            "Loss after epoch 2634: 4640.0\n",
            "Loss after epoch 2635: 4392.0\n",
            "Loss after epoch 2636: 3976.0\n",
            "Loss after epoch 2637: 4216.0\n",
            "Loss after epoch 2638: 4176.0\n",
            "Loss after epoch 2639: 4056.0\n",
            "Loss after epoch 2640: 4632.0\n",
            "Loss after epoch 2641: 4272.0\n",
            "Loss after epoch 2642: 4464.0\n",
            "Loss after epoch 2643: 4328.0\n",
            "Loss after epoch 2644: 4344.0\n",
            "Loss after epoch 2645: 4448.0\n",
            "Loss after epoch 2646: 4056.0\n",
            "Loss after epoch 2647: 4288.0\n",
            "Loss after epoch 2648: 4320.0\n",
            "Loss after epoch 2649: 3776.0\n",
            "Loss after epoch 2650: 4232.0\n",
            "Loss after epoch 2651: 4280.0\n",
            "Loss after epoch 2652: 4368.0\n",
            "Loss after epoch 2653: 4376.0\n",
            "Loss after epoch 2654: 4624.0\n",
            "Loss after epoch 2655: 4016.0\n",
            "Loss after epoch 2656: 4176.0\n",
            "Loss after epoch 2657: 4208.0\n",
            "Loss after epoch 2658: 3600.0\n",
            "Loss after epoch 2659: 4216.0\n",
            "Loss after epoch 2660: 4240.0\n",
            "Loss after epoch 2661: 4296.0\n",
            "Loss after epoch 2662: 4336.0\n",
            "Loss after epoch 2663: 4200.0\n",
            "Loss after epoch 2664: 4216.0\n",
            "Loss after epoch 2665: 4360.0\n",
            "Loss after epoch 2666: 4376.0\n",
            "Loss after epoch 2667: 4168.0\n",
            "Loss after epoch 2668: 3976.0\n",
            "Loss after epoch 2669: 4240.0\n",
            "Loss after epoch 2670: 4216.0\n",
            "Loss after epoch 2671: 4528.0\n",
            "Loss after epoch 2672: 4392.0\n",
            "Loss after epoch 2673: 4264.0\n",
            "Loss after epoch 2674: 4480.0\n",
            "Loss after epoch 2675: 4184.0\n",
            "Loss after epoch 2676: 4248.0\n",
            "Loss after epoch 2677: 4216.0\n",
            "Loss after epoch 2678: 4704.0\n",
            "Loss after epoch 2679: 3808.0\n",
            "Loss after epoch 2680: 4288.0\n",
            "Loss after epoch 2681: 4168.0\n",
            "Loss after epoch 2682: 4208.0\n",
            "Loss after epoch 2683: 4296.0\n",
            "Loss after epoch 2684: 3816.0\n",
            "Loss after epoch 2685: 4288.0\n",
            "Loss after epoch 2686: 4232.0\n",
            "Loss after epoch 2687: 4120.0\n",
            "Loss after epoch 2688: 4152.0\n",
            "Loss after epoch 2689: 4624.0\n",
            "Loss after epoch 2690: 4120.0\n",
            "Loss after epoch 2691: 4096.0\n",
            "Loss after epoch 2692: 4112.0\n",
            "Loss after epoch 2693: 4016.0\n",
            "Loss after epoch 2694: 4176.0\n",
            "Loss after epoch 2695: 4216.0\n",
            "Loss after epoch 2696: 4168.0\n",
            "Loss after epoch 2697: 4520.0\n",
            "Loss after epoch 2698: 4304.0\n",
            "Loss after epoch 2699: 4184.0\n",
            "Loss after epoch 2700: 4160.0\n",
            "Loss after epoch 2701: 4408.0\n",
            "Loss after epoch 2702: 3808.0\n",
            "Loss after epoch 2703: 4296.0\n",
            "Loss after epoch 2704: 4128.0\n",
            "Loss after epoch 2705: 4176.0\n",
            "Loss after epoch 2706: 4248.0\n",
            "Loss after epoch 2707: 4232.0\n",
            "Loss after epoch 2708: 4064.0\n",
            "Loss after epoch 2709: 4208.0\n",
            "Loss after epoch 2710: 3944.0\n",
            "Loss after epoch 2711: 4160.0\n",
            "Loss after epoch 2712: 4216.0\n",
            "Loss after epoch 2713: 4120.0\n",
            "Loss after epoch 2714: 3712.0\n",
            "Loss after epoch 2715: 4408.0\n",
            "Loss after epoch 2716: 4488.0\n",
            "Loss after epoch 2717: 4368.0\n",
            "Loss after epoch 2718: 4112.0\n",
            "Loss after epoch 2719: 4104.0\n",
            "Loss after epoch 2720: 4288.0\n",
            "Loss after epoch 2721: 4264.0\n",
            "Loss after epoch 2722: 4224.0\n",
            "Loss after epoch 2723: 3968.0\n",
            "Loss after epoch 2724: 4096.0\n",
            "Loss after epoch 2725: 4440.0\n",
            "Loss after epoch 2726: 4464.0\n",
            "Loss after epoch 2727: 4592.0\n",
            "Loss after epoch 2728: 4096.0\n",
            "Loss after epoch 2729: 4536.0\n",
            "Loss after epoch 2730: 4072.0\n",
            "Loss after epoch 2731: 4456.0\n",
            "Loss after epoch 2732: 4416.0\n",
            "Loss after epoch 2733: 4152.0\n",
            "Loss after epoch 2734: 4672.0\n",
            "Loss after epoch 2735: 4208.0\n",
            "Loss after epoch 2736: 4448.0\n",
            "Loss after epoch 2737: 3968.0\n",
            "Loss after epoch 2738: 4456.0\n",
            "Loss after epoch 2739: 4168.0\n",
            "Loss after epoch 2740: 4464.0\n",
            "Loss after epoch 2741: 4136.0\n",
            "Loss after epoch 2742: 4408.0\n",
            "Loss after epoch 2743: 4224.0\n",
            "Loss after epoch 2744: 4264.0\n",
            "Loss after epoch 2745: 4224.0\n",
            "Loss after epoch 2746: 4504.0\n",
            "Loss after epoch 2747: 3952.0\n",
            "Loss after epoch 2748: 4080.0\n",
            "Loss after epoch 2749: 4128.0\n",
            "Loss after epoch 2750: 4440.0\n",
            "Loss after epoch 2751: 3880.0\n",
            "Loss after epoch 2752: 4240.0\n",
            "Loss after epoch 2753: 4392.0\n",
            "Loss after epoch 2754: 4272.0\n",
            "Loss after epoch 2755: 4040.0\n",
            "Loss after epoch 2756: 4312.0\n",
            "Loss after epoch 2757: 4296.0\n",
            "Loss after epoch 2758: 4552.0\n",
            "Loss after epoch 2759: 4360.0\n",
            "Loss after epoch 2760: 4560.0\n",
            "Loss after epoch 2761: 4376.0\n",
            "Loss after epoch 2762: 4096.0\n",
            "Loss after epoch 2763: 4296.0\n",
            "Loss after epoch 2764: 4344.0\n",
            "Loss after epoch 2765: 4160.0\n",
            "Loss after epoch 2766: 4120.0\n",
            "Loss after epoch 2767: 4072.0\n",
            "Loss after epoch 2768: 4208.0\n",
            "Loss after epoch 2769: 4216.0\n",
            "Loss after epoch 2770: 4576.0\n",
            "Loss after epoch 2771: 4192.0\n",
            "Loss after epoch 2772: 3872.0\n",
            "Loss after epoch 2773: 4208.0\n",
            "Loss after epoch 2774: 4488.0\n",
            "Loss after epoch 2775: 4032.0\n",
            "Loss after epoch 2776: 4176.0\n",
            "Loss after epoch 2777: 4320.0\n",
            "Loss after epoch 2778: 3944.0\n",
            "Loss after epoch 2779: 4280.0\n",
            "Loss after epoch 2780: 3976.0\n",
            "Loss after epoch 2781: 4216.0\n",
            "Loss after epoch 2782: 4216.0\n",
            "Loss after epoch 2783: 4328.0\n",
            "Loss after epoch 2784: 4080.0\n",
            "Loss after epoch 2785: 4232.0\n",
            "Loss after epoch 2786: 4272.0\n",
            "Loss after epoch 2787: 4344.0\n",
            "Loss after epoch 2788: 4168.0\n",
            "Loss after epoch 2789: 3976.0\n",
            "Loss after epoch 2790: 4136.0\n",
            "Loss after epoch 2791: 4216.0\n",
            "Loss after epoch 2792: 3704.0\n",
            "Loss after epoch 2793: 4520.0\n",
            "Loss after epoch 2794: 4640.0\n",
            "Loss after epoch 2795: 4096.0\n",
            "Loss after epoch 2796: 4240.0\n",
            "Loss after epoch 2797: 4200.0\n",
            "Loss after epoch 2798: 4160.0\n",
            "Loss after epoch 2799: 4504.0\n",
            "Loss after epoch 2800: 4208.0\n",
            "Loss after epoch 2801: 4352.0\n",
            "Loss after epoch 2802: 4032.0\n",
            "Loss after epoch 2803: 4008.0\n",
            "Loss after epoch 2804: 4360.0\n",
            "Loss after epoch 2805: 4352.0\n",
            "Loss after epoch 2806: 3568.0\n",
            "Loss after epoch 2807: 4168.0\n",
            "Loss after epoch 2808: 4000.0\n",
            "Loss after epoch 2809: 3952.0\n",
            "Loss after epoch 2810: 3976.0\n",
            "Loss after epoch 2811: 3960.0\n",
            "Loss after epoch 2812: 4320.0\n",
            "Loss after epoch 2813: 3928.0\n",
            "Loss after epoch 2814: 4208.0\n",
            "Loss after epoch 2815: 4104.0\n",
            "Loss after epoch 2816: 4184.0\n",
            "Loss after epoch 2817: 3960.0\n",
            "Loss after epoch 2818: 4336.0\n",
            "Loss after epoch 2819: 4352.0\n",
            "Loss after epoch 2820: 3704.0\n",
            "Loss after epoch 2821: 4176.0\n",
            "Loss after epoch 2822: 3888.0\n",
            "Loss after epoch 2823: 4456.0\n",
            "Loss after epoch 2824: 4376.0\n",
            "Loss after epoch 2825: 4184.0\n",
            "Loss after epoch 2826: 4488.0\n",
            "Loss after epoch 2827: 4088.0\n",
            "Loss after epoch 2828: 3904.0\n",
            "Loss after epoch 2829: 4120.0\n",
            "Loss after epoch 2830: 4008.0\n",
            "Loss after epoch 2831: 3896.0\n",
            "Loss after epoch 2832: 4344.0\n",
            "Loss after epoch 2833: 4200.0\n",
            "Loss after epoch 2834: 4104.0\n",
            "Loss after epoch 2835: 3816.0\n",
            "Loss after epoch 2836: 4608.0\n",
            "Loss after epoch 2837: 3848.0\n",
            "Loss after epoch 2838: 4024.0\n",
            "Loss after epoch 2839: 4176.0\n",
            "Loss after epoch 2840: 4032.0\n",
            "Loss after epoch 2841: 4208.0\n",
            "Loss after epoch 2842: 3912.0\n",
            "Loss after epoch 2843: 4008.0\n",
            "Loss after epoch 2844: 4248.0\n",
            "Loss after epoch 2845: 4160.0\n",
            "Loss after epoch 2846: 4200.0\n",
            "Loss after epoch 2847: 4032.0\n",
            "Loss after epoch 2848: 4064.0\n",
            "Loss after epoch 2849: 4408.0\n",
            "Loss after epoch 2850: 4384.0\n",
            "Loss after epoch 2851: 4128.0\n",
            "Loss after epoch 2852: 3872.0\n",
            "Loss after epoch 2853: 4280.0\n",
            "Loss after epoch 2854: 4312.0\n",
            "Loss after epoch 2855: 4248.0\n",
            "Loss after epoch 2856: 4088.0\n",
            "Loss after epoch 2857: 4088.0\n",
            "Loss after epoch 2858: 4096.0\n",
            "Loss after epoch 2859: 4288.0\n",
            "Loss after epoch 2860: 3680.0\n",
            "Loss after epoch 2861: 4008.0\n",
            "Loss after epoch 2862: 4016.0\n",
            "Loss after epoch 2863: 4208.0\n",
            "Loss after epoch 2864: 4104.0\n",
            "Loss after epoch 2865: 4136.0\n",
            "Loss after epoch 2866: 4032.0\n",
            "Loss after epoch 2867: 3832.0\n",
            "Loss after epoch 2868: 4376.0\n",
            "Loss after epoch 2869: 4312.0\n",
            "Loss after epoch 2870: 3896.0\n",
            "Loss after epoch 2871: 4320.0\n",
            "Loss after epoch 2872: 4240.0\n",
            "Loss after epoch 2873: 4320.0\n",
            "Loss after epoch 2874: 4472.0\n",
            "Loss after epoch 2875: 4104.0\n",
            "Loss after epoch 2876: 4408.0\n",
            "Loss after epoch 2877: 4184.0\n",
            "Loss after epoch 2878: 4008.0\n",
            "Loss after epoch 2879: 4216.0\n",
            "Loss after epoch 2880: 3824.0\n",
            "Loss after epoch 2881: 3976.0\n",
            "Loss after epoch 2882: 4320.0\n",
            "Loss after epoch 2883: 4176.0\n",
            "Loss after epoch 2884: 4120.0\n",
            "Loss after epoch 2885: 4064.0\n",
            "Loss after epoch 2886: 4224.0\n",
            "Loss after epoch 2887: 4280.0\n",
            "Loss after epoch 2888: 4128.0\n",
            "Loss after epoch 2889: 4232.0\n",
            "Loss after epoch 2890: 4144.0\n",
            "Loss after epoch 2891: 4064.0\n",
            "Loss after epoch 2892: 3904.0\n",
            "Loss after epoch 2893: 3744.0\n",
            "Loss after epoch 2894: 4200.0\n",
            "Loss after epoch 2895: 4016.0\n",
            "Loss after epoch 2896: 4016.0\n",
            "Loss after epoch 2897: 4120.0\n",
            "Loss after epoch 2898: 4072.0\n",
            "Loss after epoch 2899: 4208.0\n",
            "Loss after epoch 2900: 3960.0\n",
            "Loss after epoch 2901: 3944.0\n",
            "Loss after epoch 2902: 4136.0\n",
            "Loss after epoch 2903: 3872.0\n",
            "Loss after epoch 2904: 4056.0\n",
            "Loss after epoch 2905: 4024.0\n",
            "Loss after epoch 2906: 4224.0\n",
            "Loss after epoch 2907: 4152.0\n",
            "Loss after epoch 2908: 4400.0\n",
            "Loss after epoch 2909: 4064.0\n",
            "Loss after epoch 2910: 4064.0\n",
            "Loss after epoch 2911: 4240.0\n",
            "Loss after epoch 2912: 4296.0\n",
            "Loss after epoch 2913: 4080.0\n",
            "Loss after epoch 2914: 3936.0\n",
            "Loss after epoch 2915: 4432.0\n",
            "Loss after epoch 2916: 4272.0\n",
            "Loss after epoch 2917: 3800.0\n",
            "Loss after epoch 2918: 4112.0\n",
            "Loss after epoch 2919: 3680.0\n",
            "Loss after epoch 2920: 3840.0\n",
            "Loss after epoch 2921: 4056.0\n",
            "Loss after epoch 2922: 3824.0\n",
            "Loss after epoch 2923: 4192.0\n",
            "Loss after epoch 2924: 4192.0\n",
            "Loss after epoch 2925: 3896.0\n",
            "Loss after epoch 2926: 3808.0\n",
            "Loss after epoch 2927: 4000.0\n",
            "Loss after epoch 2928: 3968.0\n",
            "Loss after epoch 2929: 3896.0\n",
            "Loss after epoch 2930: 4168.0\n",
            "Loss after epoch 2931: 4144.0\n",
            "Loss after epoch 2932: 4376.0\n",
            "Loss after epoch 2933: 3880.0\n",
            "Loss after epoch 2934: 4424.0\n",
            "Loss after epoch 2935: 4152.0\n",
            "Loss after epoch 2936: 3984.0\n",
            "Loss after epoch 2937: 4408.0\n",
            "Loss after epoch 2938: 3936.0\n",
            "Loss after epoch 2939: 4232.0\n",
            "Loss after epoch 2940: 3960.0\n",
            "Loss after epoch 2941: 4120.0\n",
            "Loss after epoch 2942: 4432.0\n",
            "Loss after epoch 2943: 4104.0\n",
            "Loss after epoch 2944: 4264.0\n",
            "Loss after epoch 2945: 3848.0\n",
            "Loss after epoch 2946: 4296.0\n",
            "Loss after epoch 2947: 4224.0\n",
            "Loss after epoch 2948: 4056.0\n",
            "Loss after epoch 2949: 4192.0\n",
            "Loss after epoch 2950: 3976.0\n",
            "Loss after epoch 2951: 3904.0\n",
            "Loss after epoch 2952: 4128.0\n",
            "Loss after epoch 2953: 4232.0\n",
            "Loss after epoch 2954: 3720.0\n",
            "Loss after epoch 2955: 4192.0\n",
            "Loss after epoch 2956: 3896.0\n",
            "Loss after epoch 2957: 4096.0\n",
            "Loss after epoch 2958: 4160.0\n",
            "Loss after epoch 2959: 4136.0\n",
            "Loss after epoch 2960: 4112.0\n",
            "Loss after epoch 2961: 3880.0\n",
            "Loss after epoch 2962: 3944.0\n",
            "Loss after epoch 2963: 3992.0\n",
            "Loss after epoch 2964: 4144.0\n",
            "Loss after epoch 2965: 4152.0\n",
            "Loss after epoch 2966: 4320.0\n",
            "Loss after epoch 2967: 4208.0\n",
            "Loss after epoch 2968: 3912.0\n",
            "Loss after epoch 2969: 4296.0\n",
            "Loss after epoch 2970: 3784.0\n",
            "Loss after epoch 2971: 4136.0\n",
            "Loss after epoch 2972: 4432.0\n",
            "Loss after epoch 2973: 4160.0\n",
            "Loss after epoch 2974: 3608.0\n",
            "Loss after epoch 2975: 3552.0\n",
            "Loss after epoch 2976: 4056.0\n",
            "Loss after epoch 2977: 3920.0\n",
            "Loss after epoch 2978: 4088.0\n",
            "Loss after epoch 2979: 4136.0\n",
            "Loss after epoch 2980: 4056.0\n",
            "Loss after epoch 2981: 4224.0\n",
            "Loss after epoch 2982: 3840.0\n",
            "Loss after epoch 2983: 3968.0\n",
            "Loss after epoch 2984: 3576.0\n",
            "Loss after epoch 2985: 4096.0\n",
            "Loss after epoch 2986: 4024.0\n",
            "Loss after epoch 2987: 4360.0\n",
            "Loss after epoch 2988: 3656.0\n",
            "Loss after epoch 2989: 4208.0\n",
            "Loss after epoch 2990: 4144.0\n",
            "Loss after epoch 2991: 3968.0\n",
            "Loss after epoch 2992: 3744.0\n",
            "Loss after epoch 2993: 3720.0\n",
            "Loss after epoch 2994: 4064.0\n",
            "Loss after epoch 2995: 3624.0\n",
            "Loss after epoch 2996: 3872.0\n",
            "Loss after epoch 2997: 4264.0\n",
            "Loss after epoch 2998: 4184.0\n",
            "Loss after epoch 2999: 4112.0\n",
            "Loss after epoch 3000: 3984.0\n",
            "Loss after epoch 3001: 3864.0\n",
            "Loss after epoch 3002: 4104.0\n",
            "Loss after epoch 3003: 3864.0\n",
            "Loss after epoch 3004: 3896.0\n",
            "Loss after epoch 3005: 3952.0\n",
            "Loss after epoch 3006: 3784.0\n",
            "Loss after epoch 3007: 4144.0\n",
            "Loss after epoch 3008: 4160.0\n",
            "Loss after epoch 3009: 3904.0\n",
            "Loss after epoch 3010: 3680.0\n",
            "Loss after epoch 3011: 4144.0\n",
            "Loss after epoch 3012: 4120.0\n",
            "Loss after epoch 3013: 4080.0\n",
            "Loss after epoch 3014: 3912.0\n",
            "Loss after epoch 3015: 3896.0\n",
            "Loss after epoch 3016: 4288.0\n",
            "Loss after epoch 3017: 3784.0\n",
            "Loss after epoch 3018: 4104.0\n",
            "Loss after epoch 3019: 4272.0\n",
            "Loss after epoch 3020: 4368.0\n",
            "Loss after epoch 3021: 4016.0\n",
            "Loss after epoch 3022: 3952.0\n",
            "Loss after epoch 3023: 4120.0\n",
            "Loss after epoch 3024: 3968.0\n",
            "Loss after epoch 3025: 4312.0\n",
            "Loss after epoch 3026: 4208.0\n",
            "Loss after epoch 3027: 4096.0\n",
            "Loss after epoch 3028: 4232.0\n",
            "Loss after epoch 3029: 4136.0\n",
            "Loss after epoch 3030: 3952.0\n",
            "Loss after epoch 3031: 3992.0\n",
            "Loss after epoch 3032: 3960.0\n",
            "Loss after epoch 3033: 4080.0\n",
            "Loss after epoch 3034: 3752.0\n",
            "Loss after epoch 3035: 4016.0\n",
            "Loss after epoch 3036: 3880.0\n",
            "Loss after epoch 3037: 3928.0\n",
            "Loss after epoch 3038: 3928.0\n",
            "Loss after epoch 3039: 3976.0\n",
            "Loss after epoch 3040: 4152.0\n",
            "Loss after epoch 3041: 4480.0\n",
            "Loss after epoch 3042: 4080.0\n",
            "Loss after epoch 3043: 3680.0\n",
            "Loss after epoch 3044: 3888.0\n",
            "Loss after epoch 3045: 3992.0\n",
            "Loss after epoch 3046: 4312.0\n",
            "Loss after epoch 3047: 3992.0\n",
            "Loss after epoch 3048: 4064.0\n",
            "Loss after epoch 3049: 3976.0\n",
            "Loss after epoch 3050: 4160.0\n",
            "Loss after epoch 3051: 3704.0\n",
            "Loss after epoch 3052: 4168.0\n",
            "Loss after epoch 3053: 4056.0\n",
            "Loss after epoch 3054: 4064.0\n",
            "Loss after epoch 3055: 3816.0\n",
            "Loss after epoch 3056: 3888.0\n",
            "Loss after epoch 3057: 3656.0\n",
            "Loss after epoch 3058: 3920.0\n",
            "Loss after epoch 3059: 4192.0\n",
            "Loss after epoch 3060: 3824.0\n",
            "Loss after epoch 3061: 3632.0\n",
            "Loss after epoch 3062: 3872.0\n",
            "Loss after epoch 3063: 4360.0\n",
            "Loss after epoch 3064: 3984.0\n",
            "Loss after epoch 3065: 3848.0\n",
            "Loss after epoch 3066: 3792.0\n",
            "Loss after epoch 3067: 4192.0\n",
            "Loss after epoch 3068: 3784.0\n",
            "Loss after epoch 3069: 3736.0\n",
            "Loss after epoch 3070: 3784.0\n",
            "Loss after epoch 3071: 4056.0\n",
            "Loss after epoch 3072: 4160.0\n",
            "Loss after epoch 3073: 4096.0\n",
            "Loss after epoch 3074: 3568.0\n",
            "Loss after epoch 3075: 4192.0\n",
            "Loss after epoch 3076: 4168.0\n",
            "Loss after epoch 3077: 4136.0\n",
            "Loss after epoch 3078: 3744.0\n",
            "Loss after epoch 3079: 3600.0\n",
            "Loss after epoch 3080: 3896.0\n",
            "Loss after epoch 3081: 3920.0\n",
            "Loss after epoch 3082: 4080.0\n",
            "Loss after epoch 3083: 3680.0\n",
            "Loss after epoch 3084: 3632.0\n",
            "Loss after epoch 3085: 3776.0\n",
            "Loss after epoch 3086: 3928.0\n",
            "Loss after epoch 3087: 4128.0\n",
            "Loss after epoch 3088: 3816.0\n",
            "Loss after epoch 3089: 4112.0\n",
            "Loss after epoch 3090: 4080.0\n",
            "Loss after epoch 3091: 4152.0\n",
            "Loss after epoch 3092: 4296.0\n",
            "Loss after epoch 3093: 3768.0\n",
            "Loss after epoch 3094: 3904.0\n",
            "Loss after epoch 3095: 3640.0\n",
            "Loss after epoch 3096: 4112.0\n",
            "Loss after epoch 3097: 3968.0\n",
            "Loss after epoch 3098: 3624.0\n",
            "Loss after epoch 3099: 3888.0\n",
            "Loss after epoch 3100: 4136.0\n",
            "Loss after epoch 3101: 4496.0\n",
            "Loss after epoch 3102: 4152.0\n",
            "Loss after epoch 3103: 3520.0\n",
            "Loss after epoch 3104: 3792.0\n",
            "Loss after epoch 3105: 3800.0\n",
            "Loss after epoch 3106: 4352.0\n",
            "Loss after epoch 3107: 3944.0\n",
            "Loss after epoch 3108: 3656.0\n",
            "Loss after epoch 3109: 4088.0\n",
            "Loss after epoch 3110: 4016.0\n",
            "Loss after epoch 3111: 3848.0\n",
            "Loss after epoch 3112: 4016.0\n",
            "Loss after epoch 3113: 4336.0\n",
            "Loss after epoch 3114: 3920.0\n",
            "Loss after epoch 3115: 4288.0\n",
            "Loss after epoch 3116: 3760.0\n",
            "Loss after epoch 3117: 4120.0\n",
            "Loss after epoch 3118: 3832.0\n",
            "Loss after epoch 3119: 3840.0\n",
            "Loss after epoch 3120: 4040.0\n",
            "Loss after epoch 3121: 3944.0\n",
            "Loss after epoch 3122: 4368.0\n",
            "Loss after epoch 3123: 3760.0\n",
            "Loss after epoch 3124: 4352.0\n",
            "Loss after epoch 3125: 3848.0\n",
            "Loss after epoch 3126: 4008.0\n",
            "Loss after epoch 3127: 4000.0\n",
            "Loss after epoch 3128: 3824.0\n",
            "Loss after epoch 3129: 3944.0\n",
            "Loss after epoch 3130: 3880.0\n",
            "Loss after epoch 3131: 4096.0\n",
            "Loss after epoch 3132: 4144.0\n",
            "Loss after epoch 3133: 3904.0\n",
            "Loss after epoch 3134: 3888.0\n",
            "Loss after epoch 3135: 4240.0\n",
            "Loss after epoch 3136: 3720.0\n",
            "Loss after epoch 3137: 4344.0\n",
            "Loss after epoch 3138: 3752.0\n",
            "Loss after epoch 3139: 3872.0\n",
            "Loss after epoch 3140: 4000.0\n",
            "Loss after epoch 3141: 3776.0\n",
            "Loss after epoch 3142: 4048.0\n",
            "Loss after epoch 3143: 4128.0\n",
            "Loss after epoch 3144: 3904.0\n",
            "Loss after epoch 3145: 3808.0\n",
            "Loss after epoch 3146: 4088.0\n",
            "Loss after epoch 3147: 3680.0\n",
            "Loss after epoch 3148: 3888.0\n",
            "Loss after epoch 3149: 3904.0\n",
            "Loss after epoch 3150: 4216.0\n",
            "Loss after epoch 3151: 4120.0\n",
            "Loss after epoch 3152: 3752.0\n",
            "Loss after epoch 3153: 3968.0\n",
            "Loss after epoch 3154: 3960.0\n",
            "Loss after epoch 3155: 3808.0\n",
            "Loss after epoch 3156: 3792.0\n",
            "Loss after epoch 3157: 3752.0\n",
            "Loss after epoch 3158: 3600.0\n",
            "Loss after epoch 3159: 3784.0\n",
            "Loss after epoch 3160: 4480.0\n",
            "Loss after epoch 3161: 3872.0\n",
            "Loss after epoch 3162: 3880.0\n",
            "Loss after epoch 3163: 3688.0\n",
            "Loss after epoch 3164: 3728.0\n",
            "Loss after epoch 3165: 4192.0\n",
            "Loss after epoch 3166: 3624.0\n",
            "Loss after epoch 3167: 3992.0\n",
            "Loss after epoch 3168: 4040.0\n",
            "Loss after epoch 3169: 3792.0\n",
            "Loss after epoch 3170: 3968.0\n",
            "Loss after epoch 3171: 3728.0\n",
            "Loss after epoch 3172: 3840.0\n",
            "Loss after epoch 3173: 3928.0\n",
            "Loss after epoch 3174: 4120.0\n",
            "Loss after epoch 3175: 3752.0\n",
            "Loss after epoch 3176: 3976.0\n",
            "Loss after epoch 3177: 3696.0\n",
            "Loss after epoch 3178: 3848.0\n",
            "Loss after epoch 3179: 4120.0\n",
            "Loss after epoch 3180: 4032.0\n",
            "Loss after epoch 3181: 3776.0\n",
            "Loss after epoch 3182: 3672.0\n",
            "Loss after epoch 3183: 3312.0\n",
            "Loss after epoch 3184: 3856.0\n",
            "Loss after epoch 3185: 4024.0\n",
            "Loss after epoch 3186: 4088.0\n",
            "Loss after epoch 3187: 4304.0\n",
            "Loss after epoch 3188: 3768.0\n",
            "Loss after epoch 3189: 3920.0\n",
            "Loss after epoch 3190: 3808.0\n",
            "Loss after epoch 3191: 3840.0\n",
            "Loss after epoch 3192: 3912.0\n",
            "Loss after epoch 3193: 3616.0\n",
            "Loss after epoch 3194: 3816.0\n",
            "Loss after epoch 3195: 3800.0\n",
            "Loss after epoch 3196: 4112.0\n",
            "Loss after epoch 3197: 3656.0\n",
            "Loss after epoch 3198: 3736.0\n",
            "Loss after epoch 3199: 3680.0\n",
            "Loss after epoch 3200: 3984.0\n",
            "Loss after epoch 3201: 3920.0\n",
            "Loss after epoch 3202: 3952.0\n",
            "Loss after epoch 3203: 3624.0\n",
            "Loss after epoch 3204: 4152.0\n",
            "Loss after epoch 3205: 4080.0\n",
            "Loss after epoch 3206: 4128.0\n",
            "Loss after epoch 3207: 3984.0\n",
            "Loss after epoch 3208: 3904.0\n",
            "Loss after epoch 3209: 3776.0\n",
            "Loss after epoch 3210: 3944.0\n",
            "Loss after epoch 3211: 3776.0\n",
            "Loss after epoch 3212: 3856.0\n",
            "Loss after epoch 3213: 3408.0\n",
            "Loss after epoch 3214: 4008.0\n",
            "Loss after epoch 3215: 3952.0\n",
            "Loss after epoch 3216: 3816.0\n",
            "Loss after epoch 3217: 3632.0\n",
            "Loss after epoch 3218: 4064.0\n",
            "Loss after epoch 3219: 3776.0\n",
            "Loss after epoch 3220: 3680.0\n",
            "Loss after epoch 3221: 3856.0\n",
            "Loss after epoch 3222: 3872.0\n",
            "Loss after epoch 3223: 3984.0\n",
            "Loss after epoch 3224: 3680.0\n",
            "Loss after epoch 3225: 3792.0\n",
            "Loss after epoch 3226: 3880.0\n",
            "Loss after epoch 3227: 4016.0\n",
            "Loss after epoch 3228: 3816.0\n",
            "Loss after epoch 3229: 3728.0\n",
            "Loss after epoch 3230: 4144.0\n",
            "Loss after epoch 3231: 3528.0\n",
            "Loss after epoch 3232: 4048.0\n",
            "Loss after epoch 3233: 3648.0\n",
            "Loss after epoch 3234: 4008.0\n",
            "Loss after epoch 3235: 4112.0\n",
            "Loss after epoch 3236: 3480.0\n",
            "Loss after epoch 3237: 3624.0\n",
            "Loss after epoch 3238: 3944.0\n",
            "Loss after epoch 3239: 3720.0\n",
            "Loss after epoch 3240: 3912.0\n",
            "Loss after epoch 3241: 3704.0\n",
            "Loss after epoch 3242: 4000.0\n",
            "Loss after epoch 3243: 3584.0\n",
            "Loss after epoch 3244: 3544.0\n",
            "Loss after epoch 3245: 3936.0\n",
            "Loss after epoch 3246: 3416.0\n",
            "Loss after epoch 3247: 3664.0\n",
            "Loss after epoch 3248: 3816.0\n",
            "Loss after epoch 3249: 3768.0\n",
            "Loss after epoch 3250: 3696.0\n",
            "Loss after epoch 3251: 3440.0\n",
            "Loss after epoch 3252: 4176.0\n",
            "Loss after epoch 3253: 3688.0\n",
            "Loss after epoch 3254: 3608.0\n",
            "Loss after epoch 3255: 3584.0\n",
            "Loss after epoch 3256: 4000.0\n",
            "Loss after epoch 3257: 3552.0\n",
            "Loss after epoch 3258: 3680.0\n",
            "Loss after epoch 3259: 3576.0\n",
            "Loss after epoch 3260: 4200.0\n",
            "Loss after epoch 3261: 4080.0\n",
            "Loss after epoch 3262: 3600.0\n",
            "Loss after epoch 3263: 3912.0\n",
            "Loss after epoch 3264: 3816.0\n",
            "Loss after epoch 3265: 3600.0\n",
            "Loss after epoch 3266: 3840.0\n",
            "Loss after epoch 3267: 3856.0\n",
            "Loss after epoch 3268: 3952.0\n",
            "Loss after epoch 3269: 3672.0\n",
            "Loss after epoch 3270: 3856.0\n",
            "Loss after epoch 3271: 3744.0\n",
            "Loss after epoch 3272: 3688.0\n",
            "Loss after epoch 3273: 3520.0\n",
            "Loss after epoch 3274: 3784.0\n",
            "Loss after epoch 3275: 3256.0\n",
            "Loss after epoch 3276: 4072.0\n",
            "Loss after epoch 3277: 3608.0\n",
            "Loss after epoch 3278: 3792.0\n",
            "Loss after epoch 3279: 3616.0\n",
            "Loss after epoch 3280: 4152.0\n",
            "Loss after epoch 3281: 3784.0\n",
            "Loss after epoch 3282: 3760.0\n",
            "Loss after epoch 3283: 3848.0\n",
            "Loss after epoch 3284: 3728.0\n",
            "Loss after epoch 3285: 3832.0\n",
            "Loss after epoch 3286: 3728.0\n",
            "Loss after epoch 3287: 3896.0\n",
            "Loss after epoch 3288: 3816.0\n",
            "Loss after epoch 3289: 3424.0\n",
            "Loss after epoch 3290: 3920.0\n",
            "Loss after epoch 3291: 3696.0\n",
            "Loss after epoch 3292: 3896.0\n",
            "Loss after epoch 3293: 3552.0\n",
            "Loss after epoch 3294: 3536.0\n",
            "Loss after epoch 3295: 3720.0\n",
            "Loss after epoch 3296: 3912.0\n",
            "Loss after epoch 3297: 4088.0\n",
            "Loss after epoch 3298: 3696.0\n",
            "Loss after epoch 3299: 3896.0\n",
            "Loss after epoch 3300: 3544.0\n",
            "Loss after epoch 3301: 4184.0\n",
            "Loss after epoch 3302: 3680.0\n",
            "Loss after epoch 3303: 3768.0\n",
            "Loss after epoch 3304: 3744.0\n",
            "Loss after epoch 3305: 3800.0\n",
            "Loss after epoch 3306: 3848.0\n",
            "Loss after epoch 3307: 3904.0\n",
            "Loss after epoch 3308: 3904.0\n",
            "Loss after epoch 3309: 3864.0\n",
            "Loss after epoch 3310: 3912.0\n",
            "Loss after epoch 3311: 4016.0\n",
            "Loss after epoch 3312: 3768.0\n",
            "Loss after epoch 3313: 4152.0\n",
            "Loss after epoch 3314: 3784.0\n",
            "Loss after epoch 3315: 3952.0\n",
            "Loss after epoch 3316: 3432.0\n",
            "Loss after epoch 3317: 3904.0\n",
            "Loss after epoch 3318: 3824.0\n",
            "Loss after epoch 3319: 3648.0\n",
            "Loss after epoch 3320: 3792.0\n",
            "Loss after epoch 3321: 3760.0\n",
            "Loss after epoch 3322: 3328.0\n",
            "Loss after epoch 3323: 3736.0\n",
            "Loss after epoch 3324: 3720.0\n",
            "Loss after epoch 3325: 3728.0\n",
            "Loss after epoch 3326: 3688.0\n",
            "Loss after epoch 3327: 3712.0\n",
            "Loss after epoch 3328: 3960.0\n",
            "Loss after epoch 3329: 4272.0\n",
            "Loss after epoch 3330: 3736.0\n",
            "Loss after epoch 3331: 3736.0\n",
            "Loss after epoch 3332: 4008.0\n",
            "Loss after epoch 3333: 3720.0\n",
            "Loss after epoch 3334: 3976.0\n",
            "Loss after epoch 3335: 4096.0\n",
            "Loss after epoch 3336: 3648.0\n",
            "Loss after epoch 3337: 3672.0\n",
            "Loss after epoch 3338: 3696.0\n",
            "Loss after epoch 3339: 3592.0\n",
            "Loss after epoch 3340: 3792.0\n",
            "Loss after epoch 3341: 3864.0\n",
            "Loss after epoch 3342: 3552.0\n",
            "Loss after epoch 3343: 3872.0\n",
            "Loss after epoch 3344: 3824.0\n",
            "Loss after epoch 3345: 3664.0\n",
            "Loss after epoch 3346: 3808.0\n",
            "Loss after epoch 3347: 3840.0\n",
            "Loss after epoch 3348: 3984.0\n",
            "Loss after epoch 3349: 3424.0\n",
            "Loss after epoch 3350: 4320.0\n",
            "Loss after epoch 3351: 3576.0\n",
            "Loss after epoch 3352: 3608.0\n",
            "Loss after epoch 3353: 3960.0\n",
            "Loss after epoch 3354: 3976.0\n",
            "Loss after epoch 3355: 3712.0\n",
            "Loss after epoch 3356: 3768.0\n",
            "Loss after epoch 3357: 3808.0\n",
            "Loss after epoch 3358: 4072.0\n",
            "Loss after epoch 3359: 4040.0\n",
            "Loss after epoch 3360: 3560.0\n",
            "Loss after epoch 3361: 3688.0\n",
            "Loss after epoch 3362: 3832.0\n",
            "Loss after epoch 3363: 3728.0\n",
            "Loss after epoch 3364: 3640.0\n",
            "Loss after epoch 3365: 3656.0\n",
            "Loss after epoch 3366: 4064.0\n",
            "Loss after epoch 3367: 3512.0\n",
            "Loss after epoch 3368: 3584.0\n",
            "Loss after epoch 3369: 3576.0\n",
            "Loss after epoch 3370: 3824.0\n",
            "Loss after epoch 3371: 4032.0\n",
            "Loss after epoch 3372: 3592.0\n",
            "Loss after epoch 3373: 3608.0\n",
            "Loss after epoch 3374: 3288.0\n",
            "Loss after epoch 3375: 3688.0\n",
            "Loss after epoch 3376: 3904.0\n",
            "Loss after epoch 3377: 3672.0\n",
            "Loss after epoch 3378: 3808.0\n",
            "Loss after epoch 3379: 3656.0\n",
            "Loss after epoch 3380: 3936.0\n",
            "Loss after epoch 3381: 4128.0\n",
            "Loss after epoch 3382: 3800.0\n",
            "Loss after epoch 3383: 3816.0\n",
            "Loss after epoch 3384: 3664.0\n",
            "Loss after epoch 3385: 3824.0\n",
            "Loss after epoch 3386: 3856.0\n",
            "Loss after epoch 3387: 3824.0\n",
            "Loss after epoch 3388: 3488.0\n",
            "Loss after epoch 3389: 3824.0\n",
            "Loss after epoch 3390: 3792.0\n",
            "Loss after epoch 3391: 3680.0\n",
            "Loss after epoch 3392: 3936.0\n",
            "Loss after epoch 3393: 3632.0\n",
            "Loss after epoch 3394: 3904.0\n",
            "Loss after epoch 3395: 3536.0\n",
            "Loss after epoch 3396: 3336.0\n",
            "Loss after epoch 3397: 3832.0\n",
            "Loss after epoch 3398: 3632.0\n",
            "Loss after epoch 3399: 4016.0\n",
            "Loss after epoch 3400: 4000.0\n",
            "Loss after epoch 3401: 3848.0\n",
            "Loss after epoch 3402: 3544.0\n",
            "Loss after epoch 3403: 3824.0\n",
            "Loss after epoch 3404: 3872.0\n",
            "Loss after epoch 3405: 3976.0\n",
            "Loss after epoch 3406: 3952.0\n",
            "Loss after epoch 3407: 3680.0\n",
            "Loss after epoch 3408: 3576.0\n",
            "Loss after epoch 3409: 3328.0\n",
            "Loss after epoch 3410: 3632.0\n",
            "Loss after epoch 3411: 3624.0\n",
            "Loss after epoch 3412: 3416.0\n",
            "Loss after epoch 3413: 3656.0\n",
            "Loss after epoch 3414: 3464.0\n",
            "Loss after epoch 3415: 3800.0\n",
            "Loss after epoch 3416: 3560.0\n",
            "Loss after epoch 3417: 3568.0\n",
            "Loss after epoch 3418: 3608.0\n",
            "Loss after epoch 3419: 3792.0\n",
            "Loss after epoch 3420: 3448.0\n",
            "Loss after epoch 3421: 3648.0\n",
            "Loss after epoch 3422: 3920.0\n",
            "Loss after epoch 3423: 3640.0\n",
            "Loss after epoch 3424: 3848.0\n",
            "Loss after epoch 3425: 3592.0\n",
            "Loss after epoch 3426: 3744.0\n",
            "Loss after epoch 3427: 3448.0\n",
            "Loss after epoch 3428: 3632.0\n",
            "Loss after epoch 3429: 3640.0\n",
            "Loss after epoch 3430: 3384.0\n",
            "Loss after epoch 3431: 3616.0\n",
            "Loss after epoch 3432: 3384.0\n",
            "Loss after epoch 3433: 3360.0\n",
            "Loss after epoch 3434: 3384.0\n",
            "Loss after epoch 3435: 3632.0\n",
            "Loss after epoch 3436: 3528.0\n",
            "Loss after epoch 3437: 3240.0\n",
            "Loss after epoch 3438: 3800.0\n",
            "Loss after epoch 3439: 3408.0\n",
            "Loss after epoch 3440: 3776.0\n",
            "Loss after epoch 3441: 3480.0\n",
            "Loss after epoch 3442: 3592.0\n",
            "Loss after epoch 3443: 3816.0\n",
            "Loss after epoch 3444: 3576.0\n",
            "Loss after epoch 3445: 3744.0\n",
            "Loss after epoch 3446: 3680.0\n",
            "Loss after epoch 3447: 3432.0\n",
            "Loss after epoch 3448: 3640.0\n",
            "Loss after epoch 3449: 3832.0\n",
            "Loss after epoch 3450: 3984.0\n",
            "Loss after epoch 3451: 3312.0\n",
            "Loss after epoch 3452: 3736.0\n",
            "Loss after epoch 3453: 3400.0\n",
            "Loss after epoch 3454: 3600.0\n",
            "Loss after epoch 3455: 3800.0\n",
            "Loss after epoch 3456: 3560.0\n",
            "Loss after epoch 3457: 3392.0\n",
            "Loss after epoch 3458: 3920.0\n",
            "Loss after epoch 3459: 3816.0\n",
            "Loss after epoch 3460: 3368.0\n",
            "Loss after epoch 3461: 3568.0\n",
            "Loss after epoch 3462: 3648.0\n",
            "Loss after epoch 3463: 3744.0\n",
            "Loss after epoch 3464: 3464.0\n",
            "Loss after epoch 3465: 3728.0\n",
            "Loss after epoch 3466: 3536.0\n",
            "Loss after epoch 3467: 3776.0\n",
            "Loss after epoch 3468: 3560.0\n",
            "Loss after epoch 3469: 3888.0\n",
            "Loss after epoch 3470: 3752.0\n",
            "Loss after epoch 3471: 3528.0\n",
            "Loss after epoch 3472: 3872.0\n",
            "Loss after epoch 3473: 3792.0\n",
            "Loss after epoch 3474: 3984.0\n",
            "Loss after epoch 3475: 3792.0\n",
            "Loss after epoch 3476: 3288.0\n",
            "Loss after epoch 3477: 4072.0\n",
            "Loss after epoch 3478: 3408.0\n",
            "Loss after epoch 3479: 3560.0\n",
            "Loss after epoch 3480: 3760.0\n",
            "Loss after epoch 3481: 3800.0\n",
            "Loss after epoch 3482: 3568.0\n",
            "Loss after epoch 3483: 3640.0\n",
            "Loss after epoch 3484: 3664.0\n",
            "Loss after epoch 3485: 3768.0\n",
            "Loss after epoch 3486: 3464.0\n",
            "Loss after epoch 3487: 3616.0\n",
            "Loss after epoch 3488: 3408.0\n",
            "Loss after epoch 3489: 3584.0\n",
            "Loss after epoch 3490: 3568.0\n",
            "Loss after epoch 3491: 3896.0\n",
            "Loss after epoch 3492: 3528.0\n",
            "Loss after epoch 3493: 3448.0\n",
            "Loss after epoch 3494: 3632.0\n",
            "Loss after epoch 3495: 3552.0\n",
            "Loss after epoch 3496: 3456.0\n",
            "Loss after epoch 3497: 3496.0\n",
            "Loss after epoch 3498: 3504.0\n",
            "Loss after epoch 3499: 3504.0\n",
            "Loss after epoch 3500: 3680.0\n",
            "Loss after epoch 3501: 3920.0\n",
            "Loss after epoch 3502: 3328.0\n",
            "Loss after epoch 3503: 3816.0\n",
            "Loss after epoch 3504: 3776.0\n",
            "Loss after epoch 3505: 3608.0\n",
            "Loss after epoch 3506: 3784.0\n",
            "Loss after epoch 3507: 3592.0\n",
            "Loss after epoch 3508: 3944.0\n",
            "Loss after epoch 3509: 3584.0\n",
            "Loss after epoch 3510: 3816.0\n",
            "Loss after epoch 3511: 3752.0\n",
            "Loss after epoch 3512: 3624.0\n",
            "Loss after epoch 3513: 3664.0\n",
            "Loss after epoch 3514: 3464.0\n",
            "Loss after epoch 3515: 3584.0\n",
            "Loss after epoch 3516: 3224.0\n",
            "Loss after epoch 3517: 3480.0\n",
            "Loss after epoch 3518: 3664.0\n",
            "Loss after epoch 3519: 3520.0\n",
            "Loss after epoch 3520: 3520.0\n",
            "Loss after epoch 3521: 3688.0\n",
            "Loss after epoch 3522: 3904.0\n",
            "Loss after epoch 3523: 3488.0\n",
            "Loss after epoch 3524: 3504.0\n",
            "Loss after epoch 3525: 3728.0\n",
            "Loss after epoch 3526: 4080.0\n",
            "Loss after epoch 3527: 3656.0\n",
            "Loss after epoch 3528: 3696.0\n",
            "Loss after epoch 3529: 3592.0\n",
            "Loss after epoch 3530: 3496.0\n",
            "Loss after epoch 3531: 3440.0\n",
            "Loss after epoch 3532: 3800.0\n",
            "Loss after epoch 3533: 3584.0\n",
            "Loss after epoch 3534: 3816.0\n",
            "Loss after epoch 3535: 2968.0\n",
            "Loss after epoch 3536: 3568.0\n",
            "Loss after epoch 3537: 3504.0\n",
            "Loss after epoch 3538: 3784.0\n",
            "Loss after epoch 3539: 3888.0\n",
            "Loss after epoch 3540: 3344.0\n",
            "Loss after epoch 3541: 3712.0\n",
            "Loss after epoch 3542: 3704.0\n",
            "Loss after epoch 3543: 3728.0\n",
            "Loss after epoch 3544: 3888.0\n",
            "Loss after epoch 3545: 3856.0\n",
            "Loss after epoch 3546: 3496.0\n",
            "Loss after epoch 3547: 3888.0\n",
            "Loss after epoch 3548: 3576.0\n",
            "Loss after epoch 3549: 3512.0\n",
            "Loss after epoch 3550: 3560.0\n",
            "Loss after epoch 3551: 3792.0\n",
            "Loss after epoch 3552: 3608.0\n",
            "Loss after epoch 3553: 3648.0\n",
            "Loss after epoch 3554: 3648.0\n",
            "Loss after epoch 3555: 3344.0\n",
            "Loss after epoch 3556: 3432.0\n",
            "Loss after epoch 3557: 3936.0\n",
            "Loss after epoch 3558: 3368.0\n",
            "Loss after epoch 3559: 3592.0\n",
            "Loss after epoch 3560: 3872.0\n",
            "Loss after epoch 3561: 3904.0\n",
            "Loss after epoch 3562: 3664.0\n",
            "Loss after epoch 3563: 3488.0\n",
            "Loss after epoch 3564: 3696.0\n",
            "Loss after epoch 3565: 3544.0\n",
            "Loss after epoch 3566: 3264.0\n",
            "Loss after epoch 3567: 3624.0\n",
            "Loss after epoch 3568: 3416.0\n",
            "Loss after epoch 3569: 3592.0\n",
            "Loss after epoch 3570: 3648.0\n",
            "Loss after epoch 3571: 3568.0\n",
            "Loss after epoch 3572: 3784.0\n",
            "Loss after epoch 3573: 3616.0\n",
            "Loss after epoch 3574: 3592.0\n",
            "Loss after epoch 3575: 3528.0\n",
            "Loss after epoch 3576: 3712.0\n",
            "Loss after epoch 3577: 3704.0\n",
            "Loss after epoch 3578: 3320.0\n",
            "Loss after epoch 3579: 3488.0\n",
            "Loss after epoch 3580: 3592.0\n",
            "Loss after epoch 3581: 3328.0\n",
            "Loss after epoch 3582: 3368.0\n",
            "Loss after epoch 3583: 3480.0\n",
            "Loss after epoch 3584: 3928.0\n",
            "Loss after epoch 3585: 3480.0\n",
            "Loss after epoch 3586: 3504.0\n",
            "Loss after epoch 3587: 3096.0\n",
            "Loss after epoch 3588: 3808.0\n",
            "Loss after epoch 3589: 3952.0\n",
            "Loss after epoch 3590: 3392.0\n",
            "Loss after epoch 3591: 3496.0\n",
            "Loss after epoch 3592: 3752.0\n",
            "Loss after epoch 3593: 3688.0\n",
            "Loss after epoch 3594: 3584.0\n",
            "Loss after epoch 3595: 3568.0\n",
            "Loss after epoch 3596: 3816.0\n",
            "Loss after epoch 3597: 4040.0\n",
            "Loss after epoch 3598: 3264.0\n",
            "Loss after epoch 3599: 3344.0\n",
            "Loss after epoch 3600: 3656.0\n",
            "Loss after epoch 3601: 3376.0\n",
            "Loss after epoch 3602: 3752.0\n",
            "Loss after epoch 3603: 3304.0\n",
            "Loss after epoch 3604: 3592.0\n",
            "Loss after epoch 3605: 3472.0\n",
            "Loss after epoch 3606: 3376.0\n",
            "Loss after epoch 3607: 3600.0\n",
            "Loss after epoch 3608: 3632.0\n",
            "Loss after epoch 3609: 3560.0\n",
            "Loss after epoch 3610: 3488.0\n",
            "Loss after epoch 3611: 3320.0\n",
            "Loss after epoch 3612: 3544.0\n",
            "Loss after epoch 3613: 3320.0\n",
            "Loss after epoch 3614: 3696.0\n",
            "Loss after epoch 3615: 3416.0\n",
            "Loss after epoch 3616: 3520.0\n",
            "Loss after epoch 3617: 3544.0\n",
            "Loss after epoch 3618: 3264.0\n",
            "Loss after epoch 3619: 3712.0\n",
            "Loss after epoch 3620: 3744.0\n",
            "Loss after epoch 3621: 3376.0\n",
            "Loss after epoch 3622: 3672.0\n",
            "Loss after epoch 3623: 3448.0\n",
            "Loss after epoch 3624: 3528.0\n",
            "Loss after epoch 3625: 3392.0\n",
            "Loss after epoch 3626: 3216.0\n",
            "Loss after epoch 3627: 3640.0\n",
            "Loss after epoch 3628: 3664.0\n",
            "Loss after epoch 3629: 3368.0\n",
            "Loss after epoch 3630: 3568.0\n",
            "Loss after epoch 3631: 3824.0\n",
            "Loss after epoch 3632: 3528.0\n",
            "Loss after epoch 3633: 3376.0\n",
            "Loss after epoch 3634: 3544.0\n",
            "Loss after epoch 3635: 3264.0\n",
            "Loss after epoch 3636: 3760.0\n",
            "Loss after epoch 3637: 3176.0\n",
            "Loss after epoch 3638: 3800.0\n",
            "Loss after epoch 3639: 3288.0\n",
            "Loss after epoch 3640: 3816.0\n",
            "Loss after epoch 3641: 3680.0\n",
            "Loss after epoch 3642: 3272.0\n",
            "Loss after epoch 3643: 3736.0\n",
            "Loss after epoch 3644: 3416.0\n",
            "Loss after epoch 3645: 3720.0\n",
            "Loss after epoch 3646: 3712.0\n",
            "Loss after epoch 3647: 3504.0\n",
            "Loss after epoch 3648: 3648.0\n",
            "Loss after epoch 3649: 3688.0\n",
            "Loss after epoch 3650: 3256.0\n",
            "Loss after epoch 3651: 3344.0\n",
            "Loss after epoch 3652: 3936.0\n",
            "Loss after epoch 3653: 3520.0\n",
            "Loss after epoch 3654: 3456.0\n",
            "Loss after epoch 3655: 3496.0\n",
            "Loss after epoch 3656: 3368.0\n",
            "Loss after epoch 3657: 3464.0\n",
            "Loss after epoch 3658: 3352.0\n",
            "Loss after epoch 3659: 3848.0\n",
            "Loss after epoch 3660: 3480.0\n",
            "Loss after epoch 3661: 3392.0\n",
            "Loss after epoch 3662: 3464.0\n",
            "Loss after epoch 3663: 3256.0\n",
            "Loss after epoch 3664: 3432.0\n",
            "Loss after epoch 3665: 3296.0\n",
            "Loss after epoch 3666: 3336.0\n",
            "Loss after epoch 3667: 3472.0\n",
            "Loss after epoch 3668: 3792.0\n",
            "Loss after epoch 3669: 3840.0\n",
            "Loss after epoch 3670: 3472.0\n",
            "Loss after epoch 3671: 3632.0\n",
            "Loss after epoch 3672: 3280.0\n",
            "Loss after epoch 3673: 3664.0\n",
            "Loss after epoch 3674: 3144.0\n",
            "Loss after epoch 3675: 3808.0\n",
            "Loss after epoch 3676: 3112.0\n",
            "Loss after epoch 3677: 3656.0\n",
            "Loss after epoch 3678: 3336.0\n",
            "Loss after epoch 3679: 3624.0\n",
            "Loss after epoch 3680: 3336.0\n",
            "Loss after epoch 3681: 3432.0\n",
            "Loss after epoch 3682: 3440.0\n",
            "Loss after epoch 3683: 3688.0\n",
            "Loss after epoch 3684: 3456.0\n",
            "Loss after epoch 3685: 3440.0\n",
            "Loss after epoch 3686: 3736.0\n",
            "Loss after epoch 3687: 3512.0\n",
            "Loss after epoch 3688: 3616.0\n",
            "Loss after epoch 3689: 3520.0\n",
            "Loss after epoch 3690: 3544.0\n",
            "Loss after epoch 3691: 3512.0\n",
            "Loss after epoch 3692: 3680.0\n",
            "Loss after epoch 3693: 3408.0\n",
            "Loss after epoch 3694: 3176.0\n",
            "Loss after epoch 3695: 3600.0\n",
            "Loss after epoch 3696: 3736.0\n",
            "Loss after epoch 3697: 3456.0\n",
            "Loss after epoch 3698: 3976.0\n",
            "Loss after epoch 3699: 3568.0\n",
            "Loss after epoch 3700: 3184.0\n",
            "Loss after epoch 3701: 3472.0\n",
            "Loss after epoch 3702: 3632.0\n",
            "Loss after epoch 3703: 3336.0\n",
            "Loss after epoch 3704: 3328.0\n",
            "Loss after epoch 3705: 3192.0\n",
            "Loss after epoch 3706: 3776.0\n",
            "Loss after epoch 3707: 3184.0\n",
            "Loss after epoch 3708: 3368.0\n",
            "Loss after epoch 3709: 3448.0\n",
            "Loss after epoch 3710: 3368.0\n",
            "Loss after epoch 3711: 3304.0\n",
            "Loss after epoch 3712: 3224.0\n",
            "Loss after epoch 3713: 3280.0\n",
            "Loss after epoch 3714: 3128.0\n",
            "Loss after epoch 3715: 3240.0\n",
            "Loss after epoch 3716: 3280.0\n",
            "Loss after epoch 3717: 3576.0\n",
            "Loss after epoch 3718: 3344.0\n",
            "Loss after epoch 3719: 3520.0\n",
            "Loss after epoch 3720: 3768.0\n",
            "Loss after epoch 3721: 3472.0\n",
            "Loss after epoch 3722: 3584.0\n",
            "Loss after epoch 3723: 3760.0\n",
            "Loss after epoch 3724: 3456.0\n",
            "Loss after epoch 3725: 3416.0\n",
            "Loss after epoch 3726: 3344.0\n",
            "Loss after epoch 3727: 3536.0\n",
            "Loss after epoch 3728: 3496.0\n",
            "Loss after epoch 3729: 3272.0\n",
            "Loss after epoch 3730: 3416.0\n",
            "Loss after epoch 3731: 3376.0\n",
            "Loss after epoch 3732: 3200.0\n",
            "Loss after epoch 3733: 3424.0\n",
            "Loss after epoch 3734: 3216.0\n",
            "Loss after epoch 3735: 3320.0\n",
            "Loss after epoch 3736: 3472.0\n",
            "Loss after epoch 3737: 3456.0\n",
            "Loss after epoch 3738: 3496.0\n",
            "Loss after epoch 3739: 3424.0\n",
            "Loss after epoch 3740: 3480.0\n",
            "Loss after epoch 3741: 3616.0\n",
            "Loss after epoch 3742: 3728.0\n",
            "Loss after epoch 3743: 3448.0\n",
            "Loss after epoch 3744: 3576.0\n",
            "Loss after epoch 3745: 3456.0\n",
            "Loss after epoch 3746: 3752.0\n",
            "Loss after epoch 3747: 3448.0\n",
            "Loss after epoch 3748: 3240.0\n",
            "Loss after epoch 3749: 3256.0\n",
            "Loss after epoch 3750: 3296.0\n",
            "Loss after epoch 3751: 3600.0\n",
            "Loss after epoch 3752: 3448.0\n",
            "Loss after epoch 3753: 3336.0\n",
            "Loss after epoch 3754: 3320.0\n",
            "Loss after epoch 3755: 3288.0\n",
            "Loss after epoch 3756: 3496.0\n",
            "Loss after epoch 3757: 3032.0\n",
            "Loss after epoch 3758: 3560.0\n",
            "Loss after epoch 3759: 3576.0\n",
            "Loss after epoch 3760: 3280.0\n",
            "Loss after epoch 3761: 3616.0\n",
            "Loss after epoch 3762: 3448.0\n",
            "Loss after epoch 3763: 3456.0\n",
            "Loss after epoch 3764: 3456.0\n",
            "Loss after epoch 3765: 3112.0\n",
            "Loss after epoch 3766: 3176.0\n",
            "Loss after epoch 3767: 3600.0\n",
            "Loss after epoch 3768: 3584.0\n",
            "Loss after epoch 3769: 3152.0\n",
            "Loss after epoch 3770: 3360.0\n",
            "Loss after epoch 3771: 3304.0\n",
            "Loss after epoch 3772: 3272.0\n",
            "Loss after epoch 3773: 3528.0\n",
            "Loss after epoch 3774: 3536.0\n",
            "Loss after epoch 3775: 3568.0\n",
            "Loss after epoch 3776: 3616.0\n",
            "Loss after epoch 3777: 3424.0\n",
            "Loss after epoch 3778: 3408.0\n",
            "Loss after epoch 3779: 3384.0\n",
            "Loss after epoch 3780: 3216.0\n",
            "Loss after epoch 3781: 3416.0\n",
            "Loss after epoch 3782: 3664.0\n",
            "Loss after epoch 3783: 3648.0\n",
            "Loss after epoch 3784: 3336.0\n",
            "Loss after epoch 3785: 3648.0\n",
            "Loss after epoch 3786: 3600.0\n",
            "Loss after epoch 3787: 3040.0\n",
            "Loss after epoch 3788: 3808.0\n",
            "Loss after epoch 3789: 3320.0\n",
            "Loss after epoch 3790: 3128.0\n",
            "Loss after epoch 3791: 3248.0\n",
            "Loss after epoch 3792: 3688.0\n",
            "Loss after epoch 3793: 3608.0\n",
            "Loss after epoch 3794: 3584.0\n",
            "Loss after epoch 3795: 3736.0\n",
            "Loss after epoch 3796: 3440.0\n",
            "Loss after epoch 3797: 3264.0\n",
            "Loss after epoch 3798: 3624.0\n",
            "Loss after epoch 3799: 3464.0\n",
            "Loss after epoch 3800: 3520.0\n",
            "Loss after epoch 3801: 3376.0\n",
            "Loss after epoch 3802: 3328.0\n",
            "Loss after epoch 3803: 3360.0\n",
            "Loss after epoch 3804: 3512.0\n",
            "Loss after epoch 3805: 3432.0\n",
            "Loss after epoch 3806: 3752.0\n",
            "Loss after epoch 3807: 3592.0\n",
            "Loss after epoch 3808: 3320.0\n",
            "Loss after epoch 3809: 3560.0\n",
            "Loss after epoch 3810: 3528.0\n",
            "Loss after epoch 3811: 3368.0\n",
            "Loss after epoch 3812: 3416.0\n",
            "Loss after epoch 3813: 3592.0\n",
            "Loss after epoch 3814: 3248.0\n",
            "Loss after epoch 3815: 4088.0\n",
            "Loss after epoch 3816: 3672.0\n",
            "Loss after epoch 3817: 3816.0\n",
            "Loss after epoch 3818: 3576.0\n",
            "Loss after epoch 3819: 3544.0\n",
            "Loss after epoch 3820: 3328.0\n",
            "Loss after epoch 3821: 3576.0\n",
            "Loss after epoch 3822: 3408.0\n",
            "Loss after epoch 3823: 3408.0\n",
            "Loss after epoch 3824: 3616.0\n",
            "Loss after epoch 3825: 3048.0\n",
            "Loss after epoch 3826: 3176.0\n",
            "Loss after epoch 3827: 3512.0\n",
            "Loss after epoch 3828: 3584.0\n",
            "Loss after epoch 3829: 3496.0\n",
            "Loss after epoch 3830: 3656.0\n",
            "Loss after epoch 3831: 3056.0\n",
            "Loss after epoch 3832: 3320.0\n",
            "Loss after epoch 3833: 3640.0\n",
            "Loss after epoch 3834: 3128.0\n",
            "Loss after epoch 3835: 3312.0\n",
            "Loss after epoch 3836: 3216.0\n",
            "Loss after epoch 3837: 3656.0\n",
            "Loss after epoch 3838: 3496.0\n",
            "Loss after epoch 3839: 3648.0\n",
            "Loss after epoch 3840: 3344.0\n",
            "Loss after epoch 3841: 3376.0\n",
            "Loss after epoch 3842: 3208.0\n",
            "Loss after epoch 3843: 3560.0\n",
            "Loss after epoch 3844: 3680.0\n",
            "Loss after epoch 3845: 3200.0\n",
            "Loss after epoch 3846: 3680.0\n",
            "Loss after epoch 3847: 3192.0\n",
            "Loss after epoch 3848: 3248.0\n",
            "Loss after epoch 3849: 3296.0\n",
            "Loss after epoch 3850: 3528.0\n",
            "Loss after epoch 3851: 3240.0\n",
            "Loss after epoch 3852: 3360.0\n",
            "Loss after epoch 3853: 3168.0\n",
            "Loss after epoch 3854: 3336.0\n",
            "Loss after epoch 3855: 3472.0\n",
            "Loss after epoch 3856: 3432.0\n",
            "Loss after epoch 3857: 3464.0\n",
            "Loss after epoch 3858: 3280.0\n",
            "Loss after epoch 3859: 3456.0\n",
            "Loss after epoch 3860: 3352.0\n",
            "Loss after epoch 3861: 3464.0\n",
            "Loss after epoch 3862: 3416.0\n",
            "Loss after epoch 3863: 3608.0\n",
            "Loss after epoch 3864: 3232.0\n",
            "Loss after epoch 3865: 3392.0\n",
            "Loss after epoch 3866: 3568.0\n",
            "Loss after epoch 3867: 3496.0\n",
            "Loss after epoch 3868: 3216.0\n",
            "Loss after epoch 3869: 3320.0\n",
            "Loss after epoch 3870: 3760.0\n",
            "Loss after epoch 3871: 3240.0\n",
            "Loss after epoch 3872: 3256.0\n",
            "Loss after epoch 3873: 3216.0\n",
            "Loss after epoch 3874: 3320.0\n",
            "Loss after epoch 3875: 3536.0\n",
            "Loss after epoch 3876: 3072.0\n",
            "Loss after epoch 3877: 3568.0\n",
            "Loss after epoch 3878: 3384.0\n",
            "Loss after epoch 3879: 3784.0\n",
            "Loss after epoch 3880: 3264.0\n",
            "Loss after epoch 3881: 3496.0\n",
            "Loss after epoch 3882: 3416.0\n",
            "Loss after epoch 3883: 3424.0\n",
            "Loss after epoch 3884: 3296.0\n",
            "Loss after epoch 3885: 3296.0\n",
            "Loss after epoch 3886: 3272.0\n",
            "Loss after epoch 3887: 3600.0\n",
            "Loss after epoch 3888: 3296.0\n",
            "Loss after epoch 3889: 3552.0\n",
            "Loss after epoch 3890: 3416.0\n",
            "Loss after epoch 3891: 3128.0\n",
            "Loss after epoch 3892: 3240.0\n",
            "Loss after epoch 3893: 3544.0\n",
            "Loss after epoch 3894: 3080.0\n",
            "Loss after epoch 3895: 3136.0\n",
            "Loss after epoch 3896: 3424.0\n",
            "Loss after epoch 3897: 3360.0\n",
            "Loss after epoch 3898: 3480.0\n",
            "Loss after epoch 3899: 3328.0\n",
            "Loss after epoch 3900: 3080.0\n",
            "Loss after epoch 3901: 3248.0\n",
            "Loss after epoch 3902: 3536.0\n",
            "Loss after epoch 3903: 3272.0\n",
            "Loss after epoch 3904: 3224.0\n",
            "Loss after epoch 3905: 3120.0\n",
            "Loss after epoch 3906: 3344.0\n",
            "Loss after epoch 3907: 3544.0\n",
            "Loss after epoch 3908: 3616.0\n",
            "Loss after epoch 3909: 3176.0\n",
            "Loss after epoch 3910: 3320.0\n",
            "Loss after epoch 3911: 3432.0\n",
            "Loss after epoch 3912: 3480.0\n",
            "Loss after epoch 3913: 3168.0\n",
            "Loss after epoch 3914: 3192.0\n",
            "Loss after epoch 3915: 3176.0\n",
            "Loss after epoch 3916: 2912.0\n",
            "Loss after epoch 3917: 3072.0\n",
            "Loss after epoch 3918: 3304.0\n",
            "Loss after epoch 3919: 3240.0\n",
            "Loss after epoch 3920: 3640.0\n",
            "Loss after epoch 3921: 3080.0\n",
            "Loss after epoch 3922: 3632.0\n",
            "Loss after epoch 3923: 3368.0\n",
            "Loss after epoch 3924: 3784.0\n",
            "Loss after epoch 3925: 3304.0\n",
            "Loss after epoch 3926: 3112.0\n",
            "Loss after epoch 3927: 3464.0\n",
            "Loss after epoch 3928: 3328.0\n",
            "Loss after epoch 3929: 3048.0\n",
            "Loss after epoch 3930: 3120.0\n",
            "Loss after epoch 3931: 3056.0\n",
            "Loss after epoch 3932: 3384.0\n",
            "Loss after epoch 3933: 3200.0\n",
            "Loss after epoch 3934: 3000.0\n",
            "Loss after epoch 3935: 3288.0\n",
            "Loss after epoch 3936: 3240.0\n",
            "Loss after epoch 3937: 3160.0\n",
            "Loss after epoch 3938: 3392.0\n",
            "Loss after epoch 3939: 3536.0\n",
            "Loss after epoch 3940: 3368.0\n",
            "Loss after epoch 3941: 3416.0\n",
            "Loss after epoch 3942: 3208.0\n",
            "Loss after epoch 3943: 3304.0\n",
            "Loss after epoch 3944: 3640.0\n",
            "Loss after epoch 3945: 3560.0\n",
            "Loss after epoch 3946: 2992.0\n",
            "Loss after epoch 3947: 3664.0\n",
            "Loss after epoch 3948: 3256.0\n",
            "Loss after epoch 3949: 3016.0\n",
            "Loss after epoch 3950: 3488.0\n",
            "Loss after epoch 3951: 3624.0\n",
            "Loss after epoch 3952: 2984.0\n",
            "Loss after epoch 3953: 3792.0\n",
            "Loss after epoch 3954: 3120.0\n",
            "Loss after epoch 3955: 3256.0\n",
            "Loss after epoch 3956: 3376.0\n",
            "Loss after epoch 3957: 2936.0\n",
            "Loss after epoch 3958: 3128.0\n",
            "Loss after epoch 3959: 3144.0\n",
            "Loss after epoch 3960: 2936.0\n",
            "Loss after epoch 3961: 3056.0\n",
            "Loss after epoch 3962: 3336.0\n",
            "Loss after epoch 3963: 3680.0\n",
            "Loss after epoch 3964: 3408.0\n",
            "Loss after epoch 3965: 2976.0\n",
            "Loss after epoch 3966: 3560.0\n",
            "Loss after epoch 3967: 2984.0\n",
            "Loss after epoch 3968: 3368.0\n",
            "Loss after epoch 3969: 3688.0\n",
            "Loss after epoch 3970: 3320.0\n",
            "Loss after epoch 3971: 2936.0\n",
            "Loss after epoch 3972: 3728.0\n",
            "Loss after epoch 3973: 3424.0\n",
            "Loss after epoch 3974: 3352.0\n",
            "Loss after epoch 3975: 3040.0\n",
            "Loss after epoch 3976: 3528.0\n",
            "Loss after epoch 3977: 3216.0\n",
            "Loss after epoch 3978: 3048.0\n",
            "Loss after epoch 3979: 3464.0\n",
            "Loss after epoch 3980: 3144.0\n",
            "Loss after epoch 3981: 3128.0\n",
            "Loss after epoch 3982: 3504.0\n",
            "Loss after epoch 3983: 3144.0\n",
            "Loss after epoch 3984: 3440.0\n",
            "Loss after epoch 3985: 3544.0\n",
            "Loss after epoch 3986: 3152.0\n",
            "Loss after epoch 3987: 3240.0\n",
            "Loss after epoch 3988: 3448.0\n",
            "Loss after epoch 3989: 3304.0\n",
            "Loss after epoch 3990: 3104.0\n",
            "Loss after epoch 3991: 3376.0\n",
            "Loss after epoch 3992: 2992.0\n",
            "Loss after epoch 3993: 3000.0\n",
            "Loss after epoch 3994: 3152.0\n",
            "Loss after epoch 3995: 3352.0\n",
            "Loss after epoch 3996: 3040.0\n",
            "Loss after epoch 3997: 3576.0\n",
            "Loss after epoch 3998: 3240.0\n",
            "Loss after epoch 3999: 3248.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43588870, 71852000)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Entrenamos el modelo generador de vectores\n",
        "# Utilizamos nuestro callback\n",
        "w2v_model.train(sentence_tokens,\n",
        "                 total_examples=w2v_model.corpus_count,\n",
        "                 epochs=4000,\n",
        "                 compute_loss = True,\n",
        "                 callbacks=[callback()]\n",
        "                 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddT9NVuNlCAe"
      },
      "source": [
        "### 4 - Ensayar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6cHN9xGLuPEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f259fe2-4b0e-46fd-ede5-354f7b59bf66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "singin': 0.4555984139442444\n",
            "fall: 0.42834582924842834\n",
            "'bout: 0.4249691665172577\n",
            "alright: 0.37303048372268677\n",
            "happy: 0.3598896861076355\n",
            "thing: 0.35635143518447876\n",
            "message: 0.3505827784538269\n",
            "pimper's: 0.3455803394317627\n",
            "gun: 0.34260499477386475\n",
            "little: 0.3294961750507355\n"
          ]
        }
      ],
      "source": [
        "similar_words = w2v_model.wv.most_similar(positive=[\"worry\"], topn=10)\n",
        "for word, similarity in similar_words:\n",
        "    print(f\"{word}: {similarity}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MENOS se relacionan con...:\n",
        "w2v_model.wv.most_similar(negative=[\"worry\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj4KlDHZdEKF",
        "outputId": "5b0f1f5c-1b92-43d3-e0a5-a5a51607dc81"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('roots', 0.018203111365437508),\n",
              " ('vibration', -0.012176807038486004),\n",
              " ('jah', -0.028318891301751137),\n",
              " ('word', -0.032436762005090714),\n",
              " ('first', -0.03879272937774658),\n",
              " ('too', -0.04466841742396355),\n",
              " ('fool', -0.048376649618148804),\n",
              " ('rastaman', -0.051271677017211914),\n",
              " ('came', -0.051643576472997665),\n",
              " ('on', -0.05538153648376465)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import plotly.express as px\n",
        "\n",
        "similar_words = w2v_model.wv.most_similar(negative=[\"worry\"], topn=10)\n",
        "words = [word for word, similarity in similar_words]\n",
        "\n",
        "# Get word vectors for the selected words\n",
        "word_vectors = [w2v_model.wv[word] for word in words]\n",
        "\n",
        "# Apply PCA to reduce the dimensionality to 2\n",
        "pca = PCA(n_components=2)\n",
        "embeddings_2d = pca.fit_transform(word_vectors)\n",
        "\n",
        "# Create a DataFrame with the embeddings and words\n",
        "data = {\"Word\": words, \"Dimension 1\": embeddings_2d[:, 0], \"Dimension 2\": embeddings_2d[:, 1]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create the scatter plot\n",
        "fig = px.scatter(df, x=\"Dimension 1\", y=\"Dimension 2\", text=\"Word\")\n",
        "\n",
        "fig.update_traces(textposition=\"top center\")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Word Embeddings - Palabras que menos se relacionan con 'worry'\",\n",
        "    xaxis_title=\"Dimension 1\",\n",
        "    yaxis_title=\"Dimension 2\",\n",
        "    hovermode=\"closest\",\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "IXIfFyHxnfAv",
        "outputId": "e132fb3e-98df-4314-9791-f27307383a25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"77f2b175-905c-4515-a590-e168f0e0e38a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"77f2b175-905c-4515-a590-e168f0e0e38a\")) {                    Plotly.newPlot(                        \"77f2b175-905c-4515-a590-e168f0e0e38a\",                        [{\"hovertemplate\":\"Dimension 1=%{x}<br>Dimension 2=%{y}<br>Word=%{text}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"roots\",\"vibration\",\"jah\",\"word\",\"first\",\"too\",\"fool\",\"rastaman\",\"came\",\"on\"],\"x\":[0.5053441212200748,-3.750489330989912,-0.4675031967192668,4.553954676144326,-0.6483162337196351,0.11985426105604846,1.5746344907691472,-1.9569471660906492,-0.7824050647378213,0.8518734430676881],\"xaxis\":\"x\",\"y\":[-0.9195954046436294,-2.01271233056874,0.14027208885628262,-1.1702743210024653,3.7591698615351,-0.11156047967871253,-1.2963964947504942,-2.5178732960435664,3.452191801714442,0.6767785745817816],\"yaxis\":\"y\",\"type\":\"scatter\",\"textposition\":\"top center\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dimension 1\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dimension 2\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Word Embeddings - Palabras que menos se relacionan con 'worry'\"},\"hovermode\":\"closest\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('77f2b175-905c-4515-a590-e168f0e0e38a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MENOS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"happy\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tWC9cHNdG4k",
        "outputId": "5d398ad8-1877-4d24-ba71-a8cab5d7209f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cornerstone', 0.3770964443683624),\n",
              " (\"cryin'\", 0.3657260537147522),\n",
              " ('worry', 0.3598896861076355),\n",
              " ('ready', 0.3521519601345062),\n",
              " ('coffee', 0.3503662645816803),\n",
              " ('ask', 0.344417929649353),\n",
              " ('song', 0.337720662355423),\n",
              " ('blue', 0.31755074858665466),\n",
              " ('wrong', 0.315708190202713),\n",
              " ('message', 0.3150540590286255)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import plotly.express as px\n",
        "\n",
        "similar_words = w2v_model.wv.most_similar(positive=[\"happy\"], topn=10)\n",
        "words = [word for word, similarity in similar_words]\n",
        "\n",
        "# Get word vectors for the selected words\n",
        "word_vectors = [w2v_model.wv[word] for word in words]\n",
        "\n",
        "# Apply PCA to reduce the dimensionality to 2\n",
        "pca = PCA(n_components=2)\n",
        "embeddings_2d = pca.fit_transform(word_vectors)\n",
        "\n",
        "# Create a DataFrame with the embeddings and words\n",
        "data = {\"Word\": words, \"Dimension 1\": embeddings_2d[:, 0], \"Dimension 2\": embeddings_2d[:, 1]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create the scatter plot\n",
        "fig = px.scatter(df, x=\"Dimension 1\", y=\"Dimension 2\", text=\"Word\")\n",
        "\n",
        "fig.update_traces(textposition=\"top center\")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Word Embeddings - Palabras que menos se relacionan con 'worry'\",\n",
        "    xaxis_title=\"Dimension 1\",\n",
        "    yaxis_title=\"Dimension 2\",\n",
        "    hovermode=\"closest\",\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "A3_27TJUogMV",
        "outputId": "1901329c-ebf0-421c-cea2-4a0477fe67a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"8c9b724e-8314-49e9-816b-bfba91402bf0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8c9b724e-8314-49e9-816b-bfba91402bf0\")) {                    Plotly.newPlot(                        \"8c9b724e-8314-49e9-816b-bfba91402bf0\",                        [{\"hovertemplate\":\"Dimension 1=%{x}<br>Dimension 2=%{y}<br>Word=%{text}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"cornerstone\",\"cryin'\",\"worry\",\"ready\",\"coffee\",\"ask\",\"song\",\"blue\",\"wrong\",\"message\"],\"x\":[-0.8215170958360127,-1.1453180620449963,-0.6633320106305902,2.707753887588568,-0.1752497668990633,-0.3557098797457373,-2.879055003746331,-2.161468725876324,5.293834278638579,0.20006237855190712],\"xaxis\":\"x\",\"y\":[1.069580274454757,3.9446746534352526,-1.2446795494314813,-2.253850553033577,-0.6186562709106809,1.9554741913520448,-2.3140592188096227,0.863457853082579,1.324262996749134,-2.7262043768884103],\"yaxis\":\"y\",\"type\":\"scatter\",\"textposition\":\"top center\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dimension 1\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dimension 2\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Word Embeddings - Palabras que menos se relacionan con 'worry'\"},\"hovermode\":\"closest\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8c9b724e-8314-49e9-816b-bfba91402bf0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "47HiU5gdkdMq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14dc26b2-0345-405d-f55f-63503663c4af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('some', 0.04305484890937805),\n",
              " ('been', 0.015359763987362385),\n",
              " ('may', 0.011414886452257633),\n",
              " ('god', 0.008973723277449608),\n",
              " ('ride', -0.0001873540022643283),\n",
              " ('rights', -0.0013440237380564213),\n",
              " ('too', -0.0016123566310852766),\n",
              " (\"we're\", -0.0024499220307916403),\n",
              " ('winepress', -0.0037879692390561104),\n",
              " ('down', -0.008398966863751411)]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Palabras que MENOS se relacionan con...:\n",
        "w2v_model.wv.most_similar(negative=[\"happy\"], topn=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "similar_words = w2v_model.wv.most_similar(negative=[\"happy\"], topn=10)\n",
        "words = [word for word, similarity in similar_words]\n",
        "\n",
        "# Get word vectors for the selected words\n",
        "word_vectors = [w2v_model.wv[word] for word in words]\n",
        "\n",
        "# Apply PCA to reduce the dimensionality to 2\n",
        "pca = PCA(n_components=2)\n",
        "embeddings_2d = pca.fit_transform(word_vectors)\n",
        "\n",
        "# Create a DataFrame with the embeddings and words\n",
        "data = {\"Word\": words, \"Dimension 1\": embeddings_2d[:, 0], \"Dimension 2\": embeddings_2d[:, 1]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create the scatter plot\n",
        "fig = px.scatter(df, x=\"Dimension 1\", y=\"Dimension 2\", text=\"Word\")\n",
        "\n",
        "fig.update_traces(textposition=\"top center\")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Word Embeddings - Palabras que menos se relacionan con 'worry'\",\n",
        "    xaxis_title=\"Dimension 1\",\n",
        "    yaxis_title=\"Dimension 2\",\n",
        "    hovermode=\"closest\",\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "28HduJ3VpMAM",
        "outputId": "5be58e7a-cfd9-4800-b0c2-e0e299dcca5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"1d507c55-93ab-48cc-82b9-1572dfa145bd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1d507c55-93ab-48cc-82b9-1572dfa145bd\")) {                    Plotly.newPlot(                        \"1d507c55-93ab-48cc-82b9-1572dfa145bd\",                        [{\"hovertemplate\":\"Dimension 1=%{x}<br>Dimension 2=%{y}<br>Word=%{text}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"some\",\"been\",\"may\",\"god\",\"ride\",\"rights\",\"too\",\"we're\",\"winepress\",\"down\"],\"x\":[1.5809714688577938,-2.563860041375635,-0.08805731634543497,4.8050332656571015,-0.28713939247986736,-0.12955780735151884,-0.9783905252592601,0.9832248847942745,-3.1052980860729256,-0.21692645042452918],\"xaxis\":\"x\",\"y\":[-0.7700875591897908,0.022100052371118777,5.508836821163359,-0.0695932622715884,-2.3119047899136187,-0.6850723662531445,-1.4643854802041218,-0.29014491801649755,-0.07154577466415686,0.1317972769784365],\"yaxis\":\"y\",\"type\":\"scatter\",\"textposition\":\"top center\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dimension 1\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dimension 2\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Word Embeddings - Palabras que menos se relacionan con 'worry'\"},\"hovermode\":\"closest\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1d507c55-93ab-48cc-82b9-1572dfa145bd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "DT4Rvno2mD65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fec3c7a8-1b42-4f90-f3e8-2b1518509559"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('can', 0.4591623842716217),\n",
              " ('top', 0.410715788602829),\n",
              " ('trodding', 0.41002213954925537),\n",
              " ('might', 0.39469975233078003),\n",
              " ('winepress', 0.3896510601043701),\n",
              " ('where', 0.3828642964363098),\n",
              " ('men', 0.3799769878387451),\n",
              " ('sun', 0.3798797130584717),\n",
              " ('refuse', 0.3764769732952118),\n",
              " ('understand', 0.37059125304222107)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"carry\"], topn=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import plotly.express as px\n",
        "\n",
        "similar_words = w2v_model.wv.most_similar(positive=[\"carry\"], topn=10)\n",
        "words = [word for word, similarity in similar_words]\n",
        "\n",
        "# Get word vectors for the selected words\n",
        "word_vectors = [w2v_model.wv[word] for word in words]\n",
        "\n",
        "# Apply PCA to reduce the dimensionality to 2\n",
        "pca = PCA(n_components=2)\n",
        "embeddings_2d = pca.fit_transform(word_vectors)\n",
        "\n",
        "# Create a DataFrame with the embeddings and words\n",
        "data = {\"Word\": words, \"Dimension 1\": embeddings_2d[:, 0], \"Dimension 2\": embeddings_2d[:, 1]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create the scatter plot\n",
        "fig = px.scatter(df, x=\"Dimension 1\", y=\"Dimension 2\", text=\"Word\")\n",
        "\n",
        "fig.update_traces(textposition=\"top center\")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Word Embeddings - Palabras que menos se relacionan con 'worry'\",\n",
        "    xaxis_title=\"Dimension 1\",\n",
        "    yaxis_title=\"Dimension 2\",\n",
        "    hovermode=\"closest\",\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "f2G4iV5zoo8P",
        "outputId": "7ffef43b-1012-456a-925d-0d8cf178bdea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"0300aaf2-0ded-4271-ac6b-61fb81eaa08a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0300aaf2-0ded-4271-ac6b-61fb81eaa08a\")) {                    Plotly.newPlot(                        \"0300aaf2-0ded-4271-ac6b-61fb81eaa08a\",                        [{\"hovertemplate\":\"Dimension 1=%{x}<br>Dimension 2=%{y}<br>Word=%{text}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"can\",\"top\",\"trodding\",\"might\",\"winepress\",\"where\",\"men\",\"sun\",\"refuse\",\"understand\"],\"x\":[0.6023610399852892,-0.7864148005803132,-2.2658685211900353,-3.1772303124636316,-2.610277825017801,2.368439866357623,0.19607947901975434,2.198406642056754,0.07954558113300937,3.394958850699353],\"xaxis\":\"x\",\"y\":[0.5292905166980169,-0.48401557548762475,-2.5538081413040192,3.842370445955887,-3.0928915608650365,0.5765172425440178,0.3455428587675999,-0.9333394115711438,2.3353997773311153,-0.5650661520688103],\"yaxis\":\"y\",\"type\":\"scatter\",\"textposition\":\"top center\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dimension 1\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dimension 2\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Word Embeddings - Palabras que menos se relacionan con 'worry'\"},\"hovermode\":\"closest\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0300aaf2-0ded-4271-ac6b-61fb81eaa08a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(negative=[\"carry\"], topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rsI-4jFdM72",
        "outputId": "8aaa73f2-f53f-4fc1-daf1-8768fb7e69eb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('home', -0.014075775630772114),\n",
              " ('mean', -0.014894583262503147),\n",
              " ('must', -0.04160614311695099),\n",
              " ('own', -0.05171738564968109),\n",
              " ('dip', -0.054053258150815964),\n",
              " ('him', -0.05461045727133751),\n",
              " ('by', -0.0574447326362133),\n",
              " ('man', -0.06352297216653824),\n",
              " ('sheriff', -0.06425084918737411),\n",
              " ('rastaman', -0.06533803790807724)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "similar_words = w2v_model.wv.most_similar(negative=[\"carry\"], topn=10)\n",
        "words = [word for word, similarity in similar_words]\n",
        "\n",
        "# Get word vectors for the selected words\n",
        "word_vectors = [w2v_model.wv[word] for word in words]\n",
        "\n",
        "# Apply PCA to reduce the dimensionality to 2\n",
        "pca = PCA(n_components=2)\n",
        "embeddings_2d = pca.fit_transform(word_vectors)\n",
        "\n",
        "# Create a DataFrame with the embeddings and words\n",
        "data = {\"Word\": words, \"Dimension 1\": embeddings_2d[:, 0], \"Dimension 2\": embeddings_2d[:, 1]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create the scatter plot\n",
        "fig = px.scatter(df, x=\"Dimension 1\", y=\"Dimension 2\", text=\"Word\")\n",
        "\n",
        "fig.update_traces(textposition=\"top center\")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Word Embeddings - Palabras que menos se relacionan con 'worry'\",\n",
        "    xaxis_title=\"Dimension 1\",\n",
        "    yaxis_title=\"Dimension 2\",\n",
        "    hovermode=\"closest\",\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "gCjfM2UfouMw",
        "outputId": "a1f29966-edf0-4119-b7c7-58df90c7ecbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"04afbba3-45fd-4d78-a1ae-28ceb143eb33\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"04afbba3-45fd-4d78-a1ae-28ceb143eb33\")) {                    Plotly.newPlot(                        \"04afbba3-45fd-4d78-a1ae-28ceb143eb33\",                        [{\"hovertemplate\":\"Dimension 1=%{x}<br>Dimension 2=%{y}<br>Word=%{text}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"home\",\"mean\",\"must\",\"own\",\"dip\",\"him\",\"by\",\"man\",\"sheriff\",\"rastaman\"],\"x\":[4.7191655303596,-3.473441678942928,-1.335754914206623,1.7645253094596465,0.4471679171475646,-2.2250274429916392,0.5067718855558535,1.111453631705647,-1.3876605120533316,-0.12719972603379218],\"xaxis\":\"x\",\"y\":[0.2120322647252071,-1.7466569123184583,0.986130662962588,-2.8682139872018104,-1.6384115910307064,-1.7658458269597888,-0.11197327717291167,0.15671670932084714,2.49208579298553,4.284136164689505],\"yaxis\":\"y\",\"type\":\"scatter\",\"textposition\":\"top center\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dimension 1\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dimension 2\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Word Embeddings - Palabras que menos se relacionan con 'worry'\"},\"hovermode\":\"closest\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('04afbba3-45fd-4d78-a1ae-28ceb143eb33');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "XPLDPgzBmQXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4a3edbe-9b21-4bf8-a1ba-92e36d0e9b1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cold', 0.4345054030418396),\n",
              " ('after', 0.43127110600471497),\n",
              " (\"we're\", 0.39652013778686523),\n",
              " ('yard', 0.3895811438560486),\n",
              " ('mystic', 0.3873659372329712)]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(positive=[\"coming\"], topn=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "similar_words = w2v_model.wv.most_similar(positive=[\"coming\"], topn=10)\n",
        "words = [word for word, similarity in similar_words]\n",
        "\n",
        "# Get word vectors for the selected words\n",
        "word_vectors = [w2v_model.wv[word] for word in words]\n",
        "\n",
        "# Apply PCA to reduce the dimensionality to 2\n",
        "pca = PCA(n_components=2)\n",
        "embeddings_2d = pca.fit_transform(word_vectors)\n",
        "\n",
        "# Create a DataFrame with the embeddings and words\n",
        "data = {\"Word\": words, \"Dimension 1\": embeddings_2d[:, 0], \"Dimension 2\": embeddings_2d[:, 1]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create the scatter plot\n",
        "fig = px.scatter(df, x=\"Dimension 1\", y=\"Dimension 2\", text=\"Word\")\n",
        "\n",
        "fig.update_traces(textposition=\"top center\")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Word Embeddings - Palabras que menos se relacionan con 'worry'\",\n",
        "    xaxis_title=\"Dimension 1\",\n",
        "    yaxis_title=\"Dimension 2\",\n",
        "    hovermode=\"closest\",\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "BzBrgv9Io0uE",
        "outputId": "5ad8bcf8-c6c9-4bbe-9e31-f605192c76c2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"5130340e-0eb3-4b2e-8962-182ddfcfb843\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5130340e-0eb3-4b2e-8962-182ddfcfb843\")) {                    Plotly.newPlot(                        \"5130340e-0eb3-4b2e-8962-182ddfcfb843\",                        [{\"hovertemplate\":\"Dimension 1=%{x}<br>Dimension 2=%{y}<br>Word=%{text}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"cold\",\"after\",\"we're\",\"yard\",\"mystic\",\"they're\",\"name\",\"black\",\"listen\",\"woo\"],\"x\":[1.2933905238984817,-2.6618200437574964,1.424781464096811,4.323875512172758,0.7090342542398947,-2.459742418308026,2.8094840190540826,-2.322284377707046,-2.031121425861647,-1.0855975078278128],\"xaxis\":\"x\",\"y\":[1.693759455275215,-2.531524288615562,-0.9535094821881254,-0.2747214957721469,-1.3202927426341677,-2.7766536341025336,-0.04186899250161353,3.0280836275757634,1.7748056581376928,1.401921894825476],\"yaxis\":\"y\",\"type\":\"scatter\",\"textposition\":\"top center\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dimension 1\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dimension 2\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Word Embeddings - Palabras que menos se relacionan con 'worry'\"},\"hovermode\":\"closest\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5130340e-0eb3-4b2e-8962-182ddfcfb843');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Palabras que MÁS se relacionan con...:\n",
        "w2v_model.wv.most_similar(negative=[\"coming\"], topn=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7bkLOkidPJm",
        "outputId": "12fb0e5a-bbd9-476d-a277-774624eeaaa2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('live', -0.018225455656647682),\n",
              " ('fight', -0.03707129508256912),\n",
              " ('eh', -0.03959693759679794),\n",
              " ('walk', -0.040384840220212936),\n",
              " ('shed', -0.049502287060022354)]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KJTJnIRxo6vT"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "similar_words = w2v_model.wv.most_similar(negative=[\"coming\"], topn=10)\n",
        "words = [word for word, similarity in similar_words]\n",
        "\n",
        "# Get word vectors for the selected words\n",
        "word_vectors = [w2v_model.wv[word] for word in words]\n",
        "\n",
        "# Apply PCA to reduce the dimensionality to 2\n",
        "pca = PCA(n_components=2)\n",
        "embeddings_2d = pca.fit_transform(word_vectors)\n",
        "\n",
        "# Create a DataFrame with the embeddings and words\n",
        "data = {\"Word\": words, \"Dimension 1\": embeddings_2d[:, 0], \"Dimension 2\": embeddings_2d[:, 1]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create the scatter plot\n",
        "fig = px.scatter(df, x=\"Dimension 1\", y=\"Dimension 2\", text=\"Word\")\n",
        "\n",
        "fig.update_traces(textposition=\"top center\")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Word Embeddings - Palabras que menos se relacionan con 'worry'\",\n",
        "    xaxis_title=\"Dimension 1\",\n",
        "    yaxis_title=\"Dimension 2\",\n",
        "    hovermode=\"closest\",\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Ap4tPZWKo69r",
        "outputId": "4030d3a8-7d3d-4f88-bc7d-ce08f4868093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"6653d046-de8c-4beb-b1ec-27135d5e45ad\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6653d046-de8c-4beb-b1ec-27135d5e45ad\")) {                    Plotly.newPlot(                        \"6653d046-de8c-4beb-b1ec-27135d5e45ad\",                        [{\"hovertemplate\":\"Dimension 1=%{x}<br>Dimension 2=%{y}<br>Word=%{text}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"live\",\"fight\",\"eh\",\"walk\",\"shed\",\"again\",\"them\",\"happy\",\"long\",\"every\"],\"x\":[-1.237091873695148,-0.4860335681804305,4.407025360599852,1.3303937651238196,-3.3979364821541878,1.4682146434219194,0.2829755921002209,-0.29474448681466664,-1.6469096005558947,-0.42589334984548577],\"xaxis\":\"x\",\"y\":[-1.1415366996707026,0.29937754658931437,-2.952703828830187,2.522214196316718,-0.39733682767137307,3.970420909209537,-1.3375908539069152,0.6553326475482217,-0.8954502794938177,-0.7227268100907908],\"yaxis\":\"y\",\"type\":\"scatter\",\"textposition\":\"top center\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dimension 1\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dimension 2\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Word Embeddings - Palabras que menos se relacionan con 'worry'\"},\"hovermode\":\"closest\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6653d046-de8c-4beb-b1ec-27135d5e45ad');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "L_UvHPMMklOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19f16073-568c-4781-8b36-b0a994ffad7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('over', 0.0013198801316320896),\n",
              " ('another', -0.02513829991221428),\n",
              " ('three', -0.026825806125998497),\n",
              " ('children', -0.02716630883514881),\n",
              " ('still', -0.028276905417442322),\n",
              " ('living', -0.032480400055646896),\n",
              " ('tonight', -0.036378975957632065),\n",
              " ('god', -0.03841937333345413),\n",
              " ('send', -0.04401835799217224),\n",
              " ('every', -0.044799793511629105)]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# Ensayar con una palabra que no está en el vocabulario:\n",
        "w2v_model.wv.most_similar(negative=[\"could\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1EaokdCRo_gt"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "similar_words = w2v_model.wv.most_similar(negative=[\"could\"], topn=10)\n",
        "words = [word for word, similarity in similar_words]\n",
        "\n",
        "# Get word vectors for the selected words\n",
        "word_vectors = [w2v_model.wv[word] for word in words]\n",
        "\n",
        "# Apply PCA to reduce the dimensionality to 2\n",
        "pca = PCA(n_components=2)\n",
        "embeddings_2d = pca.fit_transform(word_vectors)\n",
        "\n",
        "# Create a DataFrame with the embeddings and words\n",
        "data = {\"Word\": words, \"Dimension 1\": embeddings_2d[:, 0], \"Dimension 2\": embeddings_2d[:, 1]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create the scatter plot\n",
        "fig = px.scatter(df, x=\"Dimension 1\", y=\"Dimension 2\", text=\"Word\")\n",
        "\n",
        "fig.update_traces(textposition=\"top center\")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Word Embeddings - Palabras que menos se relacionan con 'worry'\",\n",
        "    xaxis_title=\"Dimension 1\",\n",
        "    yaxis_title=\"Dimension 2\",\n",
        "    hovermode=\"closest\",\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "QOokovYeo_17",
        "outputId": "3852206b-2838-493b-e389-397d5a80efa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"221bc16a-f2de-481d-a126-a4ef0cdc473e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"221bc16a-f2de-481d-a126-a4ef0cdc473e\")) {                    Plotly.newPlot(                        \"221bc16a-f2de-481d-a126-a4ef0cdc473e\",                        [{\"hovertemplate\":\"Dimension 1=%{x}<br>Dimension 2=%{y}<br>Word=%{text}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"over\",\"another\",\"three\",\"children\",\"still\",\"living\",\"tonight\",\"god\",\"send\",\"every\"],\"x\":[-2.1204323292625227,3.07510869472298,3.8640439628316665,-0.12740105969205895,1.827249112177081,-1.8830136646988183,-0.34857195050953266,-2.783054832918741,-1.9407041353389332,0.4367762026888818],\"xaxis\":\"x\",\"y\":[-1.9057864541466703,-1.3522522782152857,0.4686021958746444,-1.2788932112811096,0.3739906464789567,-2.3242875058704686,1.70273778491108,-0.9767509971077786,4.7752081950760275,0.5174316242806046],\"yaxis\":\"y\",\"type\":\"scatter\",\"textposition\":\"top center\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dimension 1\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dimension 2\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Word Embeddings - Palabras que menos se relacionan con 'worry'\"},\"hovermode\":\"closest\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('221bc16a-f2de-481d-a126-a4ef0cdc473e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensayar con una palabra que no está en el vocabulario:\n",
        "w2v_model.wv.most_similar(positive=[\"could\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qzkbm8XddRMJ",
        "outputId": "e73da7ae-a0c2-417a-c9d3-0b1af6972dd6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('loved', 0.5838057994842529),\n",
              " ('something', 0.5109092593193054),\n",
              " ('doo', 0.3822464048862457),\n",
              " ('light', 0.3619440495967865),\n",
              " ('air', 0.3482476472854614),\n",
              " ('blowing', 0.3387719392776489),\n",
              " ('matter', 0.32269126176834106),\n",
              " ('rock', 0.32117870450019836),\n",
              " ('fit', 0.32084429264068604),\n",
              " ('cap', 0.3127816617488861)]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "similar_words = w2v_model.wv.most_similar(positive=[\"could\"], topn=10)\n",
        "words = [word for word, similarity in similar_words]\n",
        "\n",
        "# Get word vectors for the selected words\n",
        "word_vectors = [w2v_model.wv[word] for word in words]\n",
        "\n",
        "# Apply PCA to reduce the dimensionality to 2\n",
        "pca = PCA(n_components=2)\n",
        "embeddings_2d = pca.fit_transform(word_vectors)\n",
        "\n",
        "# Create a DataFrame with the embeddings and words\n",
        "data = {\"Word\": words, \"Dimension 1\": embeddings_2d[:, 0], \"Dimension 2\": embeddings_2d[:, 1]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create the scatter plot\n",
        "fig = px.scatter(df, x=\"Dimension 1\", y=\"Dimension 2\", text=\"Word\")\n",
        "\n",
        "fig.update_traces(textposition=\"top center\")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Word Embeddings - Palabras que menos se relacionan con 'worry'\",\n",
        "    xaxis_title=\"Dimension 1\",\n",
        "    yaxis_title=\"Dimension 2\",\n",
        "    hovermode=\"closest\",\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "-TcpP0y4pFgO",
        "outputId": "85daa65b-a221-49bb-dadb-05c1eae18e78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"9098592f-22b6-48ef-9a11-6a20a56a2adb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9098592f-22b6-48ef-9a11-6a20a56a2adb\")) {                    Plotly.newPlot(                        \"9098592f-22b6-48ef-9a11-6a20a56a2adb\",                        [{\"hovertemplate\":\"Dimension 1=%{x}<br>Dimension 2=%{y}<br>Word=%{text}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"loved\",\"something\",\"doo\",\"light\",\"air\",\"blowing\",\"matter\",\"rock\",\"fit\",\"cap\"],\"x\":[-1.885724380091477,-1.8408601892324397,-0.9384406584569449,-2.408462746729775,3.209866622450346,2.7143549021516264,-2.493619752955401,-1.9316645915166857,3.2136780013162216,2.360872793064531],\"xaxis\":\"x\",\"y\":[-1.6181847556567446,-1.2383248889820362,0.5294842107822381,-0.6892172125000483,-2.806331298179716,-1.7367690056554703,3.092957769188518,-0.46851496472240217,2.7966926476474994,2.13820749807816],\"yaxis\":\"y\",\"type\":\"scatter\",\"textposition\":\"top center\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dimension 1\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dimension 2\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Word Embeddings - Palabras que menos se relacionan con 'worry'\"},\"hovermode\":\"closest\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9098592f-22b6-48ef-9a11-6a20a56a2adb');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g8UVWe6lFmh"
      },
      "source": [
        "### 5 - Visualizar agrupación de vectores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "pDxEVXAivjr9"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "\n",
        "def reduce_dimensions(model):\n",
        "    num_dimensions = 2\n",
        "\n",
        "    vectors = np.asarray(model.wv.vectors)\n",
        "    labels = np.asarray(model.wv.index2word)\n",
        "\n",
        "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
        "    vectors = tsne.fit_transform(vectors)\n",
        "\n",
        "    x_vals = [v[0] for v in vectors]\n",
        "    y_vals = [v[1] for v in vectors]\n",
        "    return x_vals, y_vals, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "NCCXtDpcugmd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "d8c08aae-c631-4082-a176-47232cc70cc8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"9c8c6d4a-4c86-48e4-9f0f-063d92e6eb22\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9c8c6d4a-4c86-48e4-9f0f-063d92e6eb22\")) {                    Plotly.newPlot(                        \"9c8c6d4a-4c86-48e4-9f0f-063d92e6eb22\",                        [{\"hovertemplate\":\"x=%{x}<br>y=%{y}<br>Word=%{text}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"the\",\"you\",\"i\",\"a\",\"to\",\"and\",\"no\",\"it\",\"in\",\"oh\",\"me\",\"be\",\"love\",\"is\",\"of\",\"yeah\",\"don't\",\"so\",\"all\",\"we\",\"your\",\"my\",\"on\",\"for\",\"up\",\"now\",\"down\",\"right\",\"one\",\"say\",\"this\",\"know\",\"do\",\"gonna\",\"but\",\"they\",\"when\",\"got\",\"jah\",\"that\",\"de\",\"i'm\",\"get\",\"come\",\"baby\",\"we're\",\"will\",\"give\",\"it's\",\"from\",\"people\",\"like\",\"there\",\"little\",\"jammin'\",\"thing\",\"coming\",\"with\",\"said\",\"what\",\"wanna\",\"can\",\"every\",\"feel\",\"'cause\",\"them\",\"was\",\"man\",\"want\",\"let\",\"can't\",\"ooh\",\"na\",\"try\",\"go\",\"just\",\"see\",\"could\",\"more\",\"lord\",\"are\",\"take\",\"worry\",\"stand\",\"through\",\"heart\",\"dread\",\"time\",\"good\",\"about\",\"easy\",\"life\",\"simmer\",\"some\",\"together\",\"never\",\"much\",\"woman\",\"yoy\",\"stir\",\"won't\",\"need\",\"have\",\"day\",\"ya\",\"back\",\"then\",\"hammer\",\"uh\",\"she\",\"soul\",\"'pon\",\"if\",\"cry\",\"forever\",\"move\",\"town\",\"whatcha\",\"rock\",\"bad\",\"doo\",\"youths\",\"very\",\"away\",\"we'll\",\"wo\",\"children\",\"rammer\",\"race\",\"heathen\",\"i'll\",\"rebel\",\"wall\",\"he\",\"wop\",\"sweet\",\"you're\",\"hear\",\"why\",\"not\",\"world\",\"tell\",\"loved\",\"our\",\"loving\",\"here\",\"boys\",\"ganja\",\"where\",\"bomb\",\"long\",\"i've\",\"us\",\"movement\",\"cok\",\"fire\",\"choo\",\"that's\",\"let's\",\"something\",\"make\",\"carry\",\"rat\",\"fight\",\"would\",\"who\",\"africa\",\"ain't\",\"too\",\"woo\",\"yo\",\"how\",\"gone\",\"look\",\"their\",\"am\",\"skanking\",\"jamaica\",\"cluck\",\"oo\",\"music\",\"darling\",\"well\",\"by\",\"trench\",\"unite\",\"things\",\"way\",\"while\",\"woe\",\"singin'\",\"you've\",\"keep\",\"at\",\"place\",\"war\",\"talk\",\"exodus\",\"hit\",\"as\"],\"x\":[-0.08633767813444138,-0.8197441101074219,-0.3678406774997711,-0.2900121808052063,-0.39435553550720215,-0.48560190200805664,-0.26080331206321716,-0.046494949609041214,0.4911588132381439,-0.3182700276374817,-0.7578790783882141,-0.22234751284122467,-0.9103546142578125,-0.22105664014816284,0.21210722625255585,-0.5385832786560059,-0.557169497013092,-0.8156840801239014,-0.3910384476184845,-0.22400808334350586,-0.7417159676551819,-0.5456916093826294,-0.6456624865531921,-0.49966922402381897,-0.1501876562833786,-0.5114115476608276,-0.8014294505119324,-0.4753114879131317,-0.14455294609069824,-0.13443732261657715,-0.13286113739013672,-0.5516999959945679,-0.38443028926849365,-0.4925185441970825,0.21379505097866058,-0.4422896206378937,-0.03915023058652878,-0.4903510808944702,-0.080327108502388,-0.08016733080148697,-0.6715354919433594,-0.5953740477561951,-0.60593181848526,-0.3727484345436096,-0.7156403064727783,0.15922178328037262,0.09413770586252213,-0.3357005715370178,-0.3903219997882843,0.2615513503551483,-0.003826002823188901,0.0860714241862297,-0.023620981723070145,-0.5490885376930237,0.7406517267227173,0.284895122051239,-0.1200498715043068,-0.32271280884742737,-0.038327910006046295,-0.4379366636276245,-0.446468710899353,-0.3303159773349762,-0.33383411169052124,0.006022818386554718,-0.2816659212112427,-0.0025613433681428432,0.5405013561248779,-0.330242395401001,-0.5717628002166748,-0.21659404039382935,-0.2465764582157135,-0.055334579199552536,-0.8612502217292786,-0.6000001430511475,-0.37809401750564575,0.01446120161563158,0.06891891360282898,0.1670517921447754,0.2506433427333832,0.10706396400928497,-0.011119729839265347,-0.1408449113368988,-0.39687803387641907,-0.5849263072013855,0.5075716972351074,0.008126357570290565,0.3215930461883545,-0.39549002051353455,-0.27487125992774963,0.17972178757190704,-0.452494740486145,0.37648409605026245,-0.45898202061653137,-0.13403895497322083,-0.27646923065185547,-0.22868454456329346,-0.27131426334381104,-0.011537162587046623,0.6443625688552856,-0.6913802027702332,-0.25168439745903015,-0.5052653551101685,-0.6037080883979797,-0.5651541948318481,-0.4741462469100952,-0.11892784386873245,-1.117676019668579,0.11324149370193481,-0.12316625565290451,-0.12393487989902496,-0.32500940561294556,-0.7087106108665466,-0.7862880825996399,0.018212100490927696,-0.7358742356300354,-0.8889375925064087,0.5813688635826111,-0.2867719531059265,-0.6636021733283997,-0.6350213289260864,-0.09394770115613937,0.2961556315422058,-0.2142409235239029,0.2816087603569031,-0.08849958330392838,-0.03551683574914932,0.052879489958286285,0.1449313908815384,0.2908811569213867,-0.46895915269851685,0.2820854187011719,0.0817384347319603,-0.6254233717918396,-0.41601020097732544,-0.2632199227809906,0.278556764125824,-0.6113032102584839,-0.09460744261741638,-1.0191009044647217,-0.5848348736763,0.47766563296318054,-0.30141720175743103,-0.41520196199417114,-0.06986749917268753,-0.6464453339576721,-0.14476406574249268,-0.6030241847038269,-0.4647482931613922,-0.5653601884841919,-0.72488933801651,0.05378209054470062,-0.11697797477245331,0.29654234647750854,-0.17428699135780334,-0.5028073787689209,0.8388542532920837,-0.32795220613479614,-0.1177118793129921,0.12250915169715881,-0.3245801031589508,-0.11575304716825485,-0.25528889894485474,0.6075399518013,-0.15794579684734344,-0.14662516117095947,0.5503787994384766,0.2479570508003235,0.1034434586763382,-0.8473588824272156,0.5566490888595581,0.5351731181144714,-0.4534458816051483,-0.1572853922843933,-1.2410809993743896,-0.8424499034881592,-0.12669780850410461,-0.15028932690620422,0.4596298336982727,-0.2790469527244568,0.18346813321113586,-0.5261222720146179,-0.8284815549850464,0.21891841292381287,0.23310647904872894,-0.15522277355194092,0.17630212008953094,0.4146295487880707,0.22613443434238434,-1.1755276918411255,1.0790588855743408,-1.4454176425933838,-1.1252423524856567,-0.9723609089851379,-0.5807024836540222,0.5033074021339417,0.8168758153915405,-0.41499701142311096,0.6471632719039917,-0.17490367591381073,0.30432167649269104],\"xaxis\":\"x\",\"y\":[-0.0722551941871643,-0.15677177906036377,-0.286337286233902,0.4810178577899933,-0.010349437594413757,-0.15322022140026093,0.48135700821876526,-0.07061339914798737,0.25742048025131226,0.2001795917749405,-0.006535724271088839,-0.2762645184993744,0.051493484526872635,-0.004375827498733997,-0.0781700536608696,0.43636855483055115,-0.05952969565987587,0.22512546181678772,0.3371681869029999,0.2627679407596588,0.2201296091079712,-0.33506762981414795,0.12327388674020767,0.23802264034748077,-0.2241632342338562,-0.06208137795329094,-0.20780037343502045,7.317935524042696e-05,0.4203357398509979,0.003882613265886903,-0.1298111379146576,-0.05681668221950531,-0.3006432354450226,0.5211694836616516,-0.2432352900505066,0.43928492069244385,-0.3683743178844452,-0.0048644221387803555,0.3420672118663788,-0.6276905536651611,0.29535549879074097,-0.4589478373527527,-0.1982523798942566,0.5443862080574036,-0.22537854313850403,0.22622613608837128,0.1766406148672104,0.22601301968097687,-0.38444340229034424,0.005116784013807774,0.19853748381137848,-0.4582769572734833,0.6693231463432312,0.04870935529470444,-0.28497394919395447,0.5298593044281006,0.2365923374891281,-0.5980239510536194,-0.33465954661369324,0.133583202958107,0.31060051918029785,-0.35207000374794006,0.006316915154457092,-0.13041016459465027,-0.03932701796293259,0.9031770825386047,0.6372878551483154,0.5407581925392151,-0.5383260846138,0.2336283028125763,-0.3270212411880493,-0.12771330773830414,0.17396830022335052,-0.2830199897289276,0.9139631986618042,0.14161795377731323,0.3733752965927124,-0.18896931409835815,0.5246621966362,0.09265679121017456,-0.4830377995967865,0.3785637617111206,0.16812875866889954,0.32505500316619873,-0.20533503592014313,-0.22403936088085175,0.6094918251037598,-0.014364967122673988,-0.14669238030910492,0.06868772208690643,-0.14360979199409485,0.0336611270904541,-0.5849161148071289,0.2852478623390198,-0.08262504637241364,0.22763630747795105,0.0794072151184082,0.6790315508842468,0.17127808928489685,-0.3784761428833008,-0.17258645594120026,0.2673119008541107,0.671179473400116,-0.2640073895454407,0.2899334728717804,0.05597790330648422,0.09757398068904877,0.5642539858818054,0.017812108621001244,0.4950568974018097,-0.1183917224407196,0.42917191982269287,-0.6239339113235474,0.6337716579437256,-0.08141781389713287,-0.7458512783050537,-0.04714363068342209,0.21879708766937256,-0.48235929012298584,-0.008467666804790497,-0.4012480080127716,-0.6938134431838989,0.8943058252334595,-0.1369747668504715,-0.6600381731987,0.515039324760437,-0.16243426501750946,0.721693754196167,0.4120165705680847,0.09637971967458725,0.35768115520477295,-0.2547938823699951,0.7683355808258057,1.0349347591400146,0.2842285931110382,1.0037446022033691,-0.21767961978912354,-1.1670920848846436,-0.6253119707107544,-0.6546170711517334,-0.39693716168403625,0.009737404994666576,0.021059809252619743,0.6240741014480591,-0.07518062740564346,-0.13547201454639435,0.6738547682762146,0.5956665277481079,0.09971141070127487,0.4742666482925415,-0.16207098960876465,-0.15452411770820618,0.3674551844596863,0.3682760000228882,-0.7293020486831665,-0.35952475666999817,0.2996607720851898,0.12552671134471893,0.07746005803346634,0.31368401646614075,-0.5942803621292114,-0.3157455623149872,0.481512188911438,0.5131760239601135,-0.5090470314025879,0.11340074986219406,0.03420531377196312,0.3027257025241852,-0.5079990029335022,0.34332987666130066,0.043081190437078476,-0.389649361371994,-1.0371692180633545,0.4276800751686096,1.5470855236053467,-0.09781670570373535,0.07161619514226913,0.39063432812690735,0.06689763814210892,0.2296927571296692,-0.13076935708522797,-0.5174663662910461,-0.8905118107795715,-0.37481221556663513,-0.041470155119895935,0.06720156967639923,-0.42646777629852295,-0.09868919849395752,0.28479865193367004,0.30577757954597473,0.128876730799675,0.14486759901046753,-0.05631990358233452,-0.2247135192155838,0.2710748314857483,-0.08519948273897171,0.3468307852745056,-0.27313899993896484,-0.8127428889274597,-0.7497571706771851],\"yaxis\":\"y\",\"type\":\"scatter\",\"textposition\":\"top center\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dimension 1\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dimension 2\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Word Embeddings\"},\"hovermode\":\"closest\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9c8c6d4a-4c86-48e4-9f0f-063d92e6eb22');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Get word vectors\n",
        "word_vectors = w2v_model.wv\n",
        "\n",
        "# Reduce dimensionality using PCA\n",
        "pca = PCA(n_components=2)\n",
        "embeddings_2d = pca.fit_transform(word_vectors.vectors)\n",
        "\n",
        "# Get word labels\n",
        "labels = word_vectors.index_to_key\n",
        "\n",
        "# Select a subset of words for visualization\n",
        "MAX_WORDS = 200\n",
        "embeddings_2d_subset = embeddings_2d[:MAX_WORDS]\n",
        "labels_subset = labels[:MAX_WORDS]\n",
        "\n",
        "# Create a scatter plot\n",
        "fig = px.scatter(\n",
        "    x=embeddings_2d_subset[:, 0],\n",
        "    y=embeddings_2d_subset[:, 1],\n",
        "    text=labels_subset,\n",
        "    labels={\"text\": \"Word\"},\n",
        ")\n",
        "\n",
        "fig.update_traces(textposition=\"top center\")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Word Embeddings\",\n",
        "    xaxis_title=\"Dimension 1\",\n",
        "    yaxis_title=\"Dimension 2\",\n",
        "    hovermode=\"closest\",\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMM_SHSaZ9N-"
      },
      "source": [
        "### Alumno"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WivQZ3ZCZ9N_"
      },
      "source": [
        "- Crear sus propios vectores con Gensim basado en lo visto en clase con otro dataset.\n",
        "- Probar términos de interés y explicar similitudes en el espacio de embeddings (sacar conclusiones entre palabras similitudes y diferencias).\n",
        "- Graficarlos.\n",
        "- Obtener conclusiones.\n",
        "similitudes en relación con la palabra \"worry\" en el modelo de palabras vectoriales (Word2Vec) utilizado. Las similitudes varían entre 0.3295 y 0.4556. Cada palabra tiene una similitud única que indica su grado de relación con \"worry\". En general, las palabras más cercanas en similitud son \"singin'\", \"fall\", \"'bout\" y \"alright\", mientras que las palabras menos relacionadas en términos de similitud son \"happy\", \"thing\", \"message\", \"pimper's\", \"gun\" y \"little\". La similitud se calcula en función de la proximidad de las palabras en el espacio vectorial de palabras del modelo.\n",
        "\n",
        "Estas son las palabras que menos se relacionan con \"worry\" en el modelo de palabras vectoriales (Word2Vec):\n",
        "\n",
        "'roots': 0.018203111365437508\n",
        "'vibration': -0.012176807038486004\n",
        "'jah': -0.028318891301751137\n",
        "'word': -0.032436762005090714\n",
        "'first': -0.03879272937774658\n",
        "'too': -0.04466841742396355\n",
        "'fool': -0.048376649618148804\n",
        "'rastaman': -0.051271677017211914\n",
        "'came': -0.051643576472997665\n",
        "'on': -0.05538153648376465\n",
        "Estas palabras tienen una relación menos cercana con \"worry\" en comparación con otras palabras del modelo. La similitud negativa indica que estas palabras están menos asociadas o menos relacionadas en términos de contexto y uso en comparación con la palabra \"worry\".\n",
        "COMING:\n",
        "\n",
        "Estas son las palabras que más se relacionan con \"coming\" en el modelo de palabras vectoriales (Word2Vec):\n",
        "\n",
        "'cold': 0.4345054030418396\n",
        "'after': 0.43127110600471497\n",
        "\"we're\": 0.39652013778686523\n",
        "'yard': 0.3895811438560486\n",
        "'mystic': 0.3873659372329712\n",
        "Estas palabras tienen una alta similitud con \"coming\" en términos de contexto y uso. Indican que estas palabras tienden a aparecer en contextos similares o se usan de manera similar a la palabra \"coming\".\n",
        "Estas son las palabras que más se relacionan negativamente con \"coming\" en el modelo de palabras vectoriales (Word2Vec):\n",
        "\n",
        "'live': -0.018225455656647682\n",
        "'fight': -0.03707129508256912\n",
        "'eh': -0.03959693759679794\n",
        "'walk': -0.040384840220212936\n",
        "'shed': -0.049502287060022354\n",
        "Estas palabras tienen una baja similitud con \"coming\" en términos de contexto y uso. Indican que estas palabras tienden a aparecer en contextos distintos o se usan de manera diferente a la palabra \"coming\".\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F024KFpllXg2"
      },
      "execution_count": 48,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}